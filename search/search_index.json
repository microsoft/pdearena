{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"architectures/","text":"Available Model Architectures \u00a4 If you would like your architecture added, please submit a pull request . Standard \u00a4 Architecture Module Description Based on FNO ResNet with FourierBasicBlock Fourier Neural Operator implementation with support for deeper architectures (8 and 4 layers) ResNet ResNet with BasicBlock ResNet architectures using 8 residual blocks, no downscaling DilResNet ResNet with DilatedBasicBlock ResNet where each block individually consists of 7 dilated CNN layers with dilation rates of [1, 2, 4, 8, 4, 2, 1], no downscaling U-Net 2015 Unet2015 Original U-Net implementation U-Net base Unetbase Our interpretation of original U-Net implementation without bottleneck layer and using GroupNorm U-Net mod Unet Modern U-Nets with Wide ResNet blocks, as used in various diffusion modeling applications U-F[*]Net FourierUnet Modern U-Nets with [*] Fourier blocks in the downsampling path UNO UNO Original U-shaped Neural Operator Implementation Conditioned \u00a4 Note Currently only scalar parameter conditioning is available. Architecture Model Name Description FNO ResNet with FourierBasicBlock Addition based conditioning in both spatial and spectral domain. U-Net-modern Unet Addition and AdaGN style conditioning in the spatial domain. UF-Net FourierUnet Addition and AdaGN style conditioning in the spatial domain, Addition in the spectral domain. Model Architecture Registry Philosophy \u00a4 While in principle we can make every architecture fully configurable via configuration files, we find it can affect the readability of the code quite a bit. Feel free to open issues or pull-requests for further configuration ability or any other suggestions for managing the configurability-readability tradeoffs. Other Projects of Interest \u00a4 PDEBench NVIDIA Modulus NeuralOperators.jl","title":"Architectures"},{"location":"architectures/#available-model-architectures","text":"If you would like your architecture added, please submit a pull request .","title":"Available Model Architectures"},{"location":"architectures/#standard","text":"Architecture Module Description Based on FNO ResNet with FourierBasicBlock Fourier Neural Operator implementation with support for deeper architectures (8 and 4 layers) ResNet ResNet with BasicBlock ResNet architectures using 8 residual blocks, no downscaling DilResNet ResNet with DilatedBasicBlock ResNet where each block individually consists of 7 dilated CNN layers with dilation rates of [1, 2, 4, 8, 4, 2, 1], no downscaling U-Net 2015 Unet2015 Original U-Net implementation U-Net base Unetbase Our interpretation of original U-Net implementation without bottleneck layer and using GroupNorm U-Net mod Unet Modern U-Nets with Wide ResNet blocks, as used in various diffusion modeling applications U-F[*]Net FourierUnet Modern U-Nets with [*] Fourier blocks in the downsampling path UNO UNO Original U-shaped Neural Operator Implementation","title":"Standard"},{"location":"architectures/#conditioned","text":"Note Currently only scalar parameter conditioning is available. Architecture Model Name Description FNO ResNet with FourierBasicBlock Addition based conditioning in both spatial and spectral domain. U-Net-modern Unet Addition and AdaGN style conditioning in the spatial domain. UF-Net FourierUnet Addition and AdaGN style conditioning in the spatial domain, Addition in the spectral domain.","title":"Conditioned"},{"location":"architectures/#model-architecture-registry-philosophy","text":"While in principle we can make every architecture fully configurable via configuration files, we find it can affect the readability of the code quite a bit. Feel free to open issues or pull-requests for further configuration ability or any other suggestions for managing the configurability-readability tradeoffs.","title":"Model Architecture Registry Philosophy"},{"location":"architectures/#other-projects-of-interest","text":"PDEBench NVIDIA Modulus NeuralOperators.jl","title":"Other Projects of Interest"},{"location":"data/","text":"Data Generation \u00a4 Tip For multi-gpu training, make sure that the number of shards is divisible by the number of GPUs. 8 is usually a safe number. Navier Stokes 2D \u00a4 Standard \u00a4 export seed = 42 ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke mode = train samples = 256 seed = $seed pdeconfig.sample_rate = 4 \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke mode = valid samples = 32 seed = $seed pdeconfig.sample_rate = 4 \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke mode = test samples = 32 seed = $seed pdeconfig.sample_rate = 4 \\ dirname = /mnt/data/navierstokes ; Conditioned \u00a4 export seed = 42 ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke_cond mode = train samples = 256 seed = $seed \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke_cond mode = valid samples = 32 seed = $seed \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke_cond mode = test samples = 32 seed = $seed \\ dirname = /mnt/data/navierstokes ; Data normalization \u00a4 The data was reasonably bounded that we didn't need any normalization. Shallow water 2D \u00a4 export seed = 42 ; python scripts/generate_data.py base = pdedatagen/configs/shallowwater.yaml \\ experiment = shallowwater mode = train samples = 256 seed = $seed \\ dirname = /mnt/data/shallowwater ; python scripts/generate_data.py base = pdedatagen/configs/shallowwater.yaml \\ experiment = shallowwater mode = valid samples = 32 seed = $seed \\ dirname = /mnt/data/shallowwater ; python scripts/generate_data.py base = pdedatagen/configs/shallowwater.yaml \\ experiment = shallowwater mode = test samples = 32 seed = $seed \\ dirname = /mnt/data/shallowwater ; Convert to zarr \u00a4 We found that data loading was a lot more performant with zarr format rather than original NetCDF format, especially with cloud storage. You can convert after data generation via: for mode in train valid test ; do python scripts/convertnc2zarr.py \"/mnt/data/shallowwater/ $mode \" ; done Data normalization \u00a4 python scripts/compute_normalization.py \\ --dataset shallowwater /mnt/data/shallowwater Maxwell 3D \u00a4 export seed = 42 python scripts/generate_data.py base = pdedatagen/configs/maxwell3d.yaml \\ experiment = maxwell mode = train samples = 256 seed = $seed dirname = /mnt/data/maxwell3d ; python scripts/generate_data.py base = pdedatagen/configs/maxwell3d.yaml \\ experiment = maxwell mode = valid samples = 32 seed = $seed dirname = /mnt/data/maxwell3d ; python scripts/generate_data.py base = pdedatagen/configs/maxwell3d.yaml \\ experiment = maxwell mode = test samples = 32 seed = $seed dirname = /mnt/data/maxwell3d ; Data normalization \u00a4 python scripts/compute_normalization.py \\ --dataset maxwell /mnt/data/maxwell3d PDEBench \u00a4 Generating \u00a4 Follow PDEBench's instructions . Resharding for multi-gpu experiments \u00a4 Coming soon... Data normalization \u00a4 Coming soon... Your PDE \u00a4 Please submit a pull request to add a data loading pipeline for your PDE dataset.","title":"Generation"},{"location":"data/#data-generation","text":"Tip For multi-gpu training, make sure that the number of shards is divisible by the number of GPUs. 8 is usually a safe number.","title":"Data Generation"},{"location":"data/#navier-stokes-2d","text":"","title":"Navier Stokes 2D"},{"location":"data/#standard","text":"export seed = 42 ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke mode = train samples = 256 seed = $seed pdeconfig.sample_rate = 4 \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke mode = valid samples = 32 seed = $seed pdeconfig.sample_rate = 4 \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke mode = test samples = 32 seed = $seed pdeconfig.sample_rate = 4 \\ dirname = /mnt/data/navierstokes ;","title":"Standard"},{"location":"data/#conditioned","text":"export seed = 42 ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke_cond mode = train samples = 256 seed = $seed \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke_cond mode = valid samples = 32 seed = $seed \\ dirname = /mnt/data/navierstokes ; python scripts/generate_data.py base = pdedatagen/configs/navierstokes2dsmoke.yaml \\ experiment = smoke_cond mode = test samples = 32 seed = $seed \\ dirname = /mnt/data/navierstokes ;","title":"Conditioned"},{"location":"data/#data-normalization","text":"The data was reasonably bounded that we didn't need any normalization.","title":"Data normalization"},{"location":"data/#shallow-water-2d","text":"export seed = 42 ; python scripts/generate_data.py base = pdedatagen/configs/shallowwater.yaml \\ experiment = shallowwater mode = train samples = 256 seed = $seed \\ dirname = /mnt/data/shallowwater ; python scripts/generate_data.py base = pdedatagen/configs/shallowwater.yaml \\ experiment = shallowwater mode = valid samples = 32 seed = $seed \\ dirname = /mnt/data/shallowwater ; python scripts/generate_data.py base = pdedatagen/configs/shallowwater.yaml \\ experiment = shallowwater mode = test samples = 32 seed = $seed \\ dirname = /mnt/data/shallowwater ;","title":"Shallow water 2D"},{"location":"data/#convert-to-zarr","text":"We found that data loading was a lot more performant with zarr format rather than original NetCDF format, especially with cloud storage. You can convert after data generation via: for mode in train valid test ; do python scripts/convertnc2zarr.py \"/mnt/data/shallowwater/ $mode \" ; done","title":"Convert to zarr"},{"location":"data/#data-normalization_1","text":"python scripts/compute_normalization.py \\ --dataset shallowwater /mnt/data/shallowwater","title":"Data normalization"},{"location":"data/#maxwell-3d","text":"export seed = 42 python scripts/generate_data.py base = pdedatagen/configs/maxwell3d.yaml \\ experiment = maxwell mode = train samples = 256 seed = $seed dirname = /mnt/data/maxwell3d ; python scripts/generate_data.py base = pdedatagen/configs/maxwell3d.yaml \\ experiment = maxwell mode = valid samples = 32 seed = $seed dirname = /mnt/data/maxwell3d ; python scripts/generate_data.py base = pdedatagen/configs/maxwell3d.yaml \\ experiment = maxwell mode = test samples = 32 seed = $seed dirname = /mnt/data/maxwell3d ;","title":"Maxwell 3D"},{"location":"data/#data-normalization_2","text":"python scripts/compute_normalization.py \\ --dataset maxwell /mnt/data/maxwell3d","title":"Data normalization"},{"location":"data/#pdebench","text":"","title":"PDEBench"},{"location":"data/#generating","text":"Follow PDEBench's instructions .","title":"Generating"},{"location":"data/#resharding-for-multi-gpu-experiments","text":"Coming soon...","title":"Resharding for multi-gpu experiments"},{"location":"data/#data-normalization_3","text":"Coming soon...","title":"Data normalization"},{"location":"data/#your-pde","text":"Please submit a pull request to add a data loading pipeline for your PDE dataset.","title":"Your PDE"},{"location":"datadownload/","text":"Downloading data from Azure \u00a4 First make sure you have azcopy installed. On Linux you can do: wget https://aka.ms/downloadazcopy-v10-linux tar -xvf downloadazcopy-v10-linux # move to somewhere on your PATH mv ./azcopy_linux_amd64_*/azcopy $HOME /.local/bin Navier Stokes - 2D \u00a4 Generated using \u03a6 Flow . Standard dataset \u00a4 azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/NavierStokes2D_smoke\" \\ \"/mnt/data/\" --recursive Conditioning dataset \u00a4 azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/NavierStokes2D_cond_smoke_v1\" \\ \"/mnt/data/\" --recursive Shallow water - 2D \u00a4 Generated using SpeedyWeather.jl . azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/ShallowWater2D\" \\ \"/mnt/data/\" --recursive Maxwell - 3D \u00a4 Generated using Python 3D FDTD Simulator . azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/Maxwell2D\" \\ \"/mnt/data/\" --recursive PDEBench \u00a4 PDEBench data can be downloaded with the included download_pdebenchdata.py script: For example to download the Incompressible Navier Stokes dataset: export DATAVERSE_URL = https://darus.uni-stuttgart.de ; python scripts/download_pdebenchdata.py \\ --outdir /mnt/data/PDEBench/ --limit ns_incom","title":"Download"},{"location":"datadownload/#downloading-data-from-azure","text":"First make sure you have azcopy installed. On Linux you can do: wget https://aka.ms/downloadazcopy-v10-linux tar -xvf downloadazcopy-v10-linux # move to somewhere on your PATH mv ./azcopy_linux_amd64_*/azcopy $HOME /.local/bin","title":"Downloading data from Azure"},{"location":"datadownload/#navier-stokes-2d","text":"Generated using \u03a6 Flow .","title":"Navier Stokes - 2D"},{"location":"datadownload/#standard-dataset","text":"azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/NavierStokes2D_smoke\" \\ \"/mnt/data/\" --recursive","title":"Standard dataset"},{"location":"datadownload/#conditioning-dataset","text":"azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/NavierStokes2D_cond_smoke_v1\" \\ \"/mnt/data/\" --recursive","title":"Conditioning dataset"},{"location":"datadownload/#shallow-water-2d","text":"Generated using SpeedyWeather.jl . azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/ShallowWater2D\" \\ \"/mnt/data/\" --recursive","title":"Shallow water - 2D"},{"location":"datadownload/#maxwell-3d","text":"Generated using Python 3D FDTD Simulator . azcopy copy \"https://pdearenarelease.blob.core.windows.net/datasets/Maxwell2D\" \\ \"/mnt/data/\" --recursive","title":"Maxwell - 3D"},{"location":"datadownload/#pdebench","text":"PDEBench data can be downloaded with the included download_pdebenchdata.py script: For example to download the Incompressible Navier Stokes dataset: export DATAVERSE_URL = https://darus.uni-stuttgart.de ; python scripts/download_pdebenchdata.py \\ --outdir /mnt/data/PDEBench/ --limit ns_incom","title":"PDEBench"},{"location":"install/","text":"Installation Guide \u00a4 clone the repo git clone https://github.com/microsoft/pdearena conda docker create and activate env cd pdearena conda env create --file docker/environment.yml conda activate pdearena install this package # install so the project is in PYTHONPATH pip install -e . If you also want to do data generation: pip install -e \".[datagen]\" build docker container cd docker docker build -t pdearena . run docker container cd pdearena docker run --gpus all -it --rm --user $( id -u ) : $( id -g ) \\ -v $( pwd ) :/code -v /mnt/data:/data --workdir /code -e PYTHONPATH = /code \\ pdearena:latest Note --gpus all -it --rm --user $(id -u):$(id -g) : enables using all GPUs and runs an interactive session with current user's UID/GUID to avoid docker writing files as root. -v $(pwd):/code -v /mnt/data:/data --workdir /code : mounts current directory and data directory (i.e. the cloned git repo) to /code and /data respectively, and use the code directory as the current working directory.","title":"Installation"},{"location":"install/#installation-guide","text":"clone the repo git clone https://github.com/microsoft/pdearena conda docker create and activate env cd pdearena conda env create --file docker/environment.yml conda activate pdearena install this package # install so the project is in PYTHONPATH pip install -e . If you also want to do data generation: pip install -e \".[datagen]\" build docker container cd docker docker build -t pdearena . run docker container cd pdearena docker run --gpus all -it --rm --user $( id -u ) : $( id -g ) \\ -v $( pwd ) :/code -v /mnt/data:/data --workdir /code -e PYTHONPATH = /code \\ pdearena:latest Note --gpus all -it --rm --user $(id -u):$(id -g) : enables using all GPUs and runs an interactive session with current user's UID/GUID to avoid docker writing files as root. -v $(pwd):/code -v /mnt/data:/data --workdir /code : mounts current directory and data directory (i.e. the cloned git repo) to /code and /data respectively, and use the code directory as the current working directory.","title":"Installation Guide"},{"location":"modelzoo/","text":"Model Zoo \u00a4 Here we document the performance of various models currently implemented with PDEArena . The tables below provide results and useful statistics about training and inference. Model Name Num. Params Model Size (MB) Peak GPU Memory (MB) Forward Time (s) Forward+Backward Time (s) DilResNet128 DilResNet-128 4.2 M 16.7 4849.01 0.118 0.342 DilResNet-128-norm DilResNet-128-norm 4.2 M 16.7 6921.0 0.183 0.423 FNO128-8 modes16 FNO-128-16m 134 M 537.5 2950.0 0.059 0.172 FNO128-8 modes8 FNO-128-8m 33.7 M 134.9 2160.5 0.056 0.161 FNO128-4 modes16 FNOs-128-16m 67.2 M 268.8 1850.95 0.031 0.089 FNO128-4 modes32 FNOs-128-32m 268 M 1074.1 3416.53 0.036 0.118 FNO64-4 modes32 FNOs-64-32m 67.1 M 268.5 1204.57 0.016 0.050 FNO96-4 modes32 FNOs-96-32m 151 M 604.2 2179.0 0.026 0.080 ResNet128 ResNet-128 1.2 M 4.9 2491.01 0.043 0.093 ResNet256 ResNet-256 4.9 M 19.4 4941.51 0.118 0.261 U-F1Net modes16 U-FNet1-16m 160 M 643.6 4034.6 0.082 0.196 U-F1Net modes16 -1x1 U-FNet1-16m-1x1 160 M 643.6 4037.58 0.081 0.195 U-F1Net modes8 U-FNet1-8m 148 M 593.3 3934.09 0.081 0.195 U-F1Net modes8 -1x1 U-FNet1-8m-1x1 148 M 593.3 3936.99 0.081 0.194 U-F2Net modes16,8 U-FNet2-16m 175 M 700.5 4146.64 0.083 0.200 U-F2Net modes16,8 -1x1 U-FNet2-16m-1x1 175 M 700.5 4150.08 0.083 0.199 U-F2Net modes16,16 U-FNet2-16mc 219 M 876.7 4493.39 0.084 0.204 U-F2Net modes8,4 U-FNet2-8m 151 M 606.2 3961.9 0.082 0.198 U-F2Net modes8,4 -1x1 U-FNet2-8m-1x1 151 M 606.1 3961.2 0.082 0.197 U-F2Net modes8,8 U-FNet2-8mc 162 M 650.2 4046.27 0.082 0.199 U-F2Net att,modes16,8 U-FNet2attn-16m 179 M 717.3 4228.26 0.085 0.206 U-F2Net att,modes16,8 -1x1 U-FNet2attn-16m-1x1 179 M 717.3 4224.25 0.085 0.205 U-F3Net modes16,8,4 U-FNet3-16m 187 M 751.9 4246.78 0.083 0.203 U-F3Net modes16,8,4 -1x1 U-FNet3-16m-1x1 187 M 751.9 4249.58 0.083 0.201 U-F3Net modes8,4,2 U-FNet3-8m 164 M 657.5 4059.5 0.083 0.201 U-F3Net modes8,4,2 -1x1 U-FNet3-8m-1x1 164 M 657.5 4060.67 0.083 0.200 UNO128 UNO-128 440 M 1761.8 5511.0 0.158 0.341 UNO64 UNO-64 110 M 440.5 1931.67 0.065 0.134 U-Net 2015 128 Unet2015-128 124 M 496.5 3001.0 0.042 0.117 U-Net 2015 64 Unet2015-64 31.0 M 124.2 1303.97 0.013 0.037 U-Net base 128 Unetbase-128 124 M 496.6 2999.0 0.056 0.134 U-Net base 64 Unetbase-64 31.1 M 124.2 1276.35 0.021 0.046 U-Net mod 64 Unetmod-64 144 M 577.1 3904.68 0.079 0.186 U-Net mod 64-1x1 Unetmod-64-1x1 144 M 577.0 3907.24 0.079 0.185 U-Net att 64 Unetmodattn-64 148 M 593.9 3980.78 0.081 0.192 U-Net att 64-1x1 Unetmodattn-64-1x1 148 M 593.8 3976.78 0.081 0.191 Date Created : 2022-11-12 18:46:37.780512 GPU : Tesla V100-PCIE-16GB","title":"Model Zoo"},{"location":"modelzoo/#model-zoo","text":"Here we document the performance of various models currently implemented with PDEArena . The tables below provide results and useful statistics about training and inference. Model Name Num. Params Model Size (MB) Peak GPU Memory (MB) Forward Time (s) Forward+Backward Time (s) DilResNet128 DilResNet-128 4.2 M 16.7 4849.01 0.118 0.342 DilResNet-128-norm DilResNet-128-norm 4.2 M 16.7 6921.0 0.183 0.423 FNO128-8 modes16 FNO-128-16m 134 M 537.5 2950.0 0.059 0.172 FNO128-8 modes8 FNO-128-8m 33.7 M 134.9 2160.5 0.056 0.161 FNO128-4 modes16 FNOs-128-16m 67.2 M 268.8 1850.95 0.031 0.089 FNO128-4 modes32 FNOs-128-32m 268 M 1074.1 3416.53 0.036 0.118 FNO64-4 modes32 FNOs-64-32m 67.1 M 268.5 1204.57 0.016 0.050 FNO96-4 modes32 FNOs-96-32m 151 M 604.2 2179.0 0.026 0.080 ResNet128 ResNet-128 1.2 M 4.9 2491.01 0.043 0.093 ResNet256 ResNet-256 4.9 M 19.4 4941.51 0.118 0.261 U-F1Net modes16 U-FNet1-16m 160 M 643.6 4034.6 0.082 0.196 U-F1Net modes16 -1x1 U-FNet1-16m-1x1 160 M 643.6 4037.58 0.081 0.195 U-F1Net modes8 U-FNet1-8m 148 M 593.3 3934.09 0.081 0.195 U-F1Net modes8 -1x1 U-FNet1-8m-1x1 148 M 593.3 3936.99 0.081 0.194 U-F2Net modes16,8 U-FNet2-16m 175 M 700.5 4146.64 0.083 0.200 U-F2Net modes16,8 -1x1 U-FNet2-16m-1x1 175 M 700.5 4150.08 0.083 0.199 U-F2Net modes16,16 U-FNet2-16mc 219 M 876.7 4493.39 0.084 0.204 U-F2Net modes8,4 U-FNet2-8m 151 M 606.2 3961.9 0.082 0.198 U-F2Net modes8,4 -1x1 U-FNet2-8m-1x1 151 M 606.1 3961.2 0.082 0.197 U-F2Net modes8,8 U-FNet2-8mc 162 M 650.2 4046.27 0.082 0.199 U-F2Net att,modes16,8 U-FNet2attn-16m 179 M 717.3 4228.26 0.085 0.206 U-F2Net att,modes16,8 -1x1 U-FNet2attn-16m-1x1 179 M 717.3 4224.25 0.085 0.205 U-F3Net modes16,8,4 U-FNet3-16m 187 M 751.9 4246.78 0.083 0.203 U-F3Net modes16,8,4 -1x1 U-FNet3-16m-1x1 187 M 751.9 4249.58 0.083 0.201 U-F3Net modes8,4,2 U-FNet3-8m 164 M 657.5 4059.5 0.083 0.201 U-F3Net modes8,4,2 -1x1 U-FNet3-8m-1x1 164 M 657.5 4060.67 0.083 0.200 UNO128 UNO-128 440 M 1761.8 5511.0 0.158 0.341 UNO64 UNO-64 110 M 440.5 1931.67 0.065 0.134 U-Net 2015 128 Unet2015-128 124 M 496.5 3001.0 0.042 0.117 U-Net 2015 64 Unet2015-64 31.0 M 124.2 1303.97 0.013 0.037 U-Net base 128 Unetbase-128 124 M 496.6 2999.0 0.056 0.134 U-Net base 64 Unetbase-64 31.1 M 124.2 1276.35 0.021 0.046 U-Net mod 64 Unetmod-64 144 M 577.1 3904.68 0.079 0.186 U-Net mod 64-1x1 Unetmod-64-1x1 144 M 577.0 3907.24 0.079 0.185 U-Net att 64 Unetmodattn-64 148 M 593.9 3980.78 0.081 0.192 U-Net att 64-1x1 Unetmodattn-64-1x1 148 M 593.8 3976.78 0.081 0.191 Date Created : 2022-11-12 18:46:37.780512 GPU : Tesla V100-PCIE-16GB","title":"Model Zoo"},{"location":"repomap/","text":"Repository Map \u00a4 \ud83d\udcc1 pdearena/ \ud83d\udcc1 data/ # (1) \ud83d\udcc1 twod/ # (2) \ud83d\udcc1 datapipes/ \ud83d\udcc4 common.py # (3) ... # (4) \ud83d\udcc1 models/ \ud83d\udcc4 registry.py # (5) \ud83d\udcc4 pdemodel.py # (6) \ud83d\udcc4 cond_pdemode.py # (7) \ud83d\udcc1 modules/ #(8) \ud83d\udcc1 conditioned/ ... \ud83d\udcc4 twod_resnet.py \ud83d\udcc4 twod_unet2015.py \ud83d\udcc4 twod_unetbase.py \ud83d\udcc4 twod_unet.py \ud83d\udcc4 twod_uno.py \ud83d\udcc4 activations.py # (9) \ud83d\udcc4 loss.py # (10) ... \ud83d\udcc4 utils.py ... \ud83d\udcc1 pdedatagen/ \ud83d\udcc1 configs/ #(11) \ud83d\udcc1 shallowwater \ud83d\udcc4 navier_stokes.py \ud83d\udcc4 pde.py # (12) \ud83d\udcc1 scripts/ \ud83d\udcc4 train.py # (13) \ud83d\udcc4 cond_train.py # (14) \ud83d\udcc4 generate_data.py # (15) \ud83d\udcc4 convertnc2zarr.py # (16) \ud83d\udcc4 compute_normalization.py # (17) \ud83d\udcc1 configs/ # (18) Everything data loading related goes here. Currently we only have 2D data support. But should be easy enough to add appropriate mechanisms for 1D, 3D and beyond. Common data pipe tranformations useful for building training and evaluation pipelines. Dataset opening data pipes for individual datasets. Model registry. Remember to register your new model here. LightningModule to support standard PDE surrogate learning. LightningModule to support time and parameter conditioned PDE surrogate learning. All the network architectures go here. Activation function registry Currently supported loss functions Configuration files for PDE data generation Register your new PDE configurations here Main training script for standard PDE surrogate training and testing Main training script for conditioned PDE surrogate training and testing Main script for generating data Supporting script to convert netcdf files to zarr for faster data loading Supporting script to compute the data normalization statistics. Add normalization methods for your data here. pytorch-lightning configs to run experiments.","title":"Repo Map"},{"location":"repomap/#repository-map","text":"\ud83d\udcc1 pdearena/ \ud83d\udcc1 data/ # (1) \ud83d\udcc1 twod/ # (2) \ud83d\udcc1 datapipes/ \ud83d\udcc4 common.py # (3) ... # (4) \ud83d\udcc1 models/ \ud83d\udcc4 registry.py # (5) \ud83d\udcc4 pdemodel.py # (6) \ud83d\udcc4 cond_pdemode.py # (7) \ud83d\udcc1 modules/ #(8) \ud83d\udcc1 conditioned/ ... \ud83d\udcc4 twod_resnet.py \ud83d\udcc4 twod_unet2015.py \ud83d\udcc4 twod_unetbase.py \ud83d\udcc4 twod_unet.py \ud83d\udcc4 twod_uno.py \ud83d\udcc4 activations.py # (9) \ud83d\udcc4 loss.py # (10) ... \ud83d\udcc4 utils.py ... \ud83d\udcc1 pdedatagen/ \ud83d\udcc1 configs/ #(11) \ud83d\udcc1 shallowwater \ud83d\udcc4 navier_stokes.py \ud83d\udcc4 pde.py # (12) \ud83d\udcc1 scripts/ \ud83d\udcc4 train.py # (13) \ud83d\udcc4 cond_train.py # (14) \ud83d\udcc4 generate_data.py # (15) \ud83d\udcc4 convertnc2zarr.py # (16) \ud83d\udcc4 compute_normalization.py # (17) \ud83d\udcc1 configs/ # (18) Everything data loading related goes here. Currently we only have 2D data support. But should be easy enough to add appropriate mechanisms for 1D, 3D and beyond. Common data pipe tranformations useful for building training and evaluation pipelines. Dataset opening data pipes for individual datasets. Model registry. Remember to register your new model here. LightningModule to support standard PDE surrogate learning. LightningModule to support time and parameter conditioned PDE surrogate learning. All the network architectures go here. Activation function registry Currently supported loss functions Configuration files for PDE data generation Register your new PDE configurations here Main training script for standard PDE surrogate training and testing Main training script for conditioned PDE surrogate training and testing Main script for generating data Supporting script to convert netcdf files to zarr for faster data loading Supporting script to compute the data normalization statistics. Add normalization methods for your data here. pytorch-lightning configs to run experiments.","title":"Repository Map"},{"location":"research/","text":"Research \u00a4 Following is a list of research papers that have been published using the PDEArena framework. If you have used PDEArena in your research, and would like it listed here, please add your paper to this file by sending a pull request to the PDEArena repository . Towards Multi-spatiotemporal-scale Generalized PDE Modeling \u00a4 Jayesh K. Gupta 1 , Johannes Brandstetter 2 1 Microsoft Autonomous Systems and Robotics Research, 2 Microsoft Research AI4Science Abstract: Partial differential equations (PDEs) are central to describing complex physical system simulations. Their expensive solution techniques have led to an increased interest in deep neural network based surrogates. However, the practical utility of training such surrogates is contingent on their ability to model complex multi-scale spatio-temporal phenomena. Various neural network architectures have been proposed to target such phenomena, most notably Fourier Neural Operators (FNOs), which give a natural handle over local & global spatial information via parameterization of different Fourier modes, and U-Nets which treat local and global information via downsampling and upsampling paths. However, generalizing across different equation parameters or time-scales still remains a challenge. In this work, we make a comprehensive comparison between various FNO, ResNet, and U-Net like approaches to fluid mechanics problems in both vorticity-stream and velocity function form. For U-Nets, we transfer recent architectural improvements from computer vision, most notably from object segmentation and generative modeling. We further analyze the design considerations for using FNO layers to improve performance of U-Net architectures without major degradation of computational cost. Finally, we show promising results on generalization to different PDE parameters and time-scales with a single surrogate model. Clifford Neural Layers for PDE Modeling \u00a4 Johannes Brandstetter 1 , Rianne van den Berg 1 , Max Welling 1 , Jayesh K. Gupta 2 1 Microsoft Research AI4Science, 2 Microsoft Autonomous Systems and Robotics Research Abstract: Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates have become an active research topic to accelerate these simulations. However, current methods do not explicitly take into account the relationship between different fields and their internal components, which are often correlated. Viewing the time evolution of such correlated fields through the lens of multivector fields allows us to overcome these limitations. Multivector fields consist of scalar, vector, as well as higher-order components, such as bivectors and trivectors. Their algebraic properties, such as multiplication, addition and other arithmetic operations can be described by Clifford algebras. To our knowledge, this paper presents the first usage of such multivector representations together with Clifford convolutions and Clifford Fourier transforms in the context of deep learning. The resulting Clifford neural layers are universally applicable and will find direct use in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general. We empirically evaluate the benefit of Clifford neural layers by replacing convolution and Fourier operations in common neural PDE surrogates by their Clifford counterparts on two-dimensional Navier-Stokes and weather modeling tasks, as well as three-dimensional Maxwell equations. Clifford neural layers consistently improve generalization capabilities of the tested neural PDE surrogates.","title":"Research"},{"location":"research/#research","text":"Following is a list of research papers that have been published using the PDEArena framework. If you have used PDEArena in your research, and would like it listed here, please add your paper to this file by sending a pull request to the PDEArena repository .","title":"Research"},{"location":"research/#towards-multi-spatiotemporal-scale-generalized-pde-modeling","text":"Jayesh K. Gupta 1 , Johannes Brandstetter 2 1 Microsoft Autonomous Systems and Robotics Research, 2 Microsoft Research AI4Science Abstract: Partial differential equations (PDEs) are central to describing complex physical system simulations. Their expensive solution techniques have led to an increased interest in deep neural network based surrogates. However, the practical utility of training such surrogates is contingent on their ability to model complex multi-scale spatio-temporal phenomena. Various neural network architectures have been proposed to target such phenomena, most notably Fourier Neural Operators (FNOs), which give a natural handle over local & global spatial information via parameterization of different Fourier modes, and U-Nets which treat local and global information via downsampling and upsampling paths. However, generalizing across different equation parameters or time-scales still remains a challenge. In this work, we make a comprehensive comparison between various FNO, ResNet, and U-Net like approaches to fluid mechanics problems in both vorticity-stream and velocity function form. For U-Nets, we transfer recent architectural improvements from computer vision, most notably from object segmentation and generative modeling. We further analyze the design considerations for using FNO layers to improve performance of U-Net architectures without major degradation of computational cost. Finally, we show promising results on generalization to different PDE parameters and time-scales with a single surrogate model.","title":"Towards Multi-spatiotemporal-scale Generalized PDE Modeling"},{"location":"research/#clifford-neural-layers-for-pde-modeling","text":"Johannes Brandstetter 1 , Rianne van den Berg 1 , Max Welling 1 , Jayesh K. Gupta 2 1 Microsoft Research AI4Science, 2 Microsoft Autonomous Systems and Robotics Research Abstract: Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates have become an active research topic to accelerate these simulations. However, current methods do not explicitly take into account the relationship between different fields and their internal components, which are often correlated. Viewing the time evolution of such correlated fields through the lens of multivector fields allows us to overcome these limitations. Multivector fields consist of scalar, vector, as well as higher-order components, such as bivectors and trivectors. Their algebraic properties, such as multiplication, addition and other arithmetic operations can be described by Clifford algebras. To our knowledge, this paper presents the first usage of such multivector representations together with Clifford convolutions and Clifford Fourier transforms in the context of deep learning. The resulting Clifford neural layers are universally applicable and will find direct use in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general. We empirically evaluate the benefit of Clifford neural layers by replacing convolution and Fourier operations in common neural PDE surrogates by their Clifford counterparts on two-dimensional Navier-Stokes and weather modeling tasks, as well as three-dimensional Maxwell equations. Clifford neural layers consistently improve generalization capabilities of the tested neural PDE surrogates.","title":"Clifford Neural Layers for PDE Modeling"},{"location":"train/","text":"Training PDE surrogates \u00a4 Thanks to PyTorch Lightning , whether it's a single GPU experiment or multiple GPUs (even multiple nodes), setting up scalable training experiments should be fairly simple. Tip We recommend a warmup learning rate schedule for distributed training. Standard PDE Surrogate Learning \u00a4 python scripts/train.py -c <path/to/config> For example, to run modern U-Net on Navier Stokes dataset on 4 GPUs use: python scripts/train.py -c configs/navierstokes2d.yaml \\ --data.data_dir = /mnt/data/NavierStokes2D_smoke \\ --trainer.strategy = ddp --trainer.devices = 4 \\ --trainer.max_epochs = 50 \\ --data.batch_size = 8 \\ --data.time_gap = 0 --data.time_history = 4 --data.time_future = 1 \\ --model.name = Unetmod-64 \\ --model.lr = 2e-4 \\ --optimizer = AdamW --optimizer.lr = 2e-4 --optimizer.weight_decay = 1e-5 \\ --lr_scheduler = LinearWarmupCosineAnnealingLR \\ --lr_scheduler.warmup_epochs = 5 \\ --lr_scheduler.max_epochs = 50 --lr_scheduler.eta_min = 1e-7 Conditioned PDE Surrogate Learning \u00a4 python scripts/cond_train.py -c <path/to/config> For example, to run modern U-Net on Navier Stokes dataset on 4 GPUs use: python scripts/cond_train.py -c configs/cond_navierstokes2d.yaml \\ --data.data_dir = /mnt/data/NavierStokes2D_cond_smoke_v1 \\ --trainer.strategy = ddp --trainer.devices = 4 \\ --trainer.max_epochs = 50 \\ --data.batch_size = 8 \\ --model.name = Unetmod-64 \\ --model.lr = 2e-4 \\ --optimizer = AdamW --optimizer.lr = 2e-4 --optimizer.weight_decay = 1e-5 \\ --lr_scheduler = LinearWarmupCosineAnnealingLR \\ --lr_scheduler.warmup_epochs = 5 \\ --lr_scheduler.max_epochs = 50 --lr_scheduler.eta_min = 1e-7 Dataloading philosophy \u00a4 Use modern torchdata iterable datapipes as they scale better with cloud storage. Use equally sized shards for simpler scaling with PyTorch DDP.","title":"Training PDE Surrogates"},{"location":"train/#training-pde-surrogates","text":"Thanks to PyTorch Lightning , whether it's a single GPU experiment or multiple GPUs (even multiple nodes), setting up scalable training experiments should be fairly simple. Tip We recommend a warmup learning rate schedule for distributed training.","title":"Training PDE surrogates"},{"location":"train/#standard-pde-surrogate-learning","text":"python scripts/train.py -c <path/to/config> For example, to run modern U-Net on Navier Stokes dataset on 4 GPUs use: python scripts/train.py -c configs/navierstokes2d.yaml \\ --data.data_dir = /mnt/data/NavierStokes2D_smoke \\ --trainer.strategy = ddp --trainer.devices = 4 \\ --trainer.max_epochs = 50 \\ --data.batch_size = 8 \\ --data.time_gap = 0 --data.time_history = 4 --data.time_future = 1 \\ --model.name = Unetmod-64 \\ --model.lr = 2e-4 \\ --optimizer = AdamW --optimizer.lr = 2e-4 --optimizer.weight_decay = 1e-5 \\ --lr_scheduler = LinearWarmupCosineAnnealingLR \\ --lr_scheduler.warmup_epochs = 5 \\ --lr_scheduler.max_epochs = 50 --lr_scheduler.eta_min = 1e-7","title":"Standard PDE Surrogate Learning"},{"location":"train/#conditioned-pde-surrogate-learning","text":"python scripts/cond_train.py -c <path/to/config> For example, to run modern U-Net on Navier Stokes dataset on 4 GPUs use: python scripts/cond_train.py -c configs/cond_navierstokes2d.yaml \\ --data.data_dir = /mnt/data/NavierStokes2D_cond_smoke_v1 \\ --trainer.strategy = ddp --trainer.devices = 4 \\ --trainer.max_epochs = 50 \\ --data.batch_size = 8 \\ --model.name = Unetmod-64 \\ --model.lr = 2e-4 \\ --optimizer = AdamW --optimizer.lr = 2e-4 --optimizer.weight_decay = 1e-5 \\ --lr_scheduler = LinearWarmupCosineAnnealingLR \\ --lr_scheduler.warmup_epochs = 5 \\ --lr_scheduler.max_epochs = 50 --lr_scheduler.eta_min = 1e-7","title":"Conditioned PDE Surrogate Learning"},{"location":"train/#dataloading-philosophy","text":"Use modern torchdata iterable datapipes as they scale better with cloud storage. Use equally sized shards for simpler scaling with PyTorch DDP.","title":"Dataloading philosophy"},{"location":"reference/condmodules/","text":"Available conditioned PDE Surrogate Modules \u00a4 AttentionBlock \u00a4 Bases: nn . Module Attention block This is similar to transformer multi-head attention . Parameters: Name Type Description Default n_channels int the number of channels in the input required n_heads int the number of heads in multi-head attention 1 d_k Optional [ int ] the number of dimensions in each head None n_groups int the number of groups for group normalization 1 Source code in pdearena/modules/conditioned/twod_unet.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 class AttentionBlock ( nn . Module ): \"\"\"Attention block This is similar to [transformer multi-head attention](https://arxiv.org/abs/1706.03762). Args: n_channels: the number of channels in the input n_heads: the number of heads in multi-head attention d_k: the number of dimensions in each head n_groups: the number of groups for [group normalization][torch.nn.GroupNorm] \"\"\" def __init__ ( self , n_channels : int , n_heads : int = 1 , d_k : Optional [ int ] = None , n_groups : int = 1 ): \"\"\" \"\"\" super () . __init__ () # Default `d_k` if d_k is None : d_k = n_channels # Normalization layer self . norm = nn . GroupNorm ( n_groups , n_channels ) # Projections for query, key and values self . projection = nn . Linear ( n_channels , n_heads * d_k * 3 ) # Linear layer for final transformation self . output = nn . Linear ( n_heads * d_k , n_channels ) # Scale for dot-product attention self . scale = d_k **- 0.5 # self . n_heads = n_heads self . d_k = d_k def forward ( self , x : torch . Tensor ): # Get shape batch_size , n_channels , height , width = x . shape # Change `x` to shape `[batch_size, seq, n_channels]` x = x . view ( batch_size , n_channels , - 1 ) . permute ( 0 , 2 , 1 ) # Get query, key, and values (concatenated) and shape it to `[batch_size, seq, n_heads, 3 * d_k]` qkv = self . projection ( x ) . view ( batch_size , - 1 , self . n_heads , 3 * self . d_k ) # Split query, key, and values. Each of them will have shape `[batch_size, seq, n_heads, d_k]` q , k , v = torch . chunk ( qkv , 3 , dim =- 1 ) # Calculate scaled dot-product $\\frac{Q K^\\top}{\\sqrt{d_k}}$ attn = torch . einsum ( \"bihd,bjhd->bijh\" , q , k ) * self . scale # Softmax along the sequence dimension $\\underset{seq}{softmax}\\Bigg(\\frac{Q K^\\top}{\\sqrt{d_k}}\\Bigg)$ attn = attn . softmax ( dim = 1 ) # Multiply by values res = torch . einsum ( \"bijh,bjhd->bihd\" , attn , v ) # Reshape to `[batch_size, seq, n_heads * d_k]` res = res . view ( batch_size , - 1 , self . n_heads * self . d_k ) # Transform to `[batch_size, seq, n_channels]` res = self . output ( res ) # Add skip connection res += x # Change to shape `[batch_size, in_channels, height, width]` res = res . permute ( 0 , 2 , 1 ) . view ( batch_size , n_channels , height , width ) return res DownBlock \u00a4 Bases: ConditionedBlock Down block This combines ResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required cond_channels int Number of channels in the conditioning vector. required has_attn bool Whether to use attention block False activation nn . Module Activation function 'gelu' norm bool Whether to use normalization False use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 class DownBlock ( ConditionedBlock ): \"\"\"Down block This combines `ResidualBlock` and `AttentionBlock`. These are used in the first half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels cond_channels (int): Number of channels in the conditioning vector. has_attn (bool): Whether to use attention block activation (nn.Module): Activation function norm (bool): Whether to use normalization use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () self . res = ResidualBlock ( in_channels , out_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ): x = self . res ( x , emb ) x = self . attn ( x ) return x Downsample \u00a4 Bases: nn . Module Scale down the feature map by \\(\\frac{1}{2} \\times\\) Source code in pdearena/modules/conditioned/twod_unet.py 477 478 479 480 481 482 483 484 485 class Downsample ( nn . Module ): r \"\"\"Scale down the feature map by $\\frac{1}{2} \\times$\"\"\" def __init__ ( self , n_channels ): super () . __init__ () self . conv = nn . Conv2d ( n_channels , n_channels , ( 3 , 3 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x ) FourierDownBlock \u00a4 Bases: ConditionedBlock Down block This combines ResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Source code in pdearena/modules/conditioned/twod_unet.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 class FourierDownBlock ( ConditionedBlock ): \"\"\"Down block This combines `ResidualBlock` and `AttentionBlock`. These are used in the first half of U-Net at each resolution. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () self . res = FourierResidualBlock ( in_channels , out_channels , cond_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ): x = self . res ( x , emb ) x = self . attn ( x ) return x FourierResidualBlock \u00a4 Bases: ConditionedBlock Fourier Residual Block to be used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required cond_channels int Number of channels in the conditioning vector. required modes1 int Number of modes in the first dimension. 16 modes2 int Number of modes in the second dimension. 16 activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class FourierResidualBlock ( ConditionedBlock ): \"\"\"Fourier Residual Block to be used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. cond_channels (int): Number of channels in the conditioning vector. modes1 (int): Number of modes in the first dimension. modes2 (int): Number of modes in the second dimension. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , modes1 : int = 16 , modes2 : int = 16 , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , use_scale_shift_norm : bool = False , ): super () . __init__ () self . use_scale_shift_norm = use_scale_shift_norm if activation == \"gelu\" : self . activation = nn . GELU () elif activation == \"relu\" : self . activation = nn . ReLU () elif activation == \"silu\" : self . activation = nn . SiLU () else : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . modes1 = modes1 self . modes2 = modes2 self . fourier1 = SpectralConv2d ( in_channels , out_channels , cond_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) self . fourier2 = SpectralConv2d ( out_channels , out_channels , cond_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv2 = nn . Conv2d ( out_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) # self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)) # self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () self . cond_emb = nn . Linear ( cond_channels , 2 * out_channels if use_scale_shift_norm else out_channels ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ): h = self . activation ( self . norm1 ( x )) x1 = self . fourier1 ( h , emb ) x2 = self . conv1 ( h ) out = x1 + x2 emb_out = self . cond_emb ( emb ) while len ( emb_out . shape ) < len ( h . shape ): emb_out = emb_out [ ... , None ] if self . use_scale_shift_norm : scale , shift = torch . chunk ( emb_out , 2 , dim = 1 ) h = self . norm2 ( out ) * ( 1 + scale ) + shift # where we do -1 or +1 doesn't matter h = self . activation ( h ) x1 = self . fourier2 ( h , emb ) x2 = self . conv2 ( h ) else : out = out + emb_out out = self . activation ( self . norm2 ( out )) x1 = self . fourier2 ( out , emb ) x2 = self . conv2 ( out ) out = x1 + x2 + self . shortcut ( x ) return out FourierUnet \u00a4 Bases: nn . Module Unet with Fourier layers in early downsampling blocks. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of channels in the first layer. required activation str Activation function to use. required modes1 int Number of Fourier modes to use in the first spatial dimension. 12 modes2 int Number of Fourier modes to use in the second spatial dimension. 12 norm bool Whether to use normalization. False ch_mults list List of integers to multiply the number of channels by at each resolution. (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention at each resolution. (False, False, False, False) mid_attn bool Whether to use attention in the middle block. False n_blocks int Number of blocks to use at each resolution. 2 n_fourier_layers int Number of early downsampling layers to use Fourier layers in. 2 mode_scaling bool Whether to scale the number of modes with resolution. True param_conditioning Optional [ str ] Type of conditioning to use. Defaults to None. None use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). Defaults to False. False use1x1 bool Whether to use 1x1 convolutions in the initial and final layer. False Source code in pdearena/modules/conditioned/twod_unet.py 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 class FourierUnet ( nn . Module ): \"\"\"Unet with Fourier layers in early downsampling blocks. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of channels in the first layer. activation (str): Activation function to use. modes1 (int): Number of Fourier modes to use in the first spatial dimension. modes2 (int): Number of Fourier modes to use in the second spatial dimension. norm (bool): Whether to use normalization. ch_mults (list): List of integers to multiply the number of channels by at each resolution. is_attn (list): List of booleans indicating whether to use attention at each resolution. mid_attn (bool): Whether to use attention in the middle block. n_blocks (int): Number of blocks to use at each resolution. n_fourier_layers (int): Number of early downsampling layers to use Fourier layers in. mode_scaling (bool): Whether to scale the number of modes with resolution. param_conditioning (Optional[str]): Type of conditioning to use. Defaults to None. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). Defaults to False. use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layer. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , modes1 = 12 , modes2 = 12 , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , n_fourier_layers : int = 2 , mode_scaling : bool = True , param_conditioning : Optional [ str ] = None , use_scale_shift_norm : bool = False , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . param_conditioning = param_conditioning # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) time_embed_dim = hidden_channels * 4 self . time_embed = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) if self . param_conditioning is not None : if self . param_conditioning == \"scalar\" : self . pde_emb = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) else : raise NotImplementedError ( f \"param_conditioning { self . param_conditioning } not implemented\" ) # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] if i < n_fourier_layers : for _ in range ( n_blocks ): down . append ( FourierDownBlock ( in_channels , out_channels , time_embed_dim , modes1 = max ( modes1 // 2 ** i , 4 ) if mode_scaling else modes1 , modes2 = max ( modes2 // 2 ** i , 4 ) if mode_scaling else modes2 , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) in_channels = out_channels else : # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , time_embed_dim , has_attn = mid_attn , activation = activation , norm = norm ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) if use1x1 : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = 1 )) else : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 ))) def forward ( self , x : torch . Tensor , time , z = None ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C emb = self . time_embed ( fourier_embedding ( time , self . hidden_channels )) if z is not None : if self . param_conditioning == \"scalar\" : emb = emb + self . pde_emb ( fourier_embedding ( z , self . hidden_channels )) else : raise NotImplementedError ( f \"param_conditioning { self . param_conditioning } not implemented\" ) x = self . image_proj ( x ) h = [ x ] for m in self . down : if isinstance ( m , Downsample ): x = m ( x ) else : x = m ( x , emb ) h . append ( x ) x = self . middle ( x , emb ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x , emb ) x = self . final ( self . activation ( self . norm ( x ))) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) FourierUpBlock \u00a4 Bases: ConditionedBlock Up block This combines ResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Note We currently don't recommend using this block. Source code in pdearena/modules/conditioned/twod_unet.py 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 class FourierUpBlock ( ConditionedBlock ): \"\"\"Up block This combines `ResidualBlock` and `AttentionBlock`. These are used in the second half of U-Net at each resolution. Note: We currently don't recommend using this block. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = FourierResidualBlock ( in_channels + out_channels , out_channels , cond_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ): x = self . res ( x , emb ) x = self . attn ( x ) return x MiddleBlock \u00a4 Bases: ConditionedBlock Middle block It combines a ResidualBlock , AttentionBlock , followed by another ResidualBlock . This block is applied at the lowest resolution of the U-Net. Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required cond_channels int Number of channels in the conditioning vector. required has_attn bool Whether to use attention block. Defaults to False. False activation str Activation function to use. Defaults to \"gelu\". 'gelu' norm bool Whether to use normalization. Defaults to False. False use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). Defaults to False. False Source code in pdearena/modules/conditioned/twod_unet.py 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 class MiddleBlock ( ConditionedBlock ): \"\"\"Middle block It combines a `ResidualBlock`, `AttentionBlock`, followed by another `ResidualBlock`. This block is applied at the lowest resolution of the U-Net. Args: n_channels (int): Number of channels in the input and output. cond_channels (int): Number of channels in the conditioning vector. has_attn (bool, optional): Whether to use attention block. Defaults to False. activation (str): Activation function to use. Defaults to \"gelu\". norm (bool, optional): Whether to use normalization. Defaults to False. use_scale_shift_norm (bool, optional): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). Defaults to False. \"\"\" def __init__ ( self , n_channels : int , cond_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () self . res1 = ResidualBlock ( n_channels , n_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) self . attn = AttentionBlock ( n_channels ) if has_attn else nn . Identity () self . res2 = ResidualBlock ( n_channels , n_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ) -> torch . Tensor : x = self . res1 ( x , emb ) x = self . attn ( x ) x = self . res2 ( x , emb ) return x ResidualBlock \u00a4 Bases: ConditionedBlock Wide Residual Blocks used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required cond_channels int Number of channels in the conditioning vector. required activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 class ResidualBlock ( ConditionedBlock ): \"\"\"Wide Residual Blocks used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. cond_channels (int): Number of channels in the conditioning vector. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , use_scale_shift_norm : bool = False , ): super () . __init__ () self . use_scale_shift_norm = use_scale_shift_norm if activation == \"gelu\" : self . activation = nn . GELU () elif activation == \"relu\" : self . activation = nn . ReLU () elif activation == \"silu\" : self . activation = nn . SiLU () else : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) self . conv2 = zero_module ( nn . Conv2d ( out_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 ))) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () self . cond_emb = nn . Linear ( cond_channels , 2 * out_channels if use_scale_shift_norm else out_channels ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ): # First convolution layer h = self . conv1 ( self . activation ( self . norm1 ( x ))) emb_out = self . cond_emb ( emb ) while len ( emb_out . shape ) < len ( h . shape ): emb_out = emb_out [ ... , None ] if self . use_scale_shift_norm : scale , shift = torch . chunk ( emb_out , 2 , dim = 1 ) h = self . norm2 ( h ) * ( 1 + scale ) + shift # where we do -1 or +1 doesn't matter h = self . conv2 ( self . activation ( h )) else : h = h + emb_out # Second convolution layer h = self . conv2 ( self . activation ( self . norm2 ( h ))) # Add the shortcut connection and return return h + self . shortcut ( x ) Unet \u00a4 Bases: nn . Module Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input required time_future int Number of time steps in the output required hidden_channels int Number of channels in the hidden layers required activation str Activation function to use required norm bool Whether to use normalization False ch_mults list List of channel multipliers for each resolution (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention blocks (False, False, False, False) mid_attn bool Whether to use attention block in the middle block False n_blocks int Number of residual blocks in each resolution 2 param_conditioning Optional [ str ] Type of conditioning to use. Defaults to None. None use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). Defaults to False. False use1x1 bool Whether to use 1x1 convolutions in the initial and final layers False Note Currently, only scalar parameter conditioning is supported. Source code in pdearena/modules/conditioned/twod_unet.py 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 class Unet ( nn . Module ): \"\"\"Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input time_future (int): Number of time steps in the output hidden_channels (int): Number of channels in the hidden layers activation (str): Activation function to use norm (bool): Whether to use normalization ch_mults (list): List of channel multipliers for each resolution is_attn (list): List of booleans indicating whether to use attention blocks mid_attn (bool): Whether to use attention block in the middle block n_blocks (int): Number of residual blocks in each resolution param_conditioning (Optional[str]): Type of conditioning to use. Defaults to None. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). Defaults to False. use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layers Note: Currently, only `scalar` parameter conditioning is supported. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history , time_future , hidden_channels , activation , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , param_conditioning : Optional [ str ] = None , use_scale_shift_norm : bool = False , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation = activation self . param_conditioning = param_conditioning self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels time_embed_dim = hidden_channels * 4 self . time_embed = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) if self . param_conditioning is not None : if self . param_conditioning == \"scalar\" : self . pde_emb = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) else : raise NotImplementedError ( f \"Param conditioning { self . param_conditioning } not implemented\" ) # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , time_embed_dim , has_attn = mid_attn , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) if use1x1 : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = 1 )) else : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 ))) def forward ( self , x : torch . Tensor , time , z = None ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C emb = self . time_embed ( fourier_embedding ( time , self . hidden_channels )) if z is not None : if self . param_conditioning == \"scalar\" : emb = emb + self . pde_emb ( fourier_embedding ( z , self . hidden_channels )) else : raise NotImplementedError ( f \"Param conditioning { self . param_conditioning } not implemented\" ) x = self . image_proj ( x ) h = [ x ] for m in self . down : if isinstance ( m , Downsample ): x = m ( x ) else : x = m ( x , emb ) h . append ( x ) x = self . middle ( x , emb ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x , emb ) x = self . final ( self . activation ( self . norm ( x ))) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) UpBlock \u00a4 Bases: ConditionedBlock Up block This combines ResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required cond_channels int Number of channels in the conditioning vector. required has_attn bool Whether to use attention block False activation str Activation function 'gelu' norm bool Whether to use normalization False use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 class UpBlock ( ConditionedBlock ): \"\"\"Up block This combines `ResidualBlock` and `AttentionBlock`. These are used in the second half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels cond_channels (int): Number of channels in the conditioning vector. has_attn (bool): Whether to use attention block activation (str): Activation function norm (bool): Whether to use normalization use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = ResidualBlock ( in_channels + out_channels , out_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ) -> torch . Tensor : x = self . res ( x , emb ) x = self . attn ( x ) return x Upsample \u00a4 Bases: nn . Module Scale up the feature map by \\(2 \\times\\) Source code in pdearena/modules/conditioned/twod_unet.py 466 467 468 469 470 471 472 473 474 class Upsample ( nn . Module ): r \"\"\"Scale up the feature map by $2 \\times$\"\"\" def __init__ ( self , n_channels : int ): super () . __init__ () self . conv = nn . ConvTranspose2d ( n_channels , n_channels , ( 4 , 4 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x ) ConditionedBlock \u00a4 Bases: nn . Module Source code in pdearena/modules/conditioned/condition_utils.py 39 40 41 42 class ConditionedBlock ( nn . Module ): @abstractmethod def forward ( self , x , emb ): \"\"\"Apply the module to `x` given `emb` embdding of time or others.\"\"\" forward ( x , emb ) abstractmethod \u00a4 Apply the module to x given emb embdding of time or others. Source code in pdearena/modules/conditioned/condition_utils.py 40 41 42 @abstractmethod def forward ( self , x , emb ): \"\"\"Apply the module to `x` given `emb` embdding of time or others.\"\"\" fourier_embedding ( timesteps , dim , max_period = 10000 ) \u00a4 Create sinusoidal timestep embeddings. Parameters: Name Type Description Default timesteps a 1-D Tensor of N indices, one per batch element. These may be fractional. required dim int the dimension of the output. required max_period int controls the minimum frequency of the embeddings. 10000 Returns: Name Type Description embedding torch . Tensor [N \\(\\times\\) dim] Tensor of positional embeddings. Source code in pdearena/modules/conditioned/condition_utils.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def fourier_embedding ( timesteps , dim , max_period = 10000 ): r \"\"\"Create sinusoidal timestep embeddings. Args: timesteps: a 1-D Tensor of N indices, one per batch element. These may be fractional. dim (int): the dimension of the output. max_period (int): controls the minimum frequency of the embeddings. Returns: embedding (torch.Tensor): [N $\\times$ dim] Tensor of positional embeddings. \"\"\" half = dim // 2 freqs = torch . exp ( - math . log ( max_period ) * torch . arange ( start = 0 , end = half , dtype = torch . float32 ) / half ) . to ( device = timesteps . device ) args = timesteps [:, None ] . float () * freqs [ None ] embedding = torch . cat ([ torch . cos ( args ), torch . sin ( args )], dim =- 1 ) if dim % 2 : embedding = torch . cat ([ embedding , torch . zeros_like ( embedding [:, : 1 ])], dim =- 1 ) return embedding zero_module ( module ) \u00a4 Zero out the parameters of a module and return it. Source code in pdearena/modules/conditioned/condition_utils.py 10 11 12 13 14 def zero_module ( module ): \"\"\"Zero out the parameters of a module and return it.\"\"\" for p in module . parameters (): p . detach () . zero_ () return module","title":"Conditioned Architecture Modules"},{"location":"reference/condmodules/#available-conditioned-pde-surrogate-modules","text":"","title":"Available conditioned PDE Surrogate Modules"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.AttentionBlock","text":"Bases: nn . Module Attention block This is similar to transformer multi-head attention . Parameters: Name Type Description Default n_channels int the number of channels in the input required n_heads int the number of heads in multi-head attention 1 d_k Optional [ int ] the number of dimensions in each head None n_groups int the number of groups for group normalization 1 Source code in pdearena/modules/conditioned/twod_unet.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 class AttentionBlock ( nn . Module ): \"\"\"Attention block This is similar to [transformer multi-head attention](https://arxiv.org/abs/1706.03762). Args: n_channels: the number of channels in the input n_heads: the number of heads in multi-head attention d_k: the number of dimensions in each head n_groups: the number of groups for [group normalization][torch.nn.GroupNorm] \"\"\" def __init__ ( self , n_channels : int , n_heads : int = 1 , d_k : Optional [ int ] = None , n_groups : int = 1 ): \"\"\" \"\"\" super () . __init__ () # Default `d_k` if d_k is None : d_k = n_channels # Normalization layer self . norm = nn . GroupNorm ( n_groups , n_channels ) # Projections for query, key and values self . projection = nn . Linear ( n_channels , n_heads * d_k * 3 ) # Linear layer for final transformation self . output = nn . Linear ( n_heads * d_k , n_channels ) # Scale for dot-product attention self . scale = d_k **- 0.5 # self . n_heads = n_heads self . d_k = d_k def forward ( self , x : torch . Tensor ): # Get shape batch_size , n_channels , height , width = x . shape # Change `x` to shape `[batch_size, seq, n_channels]` x = x . view ( batch_size , n_channels , - 1 ) . permute ( 0 , 2 , 1 ) # Get query, key, and values (concatenated) and shape it to `[batch_size, seq, n_heads, 3 * d_k]` qkv = self . projection ( x ) . view ( batch_size , - 1 , self . n_heads , 3 * self . d_k ) # Split query, key, and values. Each of them will have shape `[batch_size, seq, n_heads, d_k]` q , k , v = torch . chunk ( qkv , 3 , dim =- 1 ) # Calculate scaled dot-product $\\frac{Q K^\\top}{\\sqrt{d_k}}$ attn = torch . einsum ( \"bihd,bjhd->bijh\" , q , k ) * self . scale # Softmax along the sequence dimension $\\underset{seq}{softmax}\\Bigg(\\frac{Q K^\\top}{\\sqrt{d_k}}\\Bigg)$ attn = attn . softmax ( dim = 1 ) # Multiply by values res = torch . einsum ( \"bijh,bjhd->bihd\" , attn , v ) # Reshape to `[batch_size, seq, n_heads * d_k]` res = res . view ( batch_size , - 1 , self . n_heads * self . d_k ) # Transform to `[batch_size, seq, n_channels]` res = self . output ( res ) # Add skip connection res += x # Change to shape `[batch_size, in_channels, height, width]` res = res . permute ( 0 , 2 , 1 ) . view ( batch_size , n_channels , height , width ) return res","title":"AttentionBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.DownBlock","text":"Bases: ConditionedBlock Down block This combines ResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required cond_channels int Number of channels in the conditioning vector. required has_attn bool Whether to use attention block False activation nn . Module Activation function 'gelu' norm bool Whether to use normalization False use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 class DownBlock ( ConditionedBlock ): \"\"\"Down block This combines `ResidualBlock` and `AttentionBlock`. These are used in the first half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels cond_channels (int): Number of channels in the conditioning vector. has_attn (bool): Whether to use attention block activation (nn.Module): Activation function norm (bool): Whether to use normalization use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () self . res = ResidualBlock ( in_channels , out_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ): x = self . res ( x , emb ) x = self . attn ( x ) return x","title":"DownBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.Downsample","text":"Bases: nn . Module Scale down the feature map by \\(\\frac{1}{2} \\times\\) Source code in pdearena/modules/conditioned/twod_unet.py 477 478 479 480 481 482 483 484 485 class Downsample ( nn . Module ): r \"\"\"Scale down the feature map by $\\frac{1}{2} \\times$\"\"\" def __init__ ( self , n_channels ): super () . __init__ () self . conv = nn . Conv2d ( n_channels , n_channels , ( 3 , 3 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x )","title":"Downsample"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.FourierDownBlock","text":"Bases: ConditionedBlock Down block This combines ResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Source code in pdearena/modules/conditioned/twod_unet.py 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 class FourierDownBlock ( ConditionedBlock ): \"\"\"Down block This combines `ResidualBlock` and `AttentionBlock`. These are used in the first half of U-Net at each resolution. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () self . res = FourierResidualBlock ( in_channels , out_channels , cond_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ): x = self . res ( x , emb ) x = self . attn ( x ) return x","title":"FourierDownBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.FourierResidualBlock","text":"Bases: ConditionedBlock Fourier Residual Block to be used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required cond_channels int Number of channels in the conditioning vector. required modes1 int Number of modes in the first dimension. 16 modes2 int Number of modes in the second dimension. 16 activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class FourierResidualBlock ( ConditionedBlock ): \"\"\"Fourier Residual Block to be used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. cond_channels (int): Number of channels in the conditioning vector. modes1 (int): Number of modes in the first dimension. modes2 (int): Number of modes in the second dimension. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , modes1 : int = 16 , modes2 : int = 16 , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , use_scale_shift_norm : bool = False , ): super () . __init__ () self . use_scale_shift_norm = use_scale_shift_norm if activation == \"gelu\" : self . activation = nn . GELU () elif activation == \"relu\" : self . activation = nn . ReLU () elif activation == \"silu\" : self . activation = nn . SiLU () else : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . modes1 = modes1 self . modes2 = modes2 self . fourier1 = SpectralConv2d ( in_channels , out_channels , cond_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) self . fourier2 = SpectralConv2d ( out_channels , out_channels , cond_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv2 = nn . Conv2d ( out_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) # self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)) # self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () self . cond_emb = nn . Linear ( cond_channels , 2 * out_channels if use_scale_shift_norm else out_channels ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ): h = self . activation ( self . norm1 ( x )) x1 = self . fourier1 ( h , emb ) x2 = self . conv1 ( h ) out = x1 + x2 emb_out = self . cond_emb ( emb ) while len ( emb_out . shape ) < len ( h . shape ): emb_out = emb_out [ ... , None ] if self . use_scale_shift_norm : scale , shift = torch . chunk ( emb_out , 2 , dim = 1 ) h = self . norm2 ( out ) * ( 1 + scale ) + shift # where we do -1 or +1 doesn't matter h = self . activation ( h ) x1 = self . fourier2 ( h , emb ) x2 = self . conv2 ( h ) else : out = out + emb_out out = self . activation ( self . norm2 ( out )) x1 = self . fourier2 ( out , emb ) x2 = self . conv2 ( out ) out = x1 + x2 + self . shortcut ( x ) return out","title":"FourierResidualBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.FourierUnet","text":"Bases: nn . Module Unet with Fourier layers in early downsampling blocks. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of channels in the first layer. required activation str Activation function to use. required modes1 int Number of Fourier modes to use in the first spatial dimension. 12 modes2 int Number of Fourier modes to use in the second spatial dimension. 12 norm bool Whether to use normalization. False ch_mults list List of integers to multiply the number of channels by at each resolution. (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention at each resolution. (False, False, False, False) mid_attn bool Whether to use attention in the middle block. False n_blocks int Number of blocks to use at each resolution. 2 n_fourier_layers int Number of early downsampling layers to use Fourier layers in. 2 mode_scaling bool Whether to scale the number of modes with resolution. True param_conditioning Optional [ str ] Type of conditioning to use. Defaults to None. None use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). Defaults to False. False use1x1 bool Whether to use 1x1 convolutions in the initial and final layer. False Source code in pdearena/modules/conditioned/twod_unet.py 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 class FourierUnet ( nn . Module ): \"\"\"Unet with Fourier layers in early downsampling blocks. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of channels in the first layer. activation (str): Activation function to use. modes1 (int): Number of Fourier modes to use in the first spatial dimension. modes2 (int): Number of Fourier modes to use in the second spatial dimension. norm (bool): Whether to use normalization. ch_mults (list): List of integers to multiply the number of channels by at each resolution. is_attn (list): List of booleans indicating whether to use attention at each resolution. mid_attn (bool): Whether to use attention in the middle block. n_blocks (int): Number of blocks to use at each resolution. n_fourier_layers (int): Number of early downsampling layers to use Fourier layers in. mode_scaling (bool): Whether to scale the number of modes with resolution. param_conditioning (Optional[str]): Type of conditioning to use. Defaults to None. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). Defaults to False. use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layer. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , modes1 = 12 , modes2 = 12 , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , n_fourier_layers : int = 2 , mode_scaling : bool = True , param_conditioning : Optional [ str ] = None , use_scale_shift_norm : bool = False , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . param_conditioning = param_conditioning # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) time_embed_dim = hidden_channels * 4 self . time_embed = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) if self . param_conditioning is not None : if self . param_conditioning == \"scalar\" : self . pde_emb = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) else : raise NotImplementedError ( f \"param_conditioning { self . param_conditioning } not implemented\" ) # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] if i < n_fourier_layers : for _ in range ( n_blocks ): down . append ( FourierDownBlock ( in_channels , out_channels , time_embed_dim , modes1 = max ( modes1 // 2 ** i , 4 ) if mode_scaling else modes1 , modes2 = max ( modes2 // 2 ** i , 4 ) if mode_scaling else modes2 , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) in_channels = out_channels else : # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , time_embed_dim , has_attn = mid_attn , activation = activation , norm = norm ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) if use1x1 : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = 1 )) else : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 ))) def forward ( self , x : torch . Tensor , time , z = None ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C emb = self . time_embed ( fourier_embedding ( time , self . hidden_channels )) if z is not None : if self . param_conditioning == \"scalar\" : emb = emb + self . pde_emb ( fourier_embedding ( z , self . hidden_channels )) else : raise NotImplementedError ( f \"param_conditioning { self . param_conditioning } not implemented\" ) x = self . image_proj ( x ) h = [ x ] for m in self . down : if isinstance ( m , Downsample ): x = m ( x ) else : x = m ( x , emb ) h . append ( x ) x = self . middle ( x , emb ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x , emb ) x = self . final ( self . activation ( self . norm ( x ))) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] )","title":"FourierUnet"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.FourierUpBlock","text":"Bases: ConditionedBlock Up block This combines ResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Note We currently don't recommend using this block. Source code in pdearena/modules/conditioned/twod_unet.py 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 class FourierUpBlock ( ConditionedBlock ): \"\"\"Up block This combines `ResidualBlock` and `AttentionBlock`. These are used in the second half of U-Net at each resolution. Note: We currently don't recommend using this block. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = FourierResidualBlock ( in_channels + out_channels , out_channels , cond_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ): x = self . res ( x , emb ) x = self . attn ( x ) return x","title":"FourierUpBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.MiddleBlock","text":"Bases: ConditionedBlock Middle block It combines a ResidualBlock , AttentionBlock , followed by another ResidualBlock . This block is applied at the lowest resolution of the U-Net. Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required cond_channels int Number of channels in the conditioning vector. required has_attn bool Whether to use attention block. Defaults to False. False activation str Activation function to use. Defaults to \"gelu\". 'gelu' norm bool Whether to use normalization. Defaults to False. False use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). Defaults to False. False Source code in pdearena/modules/conditioned/twod_unet.py 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 class MiddleBlock ( ConditionedBlock ): \"\"\"Middle block It combines a `ResidualBlock`, `AttentionBlock`, followed by another `ResidualBlock`. This block is applied at the lowest resolution of the U-Net. Args: n_channels (int): Number of channels in the input and output. cond_channels (int): Number of channels in the conditioning vector. has_attn (bool, optional): Whether to use attention block. Defaults to False. activation (str): Activation function to use. Defaults to \"gelu\". norm (bool, optional): Whether to use normalization. Defaults to False. use_scale_shift_norm (bool, optional): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). Defaults to False. \"\"\" def __init__ ( self , n_channels : int , cond_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () self . res1 = ResidualBlock ( n_channels , n_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) self . attn = AttentionBlock ( n_channels ) if has_attn else nn . Identity () self . res2 = ResidualBlock ( n_channels , n_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ) -> torch . Tensor : x = self . res1 ( x , emb ) x = self . attn ( x ) x = self . res2 ( x , emb ) return x","title":"MiddleBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.ResidualBlock","text":"Bases: ConditionedBlock Wide Residual Blocks used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required cond_channels int Number of channels in the conditioning vector. required activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 class ResidualBlock ( ConditionedBlock ): \"\"\"Wide Residual Blocks used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. cond_channels (int): Number of channels in the conditioning vector. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , use_scale_shift_norm : bool = False , ): super () . __init__ () self . use_scale_shift_norm = use_scale_shift_norm if activation == \"gelu\" : self . activation = nn . GELU () elif activation == \"relu\" : self . activation = nn . ReLU () elif activation == \"silu\" : self . activation = nn . SiLU () else : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) self . conv2 = zero_module ( nn . Conv2d ( out_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 ))) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () self . cond_emb = nn . Linear ( cond_channels , 2 * out_channels if use_scale_shift_norm else out_channels ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ): # First convolution layer h = self . conv1 ( self . activation ( self . norm1 ( x ))) emb_out = self . cond_emb ( emb ) while len ( emb_out . shape ) < len ( h . shape ): emb_out = emb_out [ ... , None ] if self . use_scale_shift_norm : scale , shift = torch . chunk ( emb_out , 2 , dim = 1 ) h = self . norm2 ( h ) * ( 1 + scale ) + shift # where we do -1 or +1 doesn't matter h = self . conv2 ( self . activation ( h )) else : h = h + emb_out # Second convolution layer h = self . conv2 ( self . activation ( self . norm2 ( h ))) # Add the shortcut connection and return return h + self . shortcut ( x )","title":"ResidualBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.Unet","text":"Bases: nn . Module Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input required time_future int Number of time steps in the output required hidden_channels int Number of channels in the hidden layers required activation str Activation function to use required norm bool Whether to use normalization False ch_mults list List of channel multipliers for each resolution (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention blocks (False, False, False, False) mid_attn bool Whether to use attention block in the middle block False n_blocks int Number of residual blocks in each resolution 2 param_conditioning Optional [ str ] Type of conditioning to use. Defaults to None. None use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). Defaults to False. False use1x1 bool Whether to use 1x1 convolutions in the initial and final layers False Note Currently, only scalar parameter conditioning is supported. Source code in pdearena/modules/conditioned/twod_unet.py 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 class Unet ( nn . Module ): \"\"\"Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input time_future (int): Number of time steps in the output hidden_channels (int): Number of channels in the hidden layers activation (str): Activation function to use norm (bool): Whether to use normalization ch_mults (list): List of channel multipliers for each resolution is_attn (list): List of booleans indicating whether to use attention blocks mid_attn (bool): Whether to use attention block in the middle block n_blocks (int): Number of residual blocks in each resolution param_conditioning (Optional[str]): Type of conditioning to use. Defaults to None. use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). Defaults to False. use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layers Note: Currently, only `scalar` parameter conditioning is supported. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history , time_future , hidden_channels , activation , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , param_conditioning : Optional [ str ] = None , use_scale_shift_norm : bool = False , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation = activation self . param_conditioning = param_conditioning self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels time_embed_dim = hidden_channels * 4 self . time_embed = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) if self . param_conditioning is not None : if self . param_conditioning == \"scalar\" : self . pde_emb = nn . Sequential ( nn . Linear ( hidden_channels , time_embed_dim ), self . activation , nn . Linear ( time_embed_dim , time_embed_dim ), ) else : raise NotImplementedError ( f \"Param conditioning { self . param_conditioning } not implemented\" ) # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , time_embed_dim , has_attn = mid_attn , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , time_embed_dim , has_attn = is_attn [ i ], activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) ) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) if use1x1 : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = 1 )) else : self . final = zero_module ( nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 ))) def forward ( self , x : torch . Tensor , time , z = None ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C emb = self . time_embed ( fourier_embedding ( time , self . hidden_channels )) if z is not None : if self . param_conditioning == \"scalar\" : emb = emb + self . pde_emb ( fourier_embedding ( z , self . hidden_channels )) else : raise NotImplementedError ( f \"Param conditioning { self . param_conditioning } not implemented\" ) x = self . image_proj ( x ) h = [ x ] for m in self . down : if isinstance ( m , Downsample ): x = m ( x ) else : x = m ( x , emb ) h . append ( x ) x = self . middle ( x , emb ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x , emb ) x = self . final ( self . activation ( self . norm ( x ))) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] )","title":"Unet"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.UpBlock","text":"Bases: ConditionedBlock Up block This combines ResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required cond_channels int Number of channels in the conditioning vector. required has_attn bool Whether to use attention block False activation str Activation function 'gelu' norm bool Whether to use normalization False use_scale_shift_norm bool Whether to use scale and shift approach to conditoning (also termed as AdaGN ). False Source code in pdearena/modules/conditioned/twod_unet.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 class UpBlock ( ConditionedBlock ): \"\"\"Up block This combines `ResidualBlock` and `AttentionBlock`. These are used in the second half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels cond_channels (int): Number of channels in the conditioning vector. has_attn (bool): Whether to use attention block activation (str): Activation function norm (bool): Whether to use normalization use_scale_shift_norm (bool): Whether to use scale and shift approach to conditoning (also termed as `AdaGN`). \"\"\" def __init__ ( self , in_channels : int , out_channels : int , cond_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , use_scale_shift_norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = ResidualBlock ( in_channels + out_channels , out_channels , cond_channels , activation = activation , norm = norm , use_scale_shift_norm = use_scale_shift_norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor , emb : torch . Tensor ) -> torch . Tensor : x = self . res ( x , emb ) x = self . attn ( x ) return x","title":"UpBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.twod_unet.Upsample","text":"Bases: nn . Module Scale up the feature map by \\(2 \\times\\) Source code in pdearena/modules/conditioned/twod_unet.py 466 467 468 469 470 471 472 473 474 class Upsample ( nn . Module ): r \"\"\"Scale up the feature map by $2 \\times$\"\"\" def __init__ ( self , n_channels : int ): super () . __init__ () self . conv = nn . ConvTranspose2d ( n_channels , n_channels , ( 4 , 4 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x )","title":"Upsample"},{"location":"reference/condmodules/#pdearena.modules.modules.condition_utils.ConditionedBlock","text":"Bases: nn . Module Source code in pdearena/modules/conditioned/condition_utils.py 39 40 41 42 class ConditionedBlock ( nn . Module ): @abstractmethod def forward ( self , x , emb ): \"\"\"Apply the module to `x` given `emb` embdding of time or others.\"\"\"","title":"ConditionedBlock"},{"location":"reference/condmodules/#pdearena.modules.modules.condition_utils.ConditionedBlock.forward","text":"Apply the module to x given emb embdding of time or others. Source code in pdearena/modules/conditioned/condition_utils.py 40 41 42 @abstractmethod def forward ( self , x , emb ): \"\"\"Apply the module to `x` given `emb` embdding of time or others.\"\"\"","title":"forward()"},{"location":"reference/condmodules/#pdearena.modules.modules.condition_utils.fourier_embedding","text":"Create sinusoidal timestep embeddings. Parameters: Name Type Description Default timesteps a 1-D Tensor of N indices, one per batch element. These may be fractional. required dim int the dimension of the output. required max_period int controls the minimum frequency of the embeddings. 10000 Returns: Name Type Description embedding torch . Tensor [N \\(\\times\\) dim] Tensor of positional embeddings. Source code in pdearena/modules/conditioned/condition_utils.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def fourier_embedding ( timesteps , dim , max_period = 10000 ): r \"\"\"Create sinusoidal timestep embeddings. Args: timesteps: a 1-D Tensor of N indices, one per batch element. These may be fractional. dim (int): the dimension of the output. max_period (int): controls the minimum frequency of the embeddings. Returns: embedding (torch.Tensor): [N $\\times$ dim] Tensor of positional embeddings. \"\"\" half = dim // 2 freqs = torch . exp ( - math . log ( max_period ) * torch . arange ( start = 0 , end = half , dtype = torch . float32 ) / half ) . to ( device = timesteps . device ) args = timesteps [:, None ] . float () * freqs [ None ] embedding = torch . cat ([ torch . cos ( args ), torch . sin ( args )], dim =- 1 ) if dim % 2 : embedding = torch . cat ([ embedding , torch . zeros_like ( embedding [:, : 1 ])], dim =- 1 ) return embedding","title":"fourier_embedding()"},{"location":"reference/condmodules/#pdearena.modules.modules.condition_utils.zero_module","text":"Zero out the parameters of a module and return it. Source code in pdearena/modules/conditioned/condition_utils.py 10 11 12 13 14 def zero_module ( module ): \"\"\"Zero out the parameters of a module and return it.\"\"\" for p in module . parameters (): p . detach () . zero_ () return module","title":"zero_module()"},{"location":"reference/dataload/","text":"DataModules \u00a4 pdearena.data.datamodule \u00a4 PDEDataModule \u00a4 Bases: LightningDataModule Defines the standard dataloading process for PDE data. Does not support generaliztion to different parameterizations or time. Consider using pdearena.data.cond_datamodule.CondPDEDataModule for that. Parameters: Name Type Description Default task str The task to be solved. required data_dir str The path to the data directory. required time_history int The number of time steps in the past. required time_future int The number of time steps in the future. required time_gap int The number of time steps between the past and the future to be skipped. required pde dict The PDE to be solved. required batch_size int The batch size. required pin_memory bool Whether to pin memory. required num_workers int The number of workers. Make sure when using values greater than 1 on multi-GPU systems, the number of shards is divisible by the number of workers times number of GPUs. required train_limit_trajectories int The number of trajectories to be used for training. This is from each shard. required valid_limit_trajectories int The number of trajectories to be used for validation. This is from each shard. required test_limit_trajectories int The number of trajectories to be used for testing. This is from each shard. required usegrid bool Whether to use a grid. Defaults to False. False Source code in pdearena/data/datamodule.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 class PDEDataModule ( LightningDataModule ): \"\"\"Defines the standard dataloading process for PDE data. Does not support generaliztion to different parameterizations or time. Consider using [pdearena.data.cond_datamodule.CondPDEDataModule][] for that. Args: task (str): The task to be solved. data_dir (str): The path to the data directory. time_history (int): The number of time steps in the past. time_future (int): The number of time steps in the future. time_gap (int): The number of time steps between the past and the future to be skipped. pde (dict): The PDE to be solved. batch_size (int): The batch size. pin_memory (bool): Whether to pin memory. num_workers (int): The number of workers. Make sure when using values greater than 1 on multi-GPU systems, the number of shards is divisible by the number of workers times number of GPUs. train_limit_trajectories (int): The number of trajectories to be used for training. This is from each shard. valid_limit_trajectories (int): The number of trajectories to be used for validation. This is from each shard. test_limit_trajectories (int): The number of trajectories to be used for testing. This is from each shard. usegrid (bool, optional): Whether to use a grid. Defaults to False. \"\"\" def __init__ ( self , task : str , data_dir : str , time_history : int , time_future : int , time_gap : int , pde : PDEDataConfig , batch_size : int , pin_memory : bool , num_workers : int , train_limit_trajectories : int , valid_limit_trajectories : int , test_limit_trajectories : int , usegrid : bool = False , ): super () . __init__ () self . data_dir = data_dir self . pde = pde self . save_hyperparameters ( ignore = \"pde\" , logger = False ) def setup ( self , stage : Optional [ str ] = None ): dps = DATAPIPE_REGISTRY [ self . hparams . task ] self . train_dp = dps [ \"train\" ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . train_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . valid_dp1 = dps [ \"valid\" ][ 0 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . valid_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . valid_dp2 = dps [ \"valid\" ][ 1 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . valid_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . test_dp_onestep = dps [ \"test\" ][ 0 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . test_dp = dps [ \"test\" ][ 1 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) def train_dataloader ( self ): return DataLoader ( dataset = self . train_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = True , drop_last = True , collate_fn = collate_fn_cat , ) def val_dataloader ( self ): timestep_loader = DataLoader ( dataset = self . valid_dp1 , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) rollout_loader = DataLoader ( dataset = self . valid_dp2 , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , # TODO: might need to reduce this shuffle = False , collate_fn = collate_fn_stack , ) return [ timestep_loader , rollout_loader ] def test_dataloader ( self ): rollout_loader = DataLoader ( dataset = self . test_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_stack , ) timestep_loader = DataLoader ( dataset = self . test_dp_onestep , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) return [ timestep_loader , rollout_loader ] pdearena.data.cond_datamodule \u00a4 CondPDEDataModule \u00a4 Bases: LightningDataModule Definest the dataloading process for conditioned PDE data. Supports generalization experiments. Parameters: Name Type Description Default task str Name of the task. required data_dir str Path to the data directory. required pde dict Dictionary containing the PDE class and its arguments. required batch_size int Batch size. required pin_memory bool Whether to pin memory. required num_workers int Number of workers. required train_limit_trajectories int Number of trajectories to use for training. required valid_limit_trajectories int Number of trajectories to use for validation. required test_limit_trajectories int Number of trajectories to use for testing. required eval_dts List [ int ] List of timesteps to use for evaluation. Defaults to [1, 2, 4, 8, 16]. [1, 2, 4, 8, 16] usegrid bool Whether to use the grid. Defaults to False. False Source code in pdearena/data/cond_datamodule.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 class CondPDEDataModule ( LightningDataModule ): \"\"\"Definest the dataloading process for conditioned PDE data. Supports generalization experiments. Args: task (str): Name of the task. data_dir (str): Path to the data directory. pde (dict): Dictionary containing the PDE class and its arguments. batch_size (int): Batch size. pin_memory (bool): Whether to pin memory. num_workers (int): Number of workers. train_limit_trajectories (int): Number of trajectories to use for training. valid_limit_trajectories (int): Number of trajectories to use for validation. test_limit_trajectories (int): Number of trajectories to use for testing. eval_dts (List[int], optional): List of timesteps to use for evaluation. Defaults to [1, 2, 4, 8, 16]. usegrid (bool, optional): Whether to use the grid. Defaults to False. \"\"\" def __init__ ( self , task : str , data_dir : str , pde : PDEDataConfig , batch_size : int , pin_memory : bool , num_workers : int , train_limit_trajectories : int , valid_limit_trajectories : int , test_limit_trajectories : int , eval_dts : List [ int ] = [ 1 , 2 , 4 , 8 , 16 ], usegrid : bool = False , ): super () . __init__ () self . data_dir = data_dir self . eval_dts = eval_dts self . pde = pde self . save_hyperparameters ( ignore = \"pde\" , logger = False ) # if \"Weather\" in pde[\"class_path\"]: # self.dataset_opener = WeatherDatasetOpener # self.randomized_traindatapipe = RandomTimeStepPDETrainData # self.evaldatapipe = TimestepPDEEvalData # # self.train_filter = _weathertrain_filter # # self.valid_filter = _weathervalid_filter # # self.test_filter = _weathertest_filter # self.lister = lambda x: dp.iter.IterableWrapper( # map(lambda y: os.path.join(self.data_dir, y), os.listdir(x)) # ) # self.sharder = lambda x: x # elif len(self.pde.grid_size) == 3: # self.dataset_opener = NavierStokesDatasetOpener # self.randomized_traindatapipe = RandomTimeStepPDETrainData # self.evaldatapipe = TimestepPDEEvalData # self.train_filter = _train_filter # self.valid_filter = _valid_filter # self.test_filter = _test_filter # self.lister = dp.iter.FileLister # self.sharder = dp.iter.ShardingFilter # else: # raise NotImplementedError() def setup ( self , stage = None ): dps = DATAPIPE_REGISTRY [ self . hparams . task ] self . train_dp = dps [ \"train\" ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . train_limit_trajectories , usegrid = self . hparams . usegrid , time_history = 1 , time_future = 1 , time_gap = 0 , ) self . valid_dps = [ dps [ \"valid\" ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . valid_limit_trajectories , usegrid = False , time_history = 1 , time_future = 1 , time_gap = 0 , delta_t = dt , ) for dt in self . eval_dts ] self . test_dp = dps [ \"test\" ][ 1 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = self . hparams . usegrid , time_history = 1 , time_future = 1 , time_gap = 0 , ) self . test_dps = [ dps [ \"test\" ][ 0 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = False , time_history = 1 , time_future = 1 , time_gap = 0 , delta_t = dt , ) for dt in self . eval_dts ] def train_dataloader ( self ): return DataLoader ( dataset = self . train_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = True , drop_last = True , collate_fn = collate_fn_cat , ) def val_dataloader ( self ): timestep_loaders = [ DataLoader ( dataset = dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) for dp in self . valid_dps ] return timestep_loaders def test_dataloader ( self ): rollout_loader = DataLoader ( dataset = self . test_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_stack , ) timestep_loader = [ DataLoader ( dataset = dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) for dp in self . test_dps ] return [ rollout_loader ] + timestep_loader","title":"Data Loading"},{"location":"reference/dataload/#datamodules","text":"","title":"DataModules"},{"location":"reference/dataload/#pdearena.data.datamodule","text":"","title":"datamodule"},{"location":"reference/dataload/#pdearena.data.datamodule.PDEDataModule","text":"Bases: LightningDataModule Defines the standard dataloading process for PDE data. Does not support generaliztion to different parameterizations or time. Consider using pdearena.data.cond_datamodule.CondPDEDataModule for that. Parameters: Name Type Description Default task str The task to be solved. required data_dir str The path to the data directory. required time_history int The number of time steps in the past. required time_future int The number of time steps in the future. required time_gap int The number of time steps between the past and the future to be skipped. required pde dict The PDE to be solved. required batch_size int The batch size. required pin_memory bool Whether to pin memory. required num_workers int The number of workers. Make sure when using values greater than 1 on multi-GPU systems, the number of shards is divisible by the number of workers times number of GPUs. required train_limit_trajectories int The number of trajectories to be used for training. This is from each shard. required valid_limit_trajectories int The number of trajectories to be used for validation. This is from each shard. required test_limit_trajectories int The number of trajectories to be used for testing. This is from each shard. required usegrid bool Whether to use a grid. Defaults to False. False Source code in pdearena/data/datamodule.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 class PDEDataModule ( LightningDataModule ): \"\"\"Defines the standard dataloading process for PDE data. Does not support generaliztion to different parameterizations or time. Consider using [pdearena.data.cond_datamodule.CondPDEDataModule][] for that. Args: task (str): The task to be solved. data_dir (str): The path to the data directory. time_history (int): The number of time steps in the past. time_future (int): The number of time steps in the future. time_gap (int): The number of time steps between the past and the future to be skipped. pde (dict): The PDE to be solved. batch_size (int): The batch size. pin_memory (bool): Whether to pin memory. num_workers (int): The number of workers. Make sure when using values greater than 1 on multi-GPU systems, the number of shards is divisible by the number of workers times number of GPUs. train_limit_trajectories (int): The number of trajectories to be used for training. This is from each shard. valid_limit_trajectories (int): The number of trajectories to be used for validation. This is from each shard. test_limit_trajectories (int): The number of trajectories to be used for testing. This is from each shard. usegrid (bool, optional): Whether to use a grid. Defaults to False. \"\"\" def __init__ ( self , task : str , data_dir : str , time_history : int , time_future : int , time_gap : int , pde : PDEDataConfig , batch_size : int , pin_memory : bool , num_workers : int , train_limit_trajectories : int , valid_limit_trajectories : int , test_limit_trajectories : int , usegrid : bool = False , ): super () . __init__ () self . data_dir = data_dir self . pde = pde self . save_hyperparameters ( ignore = \"pde\" , logger = False ) def setup ( self , stage : Optional [ str ] = None ): dps = DATAPIPE_REGISTRY [ self . hparams . task ] self . train_dp = dps [ \"train\" ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . train_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . valid_dp1 = dps [ \"valid\" ][ 0 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . valid_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . valid_dp2 = dps [ \"valid\" ][ 1 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . valid_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . test_dp_onestep = dps [ \"test\" ][ 0 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) self . test_dp = dps [ \"test\" ][ 1 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = self . hparams . usegrid , time_history = self . hparams . time_history , time_future = self . hparams . time_future , time_gap = self . hparams . time_gap , ) def train_dataloader ( self ): return DataLoader ( dataset = self . train_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = True , drop_last = True , collate_fn = collate_fn_cat , ) def val_dataloader ( self ): timestep_loader = DataLoader ( dataset = self . valid_dp1 , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) rollout_loader = DataLoader ( dataset = self . valid_dp2 , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , # TODO: might need to reduce this shuffle = False , collate_fn = collate_fn_stack , ) return [ timestep_loader , rollout_loader ] def test_dataloader ( self ): rollout_loader = DataLoader ( dataset = self . test_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_stack , ) timestep_loader = DataLoader ( dataset = self . test_dp_onestep , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) return [ timestep_loader , rollout_loader ]","title":"PDEDataModule"},{"location":"reference/dataload/#pdearena.data.cond_datamodule","text":"","title":"cond_datamodule"},{"location":"reference/dataload/#pdearena.data.cond_datamodule.CondPDEDataModule","text":"Bases: LightningDataModule Definest the dataloading process for conditioned PDE data. Supports generalization experiments. Parameters: Name Type Description Default task str Name of the task. required data_dir str Path to the data directory. required pde dict Dictionary containing the PDE class and its arguments. required batch_size int Batch size. required pin_memory bool Whether to pin memory. required num_workers int Number of workers. required train_limit_trajectories int Number of trajectories to use for training. required valid_limit_trajectories int Number of trajectories to use for validation. required test_limit_trajectories int Number of trajectories to use for testing. required eval_dts List [ int ] List of timesteps to use for evaluation. Defaults to [1, 2, 4, 8, 16]. [1, 2, 4, 8, 16] usegrid bool Whether to use the grid. Defaults to False. False Source code in pdearena/data/cond_datamodule.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 class CondPDEDataModule ( LightningDataModule ): \"\"\"Definest the dataloading process for conditioned PDE data. Supports generalization experiments. Args: task (str): Name of the task. data_dir (str): Path to the data directory. pde (dict): Dictionary containing the PDE class and its arguments. batch_size (int): Batch size. pin_memory (bool): Whether to pin memory. num_workers (int): Number of workers. train_limit_trajectories (int): Number of trajectories to use for training. valid_limit_trajectories (int): Number of trajectories to use for validation. test_limit_trajectories (int): Number of trajectories to use for testing. eval_dts (List[int], optional): List of timesteps to use for evaluation. Defaults to [1, 2, 4, 8, 16]. usegrid (bool, optional): Whether to use the grid. Defaults to False. \"\"\" def __init__ ( self , task : str , data_dir : str , pde : PDEDataConfig , batch_size : int , pin_memory : bool , num_workers : int , train_limit_trajectories : int , valid_limit_trajectories : int , test_limit_trajectories : int , eval_dts : List [ int ] = [ 1 , 2 , 4 , 8 , 16 ], usegrid : bool = False , ): super () . __init__ () self . data_dir = data_dir self . eval_dts = eval_dts self . pde = pde self . save_hyperparameters ( ignore = \"pde\" , logger = False ) # if \"Weather\" in pde[\"class_path\"]: # self.dataset_opener = WeatherDatasetOpener # self.randomized_traindatapipe = RandomTimeStepPDETrainData # self.evaldatapipe = TimestepPDEEvalData # # self.train_filter = _weathertrain_filter # # self.valid_filter = _weathervalid_filter # # self.test_filter = _weathertest_filter # self.lister = lambda x: dp.iter.IterableWrapper( # map(lambda y: os.path.join(self.data_dir, y), os.listdir(x)) # ) # self.sharder = lambda x: x # elif len(self.pde.grid_size) == 3: # self.dataset_opener = NavierStokesDatasetOpener # self.randomized_traindatapipe = RandomTimeStepPDETrainData # self.evaldatapipe = TimestepPDEEvalData # self.train_filter = _train_filter # self.valid_filter = _valid_filter # self.test_filter = _test_filter # self.lister = dp.iter.FileLister # self.sharder = dp.iter.ShardingFilter # else: # raise NotImplementedError() def setup ( self , stage = None ): dps = DATAPIPE_REGISTRY [ self . hparams . task ] self . train_dp = dps [ \"train\" ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . train_limit_trajectories , usegrid = self . hparams . usegrid , time_history = 1 , time_future = 1 , time_gap = 0 , ) self . valid_dps = [ dps [ \"valid\" ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . valid_limit_trajectories , usegrid = False , time_history = 1 , time_future = 1 , time_gap = 0 , delta_t = dt , ) for dt in self . eval_dts ] self . test_dp = dps [ \"test\" ][ 1 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = self . hparams . usegrid , time_history = 1 , time_future = 1 , time_gap = 0 , ) self . test_dps = [ dps [ \"test\" ][ 0 ]( pde = self . pde , data_path = self . data_dir , limit_trajectories = self . hparams . test_limit_trajectories , usegrid = False , time_history = 1 , time_future = 1 , time_gap = 0 , delta_t = dt , ) for dt in self . eval_dts ] def train_dataloader ( self ): return DataLoader ( dataset = self . train_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = True , drop_last = True , collate_fn = collate_fn_cat , ) def val_dataloader ( self ): timestep_loaders = [ DataLoader ( dataset = dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) for dp in self . valid_dps ] return timestep_loaders def test_dataloader ( self ): rollout_loader = DataLoader ( dataset = self . test_dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_stack , ) timestep_loader = [ DataLoader ( dataset = dp , num_workers = self . hparams . num_workers , pin_memory = self . hparams . pin_memory , batch_size = self . hparams . batch_size , shuffle = False , collate_fn = collate_fn_cat , ) for dp in self . test_dps ] return [ rollout_loader ] + timestep_loader","title":"CondPDEDataModule"},{"location":"reference/datapipes/","text":"Datapipes \u00a4 pdearena.data.twod.datapipes.common \u00a4 RandomTimeStepConditionedPDETrainData \u00a4 Bases: dp . iter . IterDataPipe Randomized data for training conditioned PDEs. Parameters: Name Type Description Default dp IterDataPipe Data pipe that returns individual PDE trajectories. required n_input_scalar_components int Number of input scalar components. required n_input_vector_components int Number of input vector components. required n_output_scalar_components int Number of output scalar components. required n_output_vector_components int Number of output vector components. required trajlen int Length of a trajectory in the dataset. required reweigh bool Whether to rebalance the dataset so that longer horizon predictions get equal weightage despite there being fewer actual such datapoints in a trajectory. Defaults to True. True Source code in pdearena/data/twod/datapipes/common.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 class RandomTimeStepConditionedPDETrainData ( dp . iter . IterDataPipe ): \"\"\"Randomized data for training conditioned PDEs. Args: dp (IterDataPipe): Data pipe that returns individual PDE trajectories. n_input_scalar_components (int): Number of input scalar components. n_input_vector_components (int): Number of input vector components. n_output_scalar_components (int): Number of output scalar components. n_output_vector_components (int): Number of output vector components. trajlen (int): Length of a trajectory in the dataset. reweigh (bool, optional): Whether to rebalance the dataset so that longer horizon predictions get equal weightage despite there being fewer actual such datapoints in a trajectory. Defaults to True. \"\"\" def __init__ ( self , dp , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , trajlen : int , reweigh = True , ) -> None : super () . __init__ () self . dp = dp self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . trajlen = trajlen self . reweigh = reweigh def __iter__ ( self ): time_resolution = self . trajlen for ( u , v , cond , grid ) in self . dp : if self . reweigh : end_time = random . choices ( range ( 1 , time_resolution ), k = 1 )[ 0 ] start_time = random . choices ( range ( 0 , end_time ), weights = 1 / np . arange ( 1 , end_time + 1 ), k = 1 )[ 0 ] else : end_time = torch . randint ( low = 1 , high = time_resolution , size = ( 1 ,), dtype = torch . long ) . item () start_time = torch . randint ( low = 0 , high = end_time . item (), size = ( 1 ,), dtype = torch . long ) . item () delta_t = end_time - start_time yield ( * datautils . create_time_conditioned_data ( self . n_input_scalar_components , self . n_input_vector_components , self . n_output_scalar_components , self . n_output_vector_components , u , v , grid , start_time , end_time , torch . tensor ([ delta_t ]), ), cond , ) RandomizedPDETrainData \u00a4 Bases: dp . iter . IterDataPipe Randomized data for training PDEs. Parameters: Name Type Description Default dp IterDataPipe Data pipe that returns individual PDE trajectories. required n_input_scalar_components int Number of input scalar components. required n_input_vector_components int Number of input vector components. required n_output_scalar_components int Number of output scalar components. required n_output_vector_components int Number of output vector components. required trajlen int Length of a trajectory in the dataset. required time_history int Number of time steps of inputs. required time_future int Number of time steps of outputs. required time_gap int Number of time steps between inputs and outputs. required Source code in pdearena/data/twod/datapipes/common.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 class RandomizedPDETrainData ( dp . iter . IterDataPipe ): \"\"\"Randomized data for training PDEs. Args: dp (IterDataPipe): Data pipe that returns individual PDE trajectories. n_input_scalar_components (int): Number of input scalar components. n_input_vector_components (int): Number of input vector components. n_output_scalar_components (int): Number of output scalar components. n_output_vector_components (int): Number of output vector components. trajlen (int): Length of a trajectory in the dataset. time_history (int): Number of time steps of inputs. time_future (int): Number of time steps of outputs. time_gap (int): Number of time steps between inputs and outputs. \"\"\" def __init__ ( self , dp , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , trajlen : int , time_history : int , time_future : int , time_gap : int , ) -> None : super () . __init__ () self . dp = dp self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . trajlen = trajlen self . time_history = time_history self . time_future = time_future self . time_gap = time_gap def __iter__ ( self ): # Length of trajectory time_resolution = self . trajlen # Max number of previous points solver can eat reduced_time_resolution = time_resolution - self . time_history # Number of future points to predict max_start_time = reduced_time_resolution - self . time_future - self . time_gap for batch in self . dp : if len ( batch ) == 3 : ( u , v , grid ) = batch cond = None elif len ( batch ) == 4 : ( u , v , cond , grid ) = batch else : raise ValueError ( f \"Unknown batch length of { len ( batch ) } .\" ) # Choose initial random time point at the PDE solution manifold start_time = random . choices ([ t for t in range ( max_start_time + 1 )], k = 1 ) yield datautils . create_data2D ( self . n_input_scalar_components , self . n_input_vector_components , self . n_output_scalar_components , self . n_output_vector_components , u , v , grid , start_time [ 0 ], self . time_history , self . time_future , self . time_gap , ) TimestepConditionedPDEEvalData \u00a4 Bases: dp . iter . IterDataPipe Data for evaluation of time conditioned PDEs Parameters: Name Type Description Default dp torchdata . datapipes . iter . IterDataPipe Data pipe that returns individual PDE trajectories. required trajlen int Length of a trajectory in the dataset. required delta_t int Evaluates predictions conditioned at that delta_t. required Tip Make sure delta_t is less than half of trajlen . Source code in pdearena/data/twod/datapipes/common.py 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class TimestepConditionedPDEEvalData ( dp . iter . IterDataPipe ): \"\"\"Data for evaluation of time conditioned PDEs Args: dp (torchdata.datapipes.iter.IterDataPipe): Data pipe that returns individual PDE trajectories. trajlen (int): Length of a trajectory in the dataset. delta_t (int): Evaluates predictions conditioned at that delta_t. Tip: Make sure `delta_t` is less than half of `trajlen`. \"\"\" def __init__ ( self , dp : dp . iter . IterDataPipe , trajlen : int , delta_t : int ) -> None : super () . __init__ () self . dp = dp self . trajlen = trajlen if 2 * delta_t >= self . trajlen : raise ValueError ( \"delta_t should be less than half the trajectory length\" ) self . delta_t = delta_t def __iter__ ( self ): for begin in range ( self . trajlen - self . delta_t ): for ( u , v , cond , grid ) in self . dp : newu = u [ begin :: self . delta_t , ... ] newv = v [ begin :: self . delta_t , ... ] max_start_time = newu . size ( 0 ) for start in range ( max_start_time - 1 ): end = start + 1 data = torch . cat (( newu [ start : start + 1 ], newv [ start : start + 1 ]), dim = 1 ) . unsqueeze ( 0 ) if grid is not None : data = torch . cat (( data , grid ), dim = 1 ) label = torch . cat (( newu [ end : end + 1 ], newv [ end : end + 1 ]), dim = 1 ) . unsqueeze ( 0 ) if data . size ( 1 ) == 0 : raise ValueError ( \"Data is empty. Likely indexing issue.\" ) if label . size ( 1 ) == 0 : raise ValueError ( \"Label is empty. Likely indexing issue.\" ) yield data , label , torch . tensor ([ self . delta_t ]), cond ZarrLister \u00a4 Bases: dp . iter . IterDataPipe Customized lister for zarr files. Parameters: Name Type Description Default root Union [ str , Sequence [ str ], dp . iter . IterDataPipe ] Root directory. Defaults to \".\". '.' Yields: Type Description str Path to the zarr file. Source code in pdearena/data/twod/datapipes/common.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 class ZarrLister ( dp . iter . IterDataPipe ): \"\"\"Customized lister for zarr files. Args: root (Union[str, Sequence[str], dp.iter.IterDataPipe], optional): Root directory. Defaults to \".\". Yields: (str): Path to the zarr file. \"\"\" def __init__ ( self , root : Union [ str , Sequence [ str ], dp . iter . IterDataPipe ] = \".\" , ) -> None : super () . __init__ () if isinstance ( root , str ): root = [ root ] if not isinstance ( root , dp . iter . IterDataPipe ): root = dp . iter . IterableWrapper ( root ) self . datapipe : dp . iter . IterDataPipe = root def __iter__ ( self ): for path in self . datapipe : for dirname in os . listdir ( path ): if dirname . endswith ( \".zarr\" ): yield os . path . join ( path , dirname ) build_datapipes ( pde , data_path , limit_trajectories , usegrid , dataset_opener , lister , sharder , filter_fn , mode , time_history = 1 , time_future = 1 , time_gap = 0 , onestep = False , conditioned = False , delta_t = None , conditioned_reweigh = True ) \u00a4 Build datapipes for training and evaluation. Parameters: Name Type Description Default pde PDEDataConfig PDE configuration. required data_path str Path to the data. required limit_trajectories int Number of trajectories to use. required usegrid bool Whether to use spatial grid as input. required dataset_opener Callable [..., dp . iter . IterDataPipe ] Dataset opener. required lister Callable [..., dp . iter . IterDataPipe ] List files. required sharder Callable [..., dp . iter . IterDataPipe ] Shard files. required filter_fn Callable [..., dp . iter . IterDataPipe ] Filter files. required mode str Mode of the data. [\"train\", \"valid\", \"test\"] required time_history int Number of time steps in the past. Defaults to 1. 1 time_future int Number of time steps in the future. Defaults to 1. 1 time_gap int Number of time steps between the past and the future to be skipped. Defaults to 0. 0 onestep bool Whether to use one-step prediction. Defaults to False. False conditioned bool Whether to use conditioned data. Defaults to False. False delta_t Optional [ int ] Time step size. Defaults to None. Only used for conditioned data. None conditioned_reweigh bool Whether to reweight conditioned data. Defaults to True. True Returns: Name Type Description dpipe IterDataPipe IterDataPipe for training and evaluation. Source code in pdearena/data/twod/datapipes/common.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def build_datapipes ( pde : PDEDataConfig , data_path , limit_trajectories , usegrid : bool , dataset_opener : Callable [ ... , dp . iter . IterDataPipe ], lister : Callable [ ... , dp . iter . IterDataPipe ], sharder : Callable [ ... , dp . iter . IterDataPipe ], filter_fn : Callable [ ... , dp . iter . IterDataPipe ], mode : str , time_history = 1 , time_future = 1 , time_gap = 0 , onestep = False , conditioned = False , delta_t : Optional [ int ] = None , conditioned_reweigh : bool = True , ): \"\"\"Build datapipes for training and evaluation. Args: pde (PDEDataConfig): PDE configuration. data_path (str): Path to the data. limit_trajectories (int): Number of trajectories to use. usegrid (bool): Whether to use spatial grid as input. dataset_opener (Callable[..., dp.iter.IterDataPipe]): Dataset opener. lister (Callable[..., dp.iter.IterDataPipe]): List files. sharder (Callable[..., dp.iter.IterDataPipe]): Shard files. filter_fn (Callable[..., dp.iter.IterDataPipe]): Filter files. mode (str): Mode of the data. [\"train\", \"valid\", \"test\"] time_history (int, optional): Number of time steps in the past. Defaults to 1. time_future (int, optional): Number of time steps in the future. Defaults to 1. time_gap (int, optional): Number of time steps between the past and the future to be skipped. Defaults to 0. onestep (bool, optional): Whether to use one-step prediction. Defaults to False. conditioned (bool, optional): Whether to use conditioned data. Defaults to False. delta_t (Optional[int], optional): Time step size. Defaults to None. Only used for conditioned data. conditioned_reweigh (bool, optional): Whether to reweight conditioned data. Defaults to True. Returns: dpipe (IterDataPipe): IterDataPipe for training and evaluation. \"\"\" dpipe = lister ( data_path , ) . filter ( filter_fn = filter_fn ) if mode == \"train\" : dpipe = dpipe . shuffle () dpipe = dataset_opener ( sharder ( dpipe ), mode = mode , limit_trajectories = limit_trajectories , usegrid = usegrid , ) if mode == \"train\" : # Make sure that in expectation we have seen all the data despite randomization dpipe = dpipe . cycle ( pde . trajlen ) if mode == \"train\" : # Training data is randomized if conditioned : dpipe = RandomTimeStepConditionedPDETrainData ( dpipe , pde . n_scalar_components , pde . n_vector_components , pde . n_scalar_components , pde . n_vector_components , pde . trajlen , conditioned_reweigh , ) else : dpipe = RandomizedPDETrainData ( dpipe , pde . n_scalar_components , pde . n_vector_components , pde . n_scalar_components , pde . n_vector_components , pde . trajlen , time_history , time_future , time_gap , ) else : # Evaluation data is not randomized. if conditioned and onestep : assert delta_t is not None dpipe = TimestepConditionedPDEEvalData ( dpipe , pde . trajlen , delta_t ) elif onestep : dpipe = PDEEvalTimeStepData ( dpipe , pde . n_scalar_components , pde . n_vector_components , pde . n_scalar_components , pde . n_vector_components , pde . trajlen , time_history , time_future , time_gap , ) return dpipe pdearena.data.twod.datapipes.navierstokes2d \u00a4 NavierStokesDatasetOpener \u00a4 Bases: dp . iter . IterDataPipe DataPipe to load Navier-Stokes dataset. Parameters: Name Type Description Default dp dp . iter . IterDataPipe List of hdf5 files containing Navier-Stokes data. required mode str Mode to load data from. Can be one of train , val , test . required limit_trajectories int Limit the number of trajectories to load from individual hdf5 file. Defaults to None. None usegrid bool Whether to output spatial grid or not. Defaults to False. False Yields: Type Description Tuple [ torch . Tensor , torch . Tensor , Optional [ torch . Tensor ], Optional [ torch . Tensor ]] Tuple containing particle scalar field, velocity vector field, and optionally buoyancy force parameter value and spatial grid. Source code in pdearena/data/twod/datapipes/navierstokes2d.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class NavierStokesDatasetOpener ( dp . iter . IterDataPipe ): \"\"\"DataPipe to load Navier-Stokes dataset. Args: dp (dp.iter.IterDataPipe): List of `hdf5` files containing Navier-Stokes data. mode (str): Mode to load data from. Can be one of `train`, `val`, `test`. limit_trajectories (int, optional): Limit the number of trajectories to load from individual `hdf5` file. Defaults to None. usegrid (bool, optional): Whether to output spatial grid or not. Defaults to False. Yields: (Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor]]): Tuple containing particle scalar field, velocity vector field, and optionally buoyancy force parameter value and spatial grid. \"\"\" def __init__ ( self , dp , mode : str , limit_trajectories : Optional [ int ] = None , usegrid : bool = False ) -> None : super () . __init__ () self . dp = dp self . mode = mode self . limit_trajectories = limit_trajectories self . usegrid = usegrid def __iter__ ( self ): for path in self . dp : with h5py . File ( path , \"r\" ) as f : data = f [ self . mode ] if self . limit_trajectories is None or self . limit_trajectories == - 1 : num = data [ \"u\" ] . shape [ 0 ] else : num = self . limit_trajectories iter_start = 0 iter_end = num for idx in range ( iter_start , iter_end ): u = torch . tensor ( data [ \"u\" ][ idx ]) vx = torch . tensor ( data [ \"vx\" ][ idx ]) vy = torch . tensor ( data [ \"vy\" ][ idx ]) if \"buo_y\" in data : cond = torch . tensor ( data [ \"buo_y\" ][ idx ]) . unsqueeze ( 0 ) . float () else : cond = None v = torch . cat (( vx [:, None ], vy [:, None ]), dim = 1 ) if self . usegrid : gridx = torch . linspace ( 0 , 1 , data [ \"x\" ][ idx ] . shape [ 0 ]) gridy = torch . linspace ( 0 , 1 , data [ \"y\" ][ idx ] . shape [ 0 ]) gridx = gridx . reshape ( 1 , gridx . size ( 0 ), 1 ,) . repeat ( 1 , 1 , gridy . size ( 0 ), ) gridy = gridy . reshape ( 1 , 1 , gridy . size ( 0 ),) . repeat ( 1 , gridx . size ( 1 ), 1 , ) grid = torch . cat (( gridx [:, None ], gridy [:, None ]), dim = 1 ) else : grid = None yield u . unsqueeze ( 1 ) . float (), v . float (), cond , grid pdearena.data.twod.datapipes.shallowwater2d \u00a4 ShallowWaterDatasetOpener \u00a4 Bases: dp . iter . IterDataPipe DataPipe for loading the shallow water dataset Parameters: Name Type Description Default dp dp . iter . IterDataPipe datapipe with paths to load the dataset from. required mode str \"train\" or \"valid\" or \"test\" required limit_trajectories Optional [ int ] number of trajectories to load from the dataset None usevort bool whether to use vorticity or velocity. If False, velocity is returned. False usegrid bool whether to use grid or not. If False, no grid is returned. False sample_rate int sample rate for the data. Default is 1, which means no sub-sampling. 1 Note We manually manage the data distribution across workers and processes. So make sure not to use torchdata 's dp.iter.Sharder with this data pipe. Source code in pdearena/data/twod/datapipes/shallowwater2d.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 class ShallowWaterDatasetOpener ( dp . iter . IterDataPipe ): \"\"\"DataPipe for loading the shallow water dataset Args: dp: datapipe with paths to load the dataset from. mode (str): \"train\" or \"valid\" or \"test\" limit_trajectories: number of trajectories to load from the dataset usevort (bool): whether to use vorticity or velocity. If False, velocity is returned. usegrid (bool): whether to use grid or not. If False, no grid is returned. sample_rate: sample rate for the data. Default is 1, which means no sub-sampling. Note: We manually manage the data distribution across workers and processes. So make sure not to use `torchdata`'s [dp.iter.Sharder][torchdata.datapipes.iter.ShardingFilter] with this data pipe. \"\"\" def __init__ ( self , dp : dp . iter . IterDataPipe , mode : str , limit_trajectories : Optional [ int ] = None , usevort : bool = False , usegrid : bool = False , sample_rate : int = 1 , ) -> None : super () . __init__ () self . dp = dp self . mode = mode self . limit_trajectories = limit_trajectories self . usevort = usevort self . usegrid = usegrid self . sample_rate = sample_rate def __iter__ ( self ): for path in self . dp : if \"zarr\" in path : data = xr . open_zarr ( path ) else : # Note that this is much slower data = xr . open_mfdataset ( os . path . join ( path , \"seed=*\" , \"run*\" , \"output.nc\" ), concat_dim = \"b\" , combine = \"nested\" , parallel = True , ) normstat = torch . load ( os . path . join ( path , \"..\" , \"normstats.pt\" )) if self . limit_trajectories is None or self . limit_trajectories == - 1 : num = data [ \"u\" ] . shape [ 0 ] else : num = self . limit_trajectories if dist . is_initialized (): rank = dist . get_rank () world_size = dist . get_world_size () else : rank = 0 world_size = 1 # Different workers should be using different trajectory batches worker_info = torch . utils . data . get_worker_info () if worker_info is not None : num_workers_per_dist = min ( worker_info . num_workers , num ) num_shards = num_workers_per_dist * world_size per_worker = int ( math . floor ( num / float ( num_shards ))) wid = rank * num_workers_per_dist + worker_info . id iter_start = wid * per_worker iter_end = iter_start + per_worker else : per_dist = int ( math . floor ( num / float ( world_size ))) iter_start = rank * per_dist iter_end = iter_start + per_dist for idx in range ( iter_start , iter_end ): if self . usevort : vort = torch . tensor ( data [ \"vor\" ][ idx ] . to_numpy ()) vort = ( vort - normstat [ \"vor\" ][ \"mean\" ]) / normstat [ \"vor\" ][ \"std\" ] else : u = torch . tensor ( data [ \"u\" ][ idx ] . to_numpy ()) v = torch . tensor ( data [ \"v\" ][ idx ] . to_numpy ()) vecf = torch . cat (( u , v ), dim = 1 ) pres = torch . tensor ( data [ \"pres\" ][ idx ] . to_numpy ()) pres = ( pres - normstat [ \"pres\" ][ \"mean\" ]) / normstat [ \"pres\" ][ \"std\" ] pres = pres . unsqueeze ( 1 ) if self . sample_rate > 1 : # TODO: hardocded skip_nt=4 pres = pres [ 4 :: self . sample_rate ] if self . usevort : vort = vort [ 4 :: self . sample_rate ] else : vecf = vecf [ 4 :: self . sample_rate ] if self . usegrid : raise NotImplementedError ( \"Grid not implemented for weather data\" ) else : if self . usevort : yield torch . cat (( pres , vort ), dim = 1 ) . float (), None , None , None else : yield pres . float (), vecf . float (), None , None","title":"Data Pipes"},{"location":"reference/datapipes/#datapipes","text":"","title":"Datapipes"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.common","text":"","title":"common"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.common.RandomTimeStepConditionedPDETrainData","text":"Bases: dp . iter . IterDataPipe Randomized data for training conditioned PDEs. Parameters: Name Type Description Default dp IterDataPipe Data pipe that returns individual PDE trajectories. required n_input_scalar_components int Number of input scalar components. required n_input_vector_components int Number of input vector components. required n_output_scalar_components int Number of output scalar components. required n_output_vector_components int Number of output vector components. required trajlen int Length of a trajectory in the dataset. required reweigh bool Whether to rebalance the dataset so that longer horizon predictions get equal weightage despite there being fewer actual such datapoints in a trajectory. Defaults to True. True Source code in pdearena/data/twod/datapipes/common.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 class RandomTimeStepConditionedPDETrainData ( dp . iter . IterDataPipe ): \"\"\"Randomized data for training conditioned PDEs. Args: dp (IterDataPipe): Data pipe that returns individual PDE trajectories. n_input_scalar_components (int): Number of input scalar components. n_input_vector_components (int): Number of input vector components. n_output_scalar_components (int): Number of output scalar components. n_output_vector_components (int): Number of output vector components. trajlen (int): Length of a trajectory in the dataset. reweigh (bool, optional): Whether to rebalance the dataset so that longer horizon predictions get equal weightage despite there being fewer actual such datapoints in a trajectory. Defaults to True. \"\"\" def __init__ ( self , dp , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , trajlen : int , reweigh = True , ) -> None : super () . __init__ () self . dp = dp self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . trajlen = trajlen self . reweigh = reweigh def __iter__ ( self ): time_resolution = self . trajlen for ( u , v , cond , grid ) in self . dp : if self . reweigh : end_time = random . choices ( range ( 1 , time_resolution ), k = 1 )[ 0 ] start_time = random . choices ( range ( 0 , end_time ), weights = 1 / np . arange ( 1 , end_time + 1 ), k = 1 )[ 0 ] else : end_time = torch . randint ( low = 1 , high = time_resolution , size = ( 1 ,), dtype = torch . long ) . item () start_time = torch . randint ( low = 0 , high = end_time . item (), size = ( 1 ,), dtype = torch . long ) . item () delta_t = end_time - start_time yield ( * datautils . create_time_conditioned_data ( self . n_input_scalar_components , self . n_input_vector_components , self . n_output_scalar_components , self . n_output_vector_components , u , v , grid , start_time , end_time , torch . tensor ([ delta_t ]), ), cond , )","title":"RandomTimeStepConditionedPDETrainData"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.common.RandomizedPDETrainData","text":"Bases: dp . iter . IterDataPipe Randomized data for training PDEs. Parameters: Name Type Description Default dp IterDataPipe Data pipe that returns individual PDE trajectories. required n_input_scalar_components int Number of input scalar components. required n_input_vector_components int Number of input vector components. required n_output_scalar_components int Number of output scalar components. required n_output_vector_components int Number of output vector components. required trajlen int Length of a trajectory in the dataset. required time_history int Number of time steps of inputs. required time_future int Number of time steps of outputs. required time_gap int Number of time steps between inputs and outputs. required Source code in pdearena/data/twod/datapipes/common.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 class RandomizedPDETrainData ( dp . iter . IterDataPipe ): \"\"\"Randomized data for training PDEs. Args: dp (IterDataPipe): Data pipe that returns individual PDE trajectories. n_input_scalar_components (int): Number of input scalar components. n_input_vector_components (int): Number of input vector components. n_output_scalar_components (int): Number of output scalar components. n_output_vector_components (int): Number of output vector components. trajlen (int): Length of a trajectory in the dataset. time_history (int): Number of time steps of inputs. time_future (int): Number of time steps of outputs. time_gap (int): Number of time steps between inputs and outputs. \"\"\" def __init__ ( self , dp , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , trajlen : int , time_history : int , time_future : int , time_gap : int , ) -> None : super () . __init__ () self . dp = dp self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . trajlen = trajlen self . time_history = time_history self . time_future = time_future self . time_gap = time_gap def __iter__ ( self ): # Length of trajectory time_resolution = self . trajlen # Max number of previous points solver can eat reduced_time_resolution = time_resolution - self . time_history # Number of future points to predict max_start_time = reduced_time_resolution - self . time_future - self . time_gap for batch in self . dp : if len ( batch ) == 3 : ( u , v , grid ) = batch cond = None elif len ( batch ) == 4 : ( u , v , cond , grid ) = batch else : raise ValueError ( f \"Unknown batch length of { len ( batch ) } .\" ) # Choose initial random time point at the PDE solution manifold start_time = random . choices ([ t for t in range ( max_start_time + 1 )], k = 1 ) yield datautils . create_data2D ( self . n_input_scalar_components , self . n_input_vector_components , self . n_output_scalar_components , self . n_output_vector_components , u , v , grid , start_time [ 0 ], self . time_history , self . time_future , self . time_gap , )","title":"RandomizedPDETrainData"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.common.TimestepConditionedPDEEvalData","text":"Bases: dp . iter . IterDataPipe Data for evaluation of time conditioned PDEs Parameters: Name Type Description Default dp torchdata . datapipes . iter . IterDataPipe Data pipe that returns individual PDE trajectories. required trajlen int Length of a trajectory in the dataset. required delta_t int Evaluates predictions conditioned at that delta_t. required Tip Make sure delta_t is less than half of trajlen . Source code in pdearena/data/twod/datapipes/common.py 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class TimestepConditionedPDEEvalData ( dp . iter . IterDataPipe ): \"\"\"Data for evaluation of time conditioned PDEs Args: dp (torchdata.datapipes.iter.IterDataPipe): Data pipe that returns individual PDE trajectories. trajlen (int): Length of a trajectory in the dataset. delta_t (int): Evaluates predictions conditioned at that delta_t. Tip: Make sure `delta_t` is less than half of `trajlen`. \"\"\" def __init__ ( self , dp : dp . iter . IterDataPipe , trajlen : int , delta_t : int ) -> None : super () . __init__ () self . dp = dp self . trajlen = trajlen if 2 * delta_t >= self . trajlen : raise ValueError ( \"delta_t should be less than half the trajectory length\" ) self . delta_t = delta_t def __iter__ ( self ): for begin in range ( self . trajlen - self . delta_t ): for ( u , v , cond , grid ) in self . dp : newu = u [ begin :: self . delta_t , ... ] newv = v [ begin :: self . delta_t , ... ] max_start_time = newu . size ( 0 ) for start in range ( max_start_time - 1 ): end = start + 1 data = torch . cat (( newu [ start : start + 1 ], newv [ start : start + 1 ]), dim = 1 ) . unsqueeze ( 0 ) if grid is not None : data = torch . cat (( data , grid ), dim = 1 ) label = torch . cat (( newu [ end : end + 1 ], newv [ end : end + 1 ]), dim = 1 ) . unsqueeze ( 0 ) if data . size ( 1 ) == 0 : raise ValueError ( \"Data is empty. Likely indexing issue.\" ) if label . size ( 1 ) == 0 : raise ValueError ( \"Label is empty. Likely indexing issue.\" ) yield data , label , torch . tensor ([ self . delta_t ]), cond","title":"TimestepConditionedPDEEvalData"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.common.ZarrLister","text":"Bases: dp . iter . IterDataPipe Customized lister for zarr files. Parameters: Name Type Description Default root Union [ str , Sequence [ str ], dp . iter . IterDataPipe ] Root directory. Defaults to \".\". '.' Yields: Type Description str Path to the zarr file. Source code in pdearena/data/twod/datapipes/common.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 class ZarrLister ( dp . iter . IterDataPipe ): \"\"\"Customized lister for zarr files. Args: root (Union[str, Sequence[str], dp.iter.IterDataPipe], optional): Root directory. Defaults to \".\". Yields: (str): Path to the zarr file. \"\"\" def __init__ ( self , root : Union [ str , Sequence [ str ], dp . iter . IterDataPipe ] = \".\" , ) -> None : super () . __init__ () if isinstance ( root , str ): root = [ root ] if not isinstance ( root , dp . iter . IterDataPipe ): root = dp . iter . IterableWrapper ( root ) self . datapipe : dp . iter . IterDataPipe = root def __iter__ ( self ): for path in self . datapipe : for dirname in os . listdir ( path ): if dirname . endswith ( \".zarr\" ): yield os . path . join ( path , dirname )","title":"ZarrLister"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.common.build_datapipes","text":"Build datapipes for training and evaluation. Parameters: Name Type Description Default pde PDEDataConfig PDE configuration. required data_path str Path to the data. required limit_trajectories int Number of trajectories to use. required usegrid bool Whether to use spatial grid as input. required dataset_opener Callable [..., dp . iter . IterDataPipe ] Dataset opener. required lister Callable [..., dp . iter . IterDataPipe ] List files. required sharder Callable [..., dp . iter . IterDataPipe ] Shard files. required filter_fn Callable [..., dp . iter . IterDataPipe ] Filter files. required mode str Mode of the data. [\"train\", \"valid\", \"test\"] required time_history int Number of time steps in the past. Defaults to 1. 1 time_future int Number of time steps in the future. Defaults to 1. 1 time_gap int Number of time steps between the past and the future to be skipped. Defaults to 0. 0 onestep bool Whether to use one-step prediction. Defaults to False. False conditioned bool Whether to use conditioned data. Defaults to False. False delta_t Optional [ int ] Time step size. Defaults to None. Only used for conditioned data. None conditioned_reweigh bool Whether to reweight conditioned data. Defaults to True. True Returns: Name Type Description dpipe IterDataPipe IterDataPipe for training and evaluation. Source code in pdearena/data/twod/datapipes/common.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def build_datapipes ( pde : PDEDataConfig , data_path , limit_trajectories , usegrid : bool , dataset_opener : Callable [ ... , dp . iter . IterDataPipe ], lister : Callable [ ... , dp . iter . IterDataPipe ], sharder : Callable [ ... , dp . iter . IterDataPipe ], filter_fn : Callable [ ... , dp . iter . IterDataPipe ], mode : str , time_history = 1 , time_future = 1 , time_gap = 0 , onestep = False , conditioned = False , delta_t : Optional [ int ] = None , conditioned_reweigh : bool = True , ): \"\"\"Build datapipes for training and evaluation. Args: pde (PDEDataConfig): PDE configuration. data_path (str): Path to the data. limit_trajectories (int): Number of trajectories to use. usegrid (bool): Whether to use spatial grid as input. dataset_opener (Callable[..., dp.iter.IterDataPipe]): Dataset opener. lister (Callable[..., dp.iter.IterDataPipe]): List files. sharder (Callable[..., dp.iter.IterDataPipe]): Shard files. filter_fn (Callable[..., dp.iter.IterDataPipe]): Filter files. mode (str): Mode of the data. [\"train\", \"valid\", \"test\"] time_history (int, optional): Number of time steps in the past. Defaults to 1. time_future (int, optional): Number of time steps in the future. Defaults to 1. time_gap (int, optional): Number of time steps between the past and the future to be skipped. Defaults to 0. onestep (bool, optional): Whether to use one-step prediction. Defaults to False. conditioned (bool, optional): Whether to use conditioned data. Defaults to False. delta_t (Optional[int], optional): Time step size. Defaults to None. Only used for conditioned data. conditioned_reweigh (bool, optional): Whether to reweight conditioned data. Defaults to True. Returns: dpipe (IterDataPipe): IterDataPipe for training and evaluation. \"\"\" dpipe = lister ( data_path , ) . filter ( filter_fn = filter_fn ) if mode == \"train\" : dpipe = dpipe . shuffle () dpipe = dataset_opener ( sharder ( dpipe ), mode = mode , limit_trajectories = limit_trajectories , usegrid = usegrid , ) if mode == \"train\" : # Make sure that in expectation we have seen all the data despite randomization dpipe = dpipe . cycle ( pde . trajlen ) if mode == \"train\" : # Training data is randomized if conditioned : dpipe = RandomTimeStepConditionedPDETrainData ( dpipe , pde . n_scalar_components , pde . n_vector_components , pde . n_scalar_components , pde . n_vector_components , pde . trajlen , conditioned_reweigh , ) else : dpipe = RandomizedPDETrainData ( dpipe , pde . n_scalar_components , pde . n_vector_components , pde . n_scalar_components , pde . n_vector_components , pde . trajlen , time_history , time_future , time_gap , ) else : # Evaluation data is not randomized. if conditioned and onestep : assert delta_t is not None dpipe = TimestepConditionedPDEEvalData ( dpipe , pde . trajlen , delta_t ) elif onestep : dpipe = PDEEvalTimeStepData ( dpipe , pde . n_scalar_components , pde . n_vector_components , pde . n_scalar_components , pde . n_vector_components , pde . trajlen , time_history , time_future , time_gap , ) return dpipe","title":"build_datapipes()"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.navierstokes2d","text":"","title":"navierstokes2d"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.navierstokes2d.NavierStokesDatasetOpener","text":"Bases: dp . iter . IterDataPipe DataPipe to load Navier-Stokes dataset. Parameters: Name Type Description Default dp dp . iter . IterDataPipe List of hdf5 files containing Navier-Stokes data. required mode str Mode to load data from. Can be one of train , val , test . required limit_trajectories int Limit the number of trajectories to load from individual hdf5 file. Defaults to None. None usegrid bool Whether to output spatial grid or not. Defaults to False. False Yields: Type Description Tuple [ torch . Tensor , torch . Tensor , Optional [ torch . Tensor ], Optional [ torch . Tensor ]] Tuple containing particle scalar field, velocity vector field, and optionally buoyancy force parameter value and spatial grid. Source code in pdearena/data/twod/datapipes/navierstokes2d.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class NavierStokesDatasetOpener ( dp . iter . IterDataPipe ): \"\"\"DataPipe to load Navier-Stokes dataset. Args: dp (dp.iter.IterDataPipe): List of `hdf5` files containing Navier-Stokes data. mode (str): Mode to load data from. Can be one of `train`, `val`, `test`. limit_trajectories (int, optional): Limit the number of trajectories to load from individual `hdf5` file. Defaults to None. usegrid (bool, optional): Whether to output spatial grid or not. Defaults to False. Yields: (Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor]]): Tuple containing particle scalar field, velocity vector field, and optionally buoyancy force parameter value and spatial grid. \"\"\" def __init__ ( self , dp , mode : str , limit_trajectories : Optional [ int ] = None , usegrid : bool = False ) -> None : super () . __init__ () self . dp = dp self . mode = mode self . limit_trajectories = limit_trajectories self . usegrid = usegrid def __iter__ ( self ): for path in self . dp : with h5py . File ( path , \"r\" ) as f : data = f [ self . mode ] if self . limit_trajectories is None or self . limit_trajectories == - 1 : num = data [ \"u\" ] . shape [ 0 ] else : num = self . limit_trajectories iter_start = 0 iter_end = num for idx in range ( iter_start , iter_end ): u = torch . tensor ( data [ \"u\" ][ idx ]) vx = torch . tensor ( data [ \"vx\" ][ idx ]) vy = torch . tensor ( data [ \"vy\" ][ idx ]) if \"buo_y\" in data : cond = torch . tensor ( data [ \"buo_y\" ][ idx ]) . unsqueeze ( 0 ) . float () else : cond = None v = torch . cat (( vx [:, None ], vy [:, None ]), dim = 1 ) if self . usegrid : gridx = torch . linspace ( 0 , 1 , data [ \"x\" ][ idx ] . shape [ 0 ]) gridy = torch . linspace ( 0 , 1 , data [ \"y\" ][ idx ] . shape [ 0 ]) gridx = gridx . reshape ( 1 , gridx . size ( 0 ), 1 ,) . repeat ( 1 , 1 , gridy . size ( 0 ), ) gridy = gridy . reshape ( 1 , 1 , gridy . size ( 0 ),) . repeat ( 1 , gridx . size ( 1 ), 1 , ) grid = torch . cat (( gridx [:, None ], gridy [:, None ]), dim = 1 ) else : grid = None yield u . unsqueeze ( 1 ) . float (), v . float (), cond , grid","title":"NavierStokesDatasetOpener"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.shallowwater2d","text":"","title":"shallowwater2d"},{"location":"reference/datapipes/#pdearena.data.twod.datapipes.shallowwater2d.ShallowWaterDatasetOpener","text":"Bases: dp . iter . IterDataPipe DataPipe for loading the shallow water dataset Parameters: Name Type Description Default dp dp . iter . IterDataPipe datapipe with paths to load the dataset from. required mode str \"train\" or \"valid\" or \"test\" required limit_trajectories Optional [ int ] number of trajectories to load from the dataset None usevort bool whether to use vorticity or velocity. If False, velocity is returned. False usegrid bool whether to use grid or not. If False, no grid is returned. False sample_rate int sample rate for the data. Default is 1, which means no sub-sampling. 1 Note We manually manage the data distribution across workers and processes. So make sure not to use torchdata 's dp.iter.Sharder with this data pipe. Source code in pdearena/data/twod/datapipes/shallowwater2d.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 class ShallowWaterDatasetOpener ( dp . iter . IterDataPipe ): \"\"\"DataPipe for loading the shallow water dataset Args: dp: datapipe with paths to load the dataset from. mode (str): \"train\" or \"valid\" or \"test\" limit_trajectories: number of trajectories to load from the dataset usevort (bool): whether to use vorticity or velocity. If False, velocity is returned. usegrid (bool): whether to use grid or not. If False, no grid is returned. sample_rate: sample rate for the data. Default is 1, which means no sub-sampling. Note: We manually manage the data distribution across workers and processes. So make sure not to use `torchdata`'s [dp.iter.Sharder][torchdata.datapipes.iter.ShardingFilter] with this data pipe. \"\"\" def __init__ ( self , dp : dp . iter . IterDataPipe , mode : str , limit_trajectories : Optional [ int ] = None , usevort : bool = False , usegrid : bool = False , sample_rate : int = 1 , ) -> None : super () . __init__ () self . dp = dp self . mode = mode self . limit_trajectories = limit_trajectories self . usevort = usevort self . usegrid = usegrid self . sample_rate = sample_rate def __iter__ ( self ): for path in self . dp : if \"zarr\" in path : data = xr . open_zarr ( path ) else : # Note that this is much slower data = xr . open_mfdataset ( os . path . join ( path , \"seed=*\" , \"run*\" , \"output.nc\" ), concat_dim = \"b\" , combine = \"nested\" , parallel = True , ) normstat = torch . load ( os . path . join ( path , \"..\" , \"normstats.pt\" )) if self . limit_trajectories is None or self . limit_trajectories == - 1 : num = data [ \"u\" ] . shape [ 0 ] else : num = self . limit_trajectories if dist . is_initialized (): rank = dist . get_rank () world_size = dist . get_world_size () else : rank = 0 world_size = 1 # Different workers should be using different trajectory batches worker_info = torch . utils . data . get_worker_info () if worker_info is not None : num_workers_per_dist = min ( worker_info . num_workers , num ) num_shards = num_workers_per_dist * world_size per_worker = int ( math . floor ( num / float ( num_shards ))) wid = rank * num_workers_per_dist + worker_info . id iter_start = wid * per_worker iter_end = iter_start + per_worker else : per_dist = int ( math . floor ( num / float ( world_size ))) iter_start = rank * per_dist iter_end = iter_start + per_dist for idx in range ( iter_start , iter_end ): if self . usevort : vort = torch . tensor ( data [ \"vor\" ][ idx ] . to_numpy ()) vort = ( vort - normstat [ \"vor\" ][ \"mean\" ]) / normstat [ \"vor\" ][ \"std\" ] else : u = torch . tensor ( data [ \"u\" ][ idx ] . to_numpy ()) v = torch . tensor ( data [ \"v\" ][ idx ] . to_numpy ()) vecf = torch . cat (( u , v ), dim = 1 ) pres = torch . tensor ( data [ \"pres\" ][ idx ] . to_numpy ()) pres = ( pres - normstat [ \"pres\" ][ \"mean\" ]) / normstat [ \"pres\" ][ \"std\" ] pres = pres . unsqueeze ( 1 ) if self . sample_rate > 1 : # TODO: hardocded skip_nt=4 pres = pres [ 4 :: self . sample_rate ] if self . usevort : vort = vort [ 4 :: self . sample_rate ] else : vecf = vecf [ 4 :: self . sample_rate ] if self . usegrid : raise NotImplementedError ( \"Grid not implemented for weather data\" ) else : if self . usevort : yield torch . cat (( pres , vort ), dim = 1 ) . float (), None , None , None else : yield pres . float (), vecf . float (), None , None","title":"ShallowWaterDatasetOpener"},{"location":"reference/metrics/","text":"Training and Evaluation metrics \u00a4 CustomMSELoss \u00a4 Bases: torch . nn . Module Custom MSE loss for PDEs. MSE but summed over time and fields, then averaged over space and batch. Parameters: Name Type Description Default reduction str Reduction method. Defaults to \"mean\". 'mean' Source code in pdearena/modules/loss.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class CustomMSELoss ( torch . nn . Module ): \"\"\"Custom MSE loss for PDEs. MSE but summed over time and fields, then averaged over space and batch. Args: reduction (str, optional): Reduction method. Defaults to \"mean\". \"\"\" def __init__ ( self , reduction : str = \"mean\" ) -> None : super () . __init__ () self . reduction = reduction def forward ( self , input : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : return custommse_loss ( input , target , reduction = self . reduction ) ScaledLpLoss \u00a4 Bases: torch . nn . Module Scaled Lp loss for PDEs. Parameters: Name Type Description Default p int p in Lp norm. Defaults to 2. 2 reduction str Reduction method. Defaults to \"mean\". 'mean' Source code in pdearena/modules/loss.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 class ScaledLpLoss ( torch . nn . Module ): \"\"\"Scaled Lp loss for PDEs. Args: p (int, optional): p in Lp norm. Defaults to 2. reduction (str, optional): Reduction method. Defaults to \"mean\". \"\"\" def __init__ ( self , p : int = 2 , reduction : str = \"mean\" ) -> None : super () . __init__ () self . p = p self . reduction = reduction def forward ( self , input : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : return scaledlp_loss ( input , target , p = self . p , reduction = self . reduction )","title":"Metrics"},{"location":"reference/metrics/#training-and-evaluation-metrics","text":"","title":"Training and Evaluation metrics"},{"location":"reference/metrics/#pdearena.modules.loss.CustomMSELoss","text":"Bases: torch . nn . Module Custom MSE loss for PDEs. MSE but summed over time and fields, then averaged over space and batch. Parameters: Name Type Description Default reduction str Reduction method. Defaults to \"mean\". 'mean' Source code in pdearena/modules/loss.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class CustomMSELoss ( torch . nn . Module ): \"\"\"Custom MSE loss for PDEs. MSE but summed over time and fields, then averaged over space and batch. Args: reduction (str, optional): Reduction method. Defaults to \"mean\". \"\"\" def __init__ ( self , reduction : str = \"mean\" ) -> None : super () . __init__ () self . reduction = reduction def forward ( self , input : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : return custommse_loss ( input , target , reduction = self . reduction )","title":"CustomMSELoss"},{"location":"reference/metrics/#pdearena.modules.loss.ScaledLpLoss","text":"Bases: torch . nn . Module Scaled Lp loss for PDEs. Parameters: Name Type Description Default p int p in Lp norm. Defaults to 2. 2 reduction str Reduction method. Defaults to \"mean\". 'mean' Source code in pdearena/modules/loss.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 class ScaledLpLoss ( torch . nn . Module ): \"\"\"Scaled Lp loss for PDEs. Args: p (int, optional): p in Lp norm. Defaults to 2. reduction (str, optional): Reduction method. Defaults to \"mean\". \"\"\" def __init__ ( self , p : int = 2 , reduction : str = \"mean\" ) -> None : super () . __init__ () self . p = p self . reduction = reduction def forward ( self , input : torch . Tensor , target : torch . Tensor ) -> torch . Tensor : return scaledlp_loss ( input , target , p = self . p , reduction = self . reduction )","title":"ScaledLpLoss"},{"location":"reference/modules/","text":"Available PDE Surrogate Modules \u00a4 SpectralConv2d \u00a4 Bases: nn . Module 2D Fourier layer. Does FFT, linear transform, and Inverse FFT. Implemented in a way to allow multi-gpu training. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required modes1 int Number of Fourier modes to keep in the first spatial direction required modes2 int Number of Fourier modes to keep in the second spatial direction required paper Source code in pdearena/modules/fourier.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class SpectralConv2d ( nn . Module ): \"\"\"2D Fourier layer. Does FFT, linear transform, and Inverse FFT. Implemented in a way to allow multi-gpu training. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels modes1 (int): Number of Fourier modes to keep in the first spatial direction modes2 (int): Number of Fourier modes to keep in the second spatial direction [paper](https://arxiv.org/abs/2010.08895) \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int , modes2 : int ): super () . __init__ () self . in_channels = in_channels self . out_channels = out_channels self . modes1 = modes1 # Number of Fourier modes to multiply, at most floor(N/2) + 1 self . modes2 = modes2 self . scale = 1 / ( in_channels * out_channels ) self . weights1 = nn . Parameter ( self . scale * torch . rand ( in_channels , out_channels , self . modes1 , self . modes2 , 2 , dtype = torch . float32 ) ) self . weights2 = nn . Parameter ( self . scale * torch . rand ( in_channels , out_channels , self . modes1 , self . modes2 , 2 , dtype = torch . float32 ) ) def forward ( self , x , x_dim = None , y_dim = None ): batchsize = x . shape [ 0 ] # Compute Fourier coeffcients up to factor of e^(- something constant) x_ft = torch . fft . rfft2 ( x ) # Multiply relevant Fourier modes out_ft = torch . zeros ( batchsize , self . out_channels , x . size ( - 2 ), x . size ( - 1 ) // 2 + 1 , dtype = torch . cfloat , device = x . device , ) out_ft [:, :, : self . modes1 , : self . modes2 ] = batchmul2d ( x_ft [:, :, : self . modes1 , : self . modes2 ], torch . view_as_complex ( self . weights1 ) ) out_ft [:, :, - self . modes1 :, : self . modes2 ] = batchmul2d ( x_ft [:, :, - self . modes1 :, : self . modes2 ], torch . view_as_complex ( self . weights2 ) ) # Return to physical space x = torch . fft . irfft2 ( out_ft , s = ( x . size ( - 2 ), x . size ( - 1 ))) return x DilatedBasicBlock \u00a4 Bases: nn . Module Basic block for Dilated ResNet Parameters: Name Type Description Default in_planes int number of input channels required planes int number of output channels required stride int stride of the convolution. Defaults to 1. 1 activation str activation function. Defaults to \"relu\". 'relu' norm bool whether to use group normalization. Defaults to True. True num_groups int number of groups for group normalization. Defaults to 1. 1 Source code in pdearena/modules/twod_resnet.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class DilatedBasicBlock ( nn . Module ): \"\"\"Basic block for Dilated ResNet Args: in_planes (int): number of input channels planes (int): number of output channels stride (int, optional): stride of the convolution. Defaults to 1. activation (str, optional): activation function. Defaults to \"relu\". norm (bool, optional): whether to use group normalization. Defaults to True. num_groups (int, optional): number of groups for group normalization. Defaults to 1. \"\"\" expansion = 1 def __init__ ( self , in_planes : int , planes : int , stride : int = 1 , activation : str = \"relu\" , norm : bool = True , num_groups : int = 1 , ): super () . __init__ () self . dilation = [ 1 , 2 , 4 , 8 , 4 , 2 , 1 ] dilation_layers = [] for dil in self . dilation : dilation_layers . append ( nn . Conv2d ( in_planes , planes , kernel_size = 3 , stride = stride , dilation = dil , padding = dil , bias = True , ) ) self . dilation_layers = nn . ModuleList ( dilation_layers ) self . norm_layers = nn . ModuleList ( nn . GroupNorm ( num_groups , num_channels = planes ) if norm else nn . Identity () for dil in self . dilation ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : out = x for layer , norm in zip ( self . dilation_layers , self . norm_layers ): out = self . activation ( layer ( norm ( out ))) return out + x FourierBasicBlock \u00a4 Bases: nn . Module Basic block for Fourier Neural Operators Parameters: Name Type Description Default in_planes int number of input channels required planes int number of output channels required stride int stride of the convolution. Defaults to 1. 1 modes1 int number of modes for the first spatial dimension. Defaults to 16. 16 modes2 int number of modes for the second spatial dimension. Defaults to 16. 16 activation str activation function. Defaults to \"relu\". 'gelu' norm bool whether to use group normalization. Defaults to False. False Source code in pdearena/modules/twod_resnet.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 class FourierBasicBlock ( nn . Module ): \"\"\"Basic block for Fourier Neural Operators Args: in_planes (int): number of input channels planes (int): number of output channels stride (int, optional): stride of the convolution. Defaults to 1. modes1 (int, optional): number of modes for the first spatial dimension. Defaults to 16. modes2 (int, optional): number of modes for the second spatial dimension. Defaults to 16. activation (str, optional): activation function. Defaults to \"relu\". norm (bool, optional): whether to use group normalization. Defaults to False. \"\"\" expansion : int = 1 def __init__ ( self , in_planes : int , planes : int , stride : int = 1 , modes1 : int = 16 , modes2 : int = 16 , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () self . modes1 = modes1 self . modes2 = modes2 assert not norm self . fourier1 = SpectralConv2d ( in_planes , planes , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv1 = nn . Conv2d ( in_planes , planes , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" , bias = True ) self . fourier2 = SpectralConv2d ( planes , planes , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv2 = nn . Conv2d ( planes , planes , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" , bias = True ) # So far shortcut connections are not helping # self.shortcut = nn.Sequential() # if stride != 1 or in_planes != self.expansion * planes: # self.shortcut = nn.Sequential( # nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1) # ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : x1 = self . fourier1 ( x ) x2 = self . conv1 ( x ) out = self . activation ( x1 + x2 ) x1 = self . fourier2 ( out ) x2 = self . conv2 ( out ) out = x1 + x2 # out += self.shortcut(x) out = self . activation ( out ) return out ResNet \u00a4 Bases: nn . Module Class to support ResNet like feedforward architectures Parameters: Name Type Description Default n_input_scalar_components int Number of input scalar components in the model required n_input_vector_components int Number of input vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required block Callable BasicBlock or DilatedBasicBlock or FourierBasicBlock required num_blocks List [ int ] Number of blocks in each layer required time_history int Number of time steps to use in the input required time_future int Number of time steps to predict in the output required hidden_channels int Number of channels in the hidden layers 64 activation str Activation function to use 'gelu' norm bool Whether to use normalization True Source code in pdearena/modules/twod_resnet.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 class ResNet ( nn . Module ): \"\"\"Class to support ResNet like feedforward architectures Args: n_input_scalar_components (int): Number of input scalar components in the model n_input_vector_components (int): Number of input vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model block (Callable): BasicBlock or DilatedBasicBlock or FourierBasicBlock num_blocks (List[int]): Number of blocks in each layer time_history (int): Number of time steps to use in the input time_future (int): Number of time steps to predict in the output hidden_channels (int): Number of channels in the hidden layers activation (str): Activation function to use norm (bool): Whether to use normalization \"\"\" padding = 9 def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , block , num_blocks : list , time_history : int , time_future : int , hidden_channels : int = 64 , activation : str = \"gelu\" , norm : bool = True , diffmode : bool = False , usegrid : bool = False , ): super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . diffmode = diffmode self . usegrid = usegrid self . in_planes = hidden_channels insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) if self . usegrid : insize += 2 self . conv_in1 = nn . Conv2d ( insize , self . in_planes , kernel_size = 1 , bias = True , ) self . conv_in2 = nn . Conv2d ( self . in_planes , self . in_planes , kernel_size = 1 , bias = True , ) self . conv_out1 = nn . Conv2d ( self . in_planes , self . in_planes , kernel_size = 1 , bias = True , ) self . conv_out2 = nn . Conv2d ( self . in_planes , time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), kernel_size = 1 , bias = True , ) self . layers = nn . ModuleList ( [ self . _make_layer ( block , self . in_planes , num_blocks [ i ], stride = 1 , activation = activation , norm = norm , ) for i in range ( len ( num_blocks )) ] ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) def _make_layer ( self , block : Callable , planes : int , num_blocks : int , stride : int , activation : str , norm : bool = True , ) -> nn . Sequential : strides = [ stride ] + [ 1 ] * ( num_blocks - 1 ) layers = [] for stride in strides : layers . append ( block ( self . in_planes , planes , stride , activation = activation , norm = norm , ) ) self . in_planes = planes * block . expansion return nn . Sequential ( * layers ) def __repr__ ( self ): return \"ResNet\" def forward ( self , x : torch . Tensor ) -> torch . Tensor : assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C # prev = x.float() x = self . activation ( self . conv_in1 ( x . float ())) x = self . activation ( self . conv_in2 ( x . float ())) if self . padding > 0 : x = F . pad ( x , [ 0 , self . padding , 0 , self . padding ]) for layer in self . layers : x = layer ( x ) if self . padding > 0 : x = x [ ... , : - self . padding , : - self . padding ] x = self . activation ( self . conv_out1 ( x )) x = self . conv_out2 ( x ) if self . diffmode : raise NotImplementedError ( \"diffmode\" ) # x = x + prev[:, -1:, ...].detach() return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) OperatorBlock_2D \u00a4 Bases: nn . Module Parameters: Name Type Description Default in_codim int Input co-domian dimension required out_codim int output co-domain dimension required dim1 int Default output grid size along x (or 1st dimension) required dim2 int Default output grid size along y ( or 2nd dimension) required modes1 int Number of fourier modes to consider along 1st dimension required modes2 int Number of fourier modes to consider along 2nd dimension required norm bool Whether to use normalization ( torch.nn.InstanceNorm2d ) True nonlin bool Whether to use non-linearity ( torch.nn.GELU ) True All variables are consistent with the SpectralConv2d_Uno . Source code in pdearena/modules/twod_uno.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 class OperatorBlock_2D ( nn . Module ): \"\"\" Args: in_codim (int): Input co-domian dimension out_codim (int): output co-domain dimension dim1 (int): Default output grid size along x (or 1st dimension) dim2 (int): Default output grid size along y ( or 2nd dimension) modes1 (int): Number of fourier modes to consider along 1st dimension modes2 (int): Number of fourier modes to consider along 2nd dimension norm (bool): Whether to use normalization ([torch.nn.InstanceNorm2d][]) nonlin (bool): Whether to use non-linearity ([torch.nn.GELU][]) All variables are consistent with the [`SpectralConv2d_Uno`][pdearena.modules.twod_uno.SpectralConv2d_Uno]. \"\"\" def __init__ ( self , in_codim , out_codim , dim1 , dim2 , modes1 , modes2 , norm = True , nonlin = True ): super () . __init__ () self . conv = SpectralConv2d_Uno ( in_codim , out_codim , dim1 , dim2 , modes1 , modes2 ) self . w = Pointwise_op_2D ( in_codim , out_codim , dim1 , dim2 ) self . norm = norm self . non_lin = nonlin if norm : self . normalize_layer = nn . InstanceNorm2d ( int ( out_codim ), affine = True ) def forward ( self , x , dim1 = None , dim2 = None ): # # input shape = (batch, in_codim, input_dim1,input_dim2) # output shape = (batch, out_codim, dim1,dim2) x1_out = self . conv ( x , dim1 , dim2 ) x2_out = self . w ( x , dim1 , dim2 ) x_out = x1_out + x2_out if self . norm : x_out = self . normalize_layer ( x_out ) if self . non_lin : x_out = F . gelu ( x_out ) return x_out Pointwise_op_2D \u00a4 Bases: nn . Module Parameters: Name Type Description Default in_codim int Input co-domian dimension required out_codim int output co-domain dimension required dim1 int Default output grid size along x (or 1st dimension) required dim2 int Default output grid size along y ( or 2nd dimension) required Source code in pdearena/modules/twod_uno.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 class Pointwise_op_2D ( nn . Module ): \"\"\" Args: in_codim (int): Input co-domian dimension out_codim (int): output co-domain dimension dim1 (int): Default output grid size along x (or 1st dimension) dim2 (int): Default output grid size along y ( or 2nd dimension) \"\"\" def __init__ ( self , in_codim : int , out_codim : int , dim1 : int , dim2 : int ): super () . __init__ () self . conv = nn . Conv2d ( int ( in_codim ), int ( out_codim ), 1 ) self . dim1 = int ( dim1 ) self . dim2 = int ( dim2 ) def forward ( self , x , dim1 = None , dim2 = None ): # # input shape = (batch, in_codim, input_dim1,input_dim2) # output shape = (batch, out_codim, dim1,dim2) if dim1 is None : dim1 = self . dim1 dim2 = self . dim2 x_out = self . conv ( x ) x_out = F . interpolate ( x_out , size = ( dim1 , dim2 ), mode = \"bicubic\" , align_corners = True , antialias = True ) return x_out SpectralConv2d_Uno \u00a4 Bases: nn . Module 2D Fourier layer. It does FFT, linear transform, and Inverse FFT. Modified to support multi-gpu training. Parameters: Name Type Description Default in_codim int Input co-domian dimension required out_codim int output co-domain dimension required dim1 int Default output grid size along x (or 1st dimension of output domain) required dim2 int Default output grid size along y ( or 2nd dimension of output domain) Ratio of grid size of the input and the output implecitely set the expansion or contraction farctor along each dimension. required modes1 int), modes2 (int Number of fourier modes to consider for the ontegral operator Number of modes must be compatibale with the input grid size and desired output grid size. i.e., modes1 <= min( dim1/2, input_dim1/2). Here \"input_dim1\" is the grid size along x axis (or first dimension) of the input domain. Other modes also the have same constrain. None Source code in pdearena/modules/twod_uno.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class SpectralConv2d_Uno ( nn . Module ): \"\"\"2D Fourier layer. It does FFT, linear transform, and Inverse FFT. Modified to support multi-gpu training. Args: in_codim (int): Input co-domian dimension out_codim (int): output co-domain dimension dim1 (int): Default output grid size along x (or 1st dimension of output domain) dim2 (int): Default output grid size along y ( or 2nd dimension of output domain) Ratio of grid size of the input and the output implecitely set the expansion or contraction farctor along each dimension. modes1 (int), modes2 (int): Number of fourier modes to consider for the ontegral operator Number of modes must be compatibale with the input grid size and desired output grid size. i.e., modes1 <= min( dim1/2, input_dim1/2). Here \"input_dim1\" is the grid size along x axis (or first dimension) of the input domain. Other modes also the have same constrain. \"\"\" def __init__ ( self , in_codim , out_codim , dim1 , dim2 , modes1 = None , modes2 = None ): super () . __init__ () in_codim = int ( in_codim ) out_codim = int ( out_codim ) self . in_channels = in_codim self . out_channels = out_codim self . dim1 = dim1 self . dim2 = dim2 if modes1 is not None : self . modes1 = modes1 self . modes2 = modes2 else : self . modes1 = dim1 // 2 - 1 self . modes2 = dim2 // 2 self . scale = ( 1 / ( 2 * in_codim )) ** ( 1.0 / 2.0 ) self . weights1 = nn . Parameter ( self . scale * ( torch . randn ( in_codim , out_codim , self . modes1 , self . modes2 , 2 , dtype = torch . float32 )) ) self . weights2 = nn . Parameter ( self . scale * ( torch . randn ( in_codim , out_codim , self . modes1 , self . modes2 , 2 , dtype = torch . float32 )) ) # Complex multiplication def compl_mul2d ( self , input , weights ): return torch . einsum ( \"bixy,ioxy->boxy\" , input , weights ) def forward ( self , x , dim1 = None , dim2 = None ): if dim1 is not None : self . dim1 = dim1 self . dim2 = dim2 batchsize = x . shape [ 0 ] # Compute Fourier coeffcients up to factor of e^(- something constant) x_ft = torch . fft . rfft2 ( x , norm = \"forward\" ) # Multiply relevant Fourier modes out_ft = torch . zeros ( batchsize , self . out_channels , self . dim1 , self . dim2 // 2 + 1 , dtype = torch . cfloat , device = x . device , ) out_ft [:, :, : self . modes1 , : self . modes2 ] = self . compl_mul2d ( x_ft [:, :, : self . modes1 , : self . modes2 ], torch . view_as_complex ( self . weights1 ) ) out_ft [:, :, - self . modes1 :, : self . modes2 ] = self . compl_mul2d ( x_ft [:, :, - self . modes1 :, : self . modes2 ], torch . view_as_complex ( self . weights2 ) ) # Return to physical space x = torch . fft . irfft2 ( out_ft , s = ( self . dim1 , self . dim2 ), norm = \"forward\" ) return x UNO \u00a4 Bases: nn . Module UNO model Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps to include in the model required time_future int Number of time steps to predict in the model required hidden_channels int Number of hidden channels in the model required pad int Padding to use in the model 0 factor int Scaling factor to use in the model 3 / 4 activation str Activation function to use in the model 'gelu' Source code in pdearena/modules/twod_uno.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 class UNO ( nn . Module ): \"\"\"UNO model Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps to include in the model time_future (int): Number of time steps to predict in the model hidden_channels (int): Number of hidden channels in the model pad (int): Padding to use in the model factor (int): Scaling factor to use in the model activation (str): Activation function to use in the model \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , pad = 0 , factor = 3 / 4 , activation = \"gelu\" , ): super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . width = hidden_channels self . factor = factor self . padding = pad self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) in_width = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) out_width = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) self . fc = nn . Linear ( in_width , self . width // 2 ) self . fc0 = nn . Linear ( self . width // 2 , self . width ) # input channel is 3: (a(x, y), x, y) self . L0 = OperatorBlock_2D ( self . width , 2 * factor * self . width , 48 , 48 , 18 , 18 ) self . L1 = OperatorBlock_2D ( 2 * factor * self . width , 4 * factor * self . width , 32 , 32 , 14 , 14 ) self . L2 = OperatorBlock_2D ( 4 * factor * self . width , 8 * factor * self . width , 16 , 16 , 6 , 6 ) self . L3 = OperatorBlock_2D ( 8 * factor * self . width , 8 * factor * self . width , 16 , 16 , 6 , 6 ) self . L4 = OperatorBlock_2D ( 8 * factor * self . width , 4 * factor * self . width , 32 , 32 , 6 , 6 ) self . L5 = OperatorBlock_2D ( 8 * factor * self . width , 2 * factor * self . width , 48 , 48 , 14 , 14 ) self . L6 = OperatorBlock_2D ( 4 * factor * self . width , self . width , 64 , 64 , 18 , 18 ) # will be reshaped self . fc1 = nn . Linear ( 2 * self . width , 4 * self . width ) self . fc2 = nn . Linear ( 4 * self . width , out_width ) def forward ( self , x ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C x = x . permute ( 0 , 2 , 3 , 1 ) x_fc = self . fc ( x ) x_fc = self . activation ( x_fc ) x_fc0 = self . fc0 ( x_fc ) x_fc0 = self . activation ( x_fc0 ) x_fc0 = x_fc0 . permute ( 0 , 3 , 1 , 2 ) x_fc0 = F . pad ( x_fc0 , [ self . padding , self . padding , self . padding , self . padding ]) D1 , D2 = x_fc0 . shape [ - 2 ], x_fc0 . shape [ - 1 ] x_c0 = self . L0 ( x_fc0 , int ( D1 * self . factor ), int ( D2 * self . factor )) x_c1 = self . L1 ( x_c0 , D1 // 2 , D2 // 2 ) x_c2 = self . L2 ( x_c1 , D1 // 4 , D2 // 4 ) x_c3 = self . L3 ( x_c2 , D1 // 4 , D2 // 4 ) x_c4 = self . L4 ( x_c3 , D1 // 2 , D2 // 2 ) x_c4 = torch . cat ([ x_c4 , x_c1 ], dim = 1 ) x_c5 = self . L5 ( x_c4 , int ( D1 * self . factor ), int ( D2 * self . factor )) x_c5 = torch . cat ([ x_c5 , x_c0 ], dim = 1 ) x_c6 = self . L6 ( x_c5 , D1 , D2 ) x_c6 = torch . cat ([ x_c6 , x_fc0 ], dim = 1 ) if self . padding != 0 : x_c6 = x_c6 [ ... , : - self . padding , : - self . padding ] x_c6 = x_c6 . permute ( 0 , 2 , 3 , 1 ) x_fc1 = self . fc1 ( x_c6 ) x_fc1 = self . activation ( x_fc1 ) x_out = self . fc2 ( x_fc1 ) x_out = x_out . permute ( 0 , 3 , 1 , 2 ) return x_out . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) Unet2015 \u00a4 Bases: nn . Module Two-dimensional UNet based on original architecture. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of hidden channels. required activation str Activation function. required Source code in pdearena/modules/twod_unet2015.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 class Unet2015 ( nn . Module ): \"\"\"Two-dimensional UNet based on original architecture. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of hidden channels. activation (str): Activation function. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) in_channels = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) features = hidden_channels self . encoder1 = Unet2015 . _block ( in_channels , features , name = \"enc1\" , activation = self . activation ) self . pool1 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . encoder2 = Unet2015 . _block ( features , features * 2 , name = \"enc2\" , activation = self . activation ) self . pool2 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . encoder3 = Unet2015 . _block ( features * 2 , features * 4 , name = \"enc3\" , activation = self . activation ) self . pool3 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . encoder4 = Unet2015 . _block ( features * 4 , features * 8 , name = \"enc4\" , activation = self . activation ) self . pool4 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . bottleneck = Unet2015 . _block ( features * 8 , features * 16 , name = \"bottleneck\" , activation = self . activation ) self . upconv4 = nn . ConvTranspose2d ( features * 16 , features * 8 , kernel_size = 2 , stride = 2 ) self . decoder4 = Unet2015 . _block (( features * 8 ) * 2 , features * 8 , name = \"dec4\" , activation = self . activation ) self . upconv3 = nn . ConvTranspose2d ( features * 8 , features * 4 , kernel_size = 2 , stride = 2 ) self . decoder3 = Unet2015 . _block (( features * 4 ) * 2 , features * 4 , name = \"dec3\" , activation = self . activation ) self . upconv2 = nn . ConvTranspose2d ( features * 4 , features * 2 , kernel_size = 2 , stride = 2 ) self . decoder2 = Unet2015 . _block (( features * 2 ) * 2 , features * 2 , name = \"dec2\" , activation = self . activation ) self . upconv1 = nn . ConvTranspose2d ( features * 2 , features , kernel_size = 2 , stride = 2 ) self . decoder1 = Unet2015 . _block ( features * 2 , features , name = \"dec1\" , activation = self . activation ) self . conv = nn . Conv2d ( in_channels = features , out_channels = out_channels , kernel_size = 1 ) def forward ( self , x ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) enc1 = self . encoder1 ( x ) enc2 = self . encoder2 ( self . pool1 ( enc1 )) enc3 = self . encoder3 ( self . pool2 ( enc2 )) enc4 = self . encoder4 ( self . pool3 ( enc3 )) bottleneck = self . bottleneck ( self . pool4 ( enc4 )) dec4 = self . upconv4 ( bottleneck ) dec4 = torch . cat (( dec4 , enc4 ), dim = 1 ) dec4 = self . decoder4 ( dec4 ) dec3 = self . upconv3 ( dec4 ) dec3 = torch . cat (( dec3 , enc3 ), dim = 1 ) dec3 = self . decoder3 ( dec3 ) dec2 = self . upconv2 ( dec3 ) dec2 = torch . cat (( dec2 , enc2 ), dim = 1 ) dec2 = self . decoder2 ( dec2 ) dec1 = self . upconv1 ( dec2 ) dec1 = torch . cat (( dec1 , enc1 ), dim = 1 ) dec1 = self . decoder1 ( dec1 ) out = self . conv ( dec1 ) return out . reshape ( orig_shape [ 0 ], - 1 , * orig_shape [ 2 :]) @staticmethod def _block ( in_channels , features , name , activation = nn . Tanh ()): return nn . Sequential ( OrderedDict ( [ ( name + \"conv1\" , nn . Conv2d ( in_channels = in_channels , out_channels = features , kernel_size = 3 , padding = 1 , bias = False , ), ), ( name + \"norm1\" , nn . BatchNorm2d ( num_features = features )), ( name + \"act1\" , activation ), ( name + \"conv2\" , nn . Conv2d ( in_channels = features , out_channels = features , kernel_size = 3 , padding = 1 , bias = False , ), ), ( name + \"norm2\" , nn . BatchNorm2d ( num_features = features )), ( name + \"act2\" , activation ), ] ) ) Unetbase \u00a4 Bases: nn . Module Our interpretation of the original U-Net architecture. Uses torch.nn.GroupNorm instead of torch.nn.BatchNorm2d . Also there is no BottleNeck block. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of channels in the hidden layers. required activation str Activation function to use. One of [\"gelu\", \"relu\", \"silu\"]. 'gelu' Source code in pdearena/modules/twod_unetbase.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Unetbase ( nn . Module ): \"\"\"Our interpretation of the original U-Net architecture. Uses [torch.nn.GroupNorm][] instead of [torch.nn.BatchNorm2d][]. Also there is no `BottleNeck` block. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of channels in the hidden layers. activation (str): Activation function to use. One of [\"gelu\", \"relu\", \"silu\"]. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation = \"gelu\" , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels self . image_proj = ConvBlock ( insize , n_channels , activation = activation ) self . down = nn . ModuleList ( [ Down ( n_channels , n_channels * 2 , activation = activation ), Down ( n_channels * 2 , n_channels * 4 , activation = activation ), Down ( n_channels * 4 , n_channels * 8 , activation = activation ), Down ( n_channels * 8 , n_channels * 16 , activation = activation ), ] ) self . up = nn . ModuleList ( [ Up ( n_channels * 16 , n_channels * 8 , activation = activation ), Up ( n_channels * 8 , n_channels * 4 , activation = activation ), Up ( n_channels * 4 , n_channels * 2 , activation = activation ), Up ( n_channels * 2 , n_channels , activation = activation ), ] ) out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) # should there be a final norm too? but we aren't doing \"prenorm\" in the original self . final = nn . Conv2d ( n_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) def forward ( self , x ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) h = self . image_proj ( x ) x1 = self . down [ 0 ]( h ) x2 = self . down [ 1 ]( x1 ) x3 = self . down [ 2 ]( x2 ) x4 = self . down [ 3 ]( x3 ) x = self . up [ 0 ]( x4 , x3 ) x = self . up [ 1 ]( x , x2 ) x = self . up [ 2 ]( x , x1 ) x = self . up [ 3 ]( x , h ) x = self . final ( x ) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) AttentionBlock \u00a4 Bases: nn . Module Attention block This is similar to [transformer multi-head attention] Parameters: Name Type Description Default n_channels int the number of channels in the input required n_heads int the number of heads in multi-head attention 1 d_k Optional [ int ] the number of dimensions in each head None n_groups int the number of groups for group normalization . 1 Source code in pdearena/modules/twod_unet.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class AttentionBlock ( nn . Module ): \"\"\"Attention block This is similar to [transformer multi-head attention] Args: n_channels (int): the number of channels in the input n_heads (int): the number of heads in multi-head attention d_k: the number of dimensions in each head n_groups (int): the number of groups for [group normalization][torch.nn.GroupNorm]. \"\"\" def __init__ ( self , n_channels : int , n_heads : int = 1 , d_k : Optional [ int ] = None , n_groups : int = 1 ): super () . __init__ () # Default `d_k` if d_k is None : d_k = n_channels # Normalization layer self . norm = nn . GroupNorm ( n_groups , n_channels ) # Projections for query, key and values self . projection = nn . Linear ( n_channels , n_heads * d_k * 3 ) # Linear layer for final transformation self . output = nn . Linear ( n_heads * d_k , n_channels ) # Scale for dot-product attention self . scale = d_k **- 0.5 # self . n_heads = n_heads self . d_k = d_k def forward ( self , x : torch . Tensor ): # Get shape batch_size , n_channels , height , width = x . shape # Change `x` to shape `[batch_size, seq, n_channels]` x = x . view ( batch_size , n_channels , - 1 ) . permute ( 0 , 2 , 1 ) # Get query, key, and values (concatenated) and shape it to `[batch_size, seq, n_heads, 3 * d_k]` qkv = self . projection ( x ) . view ( batch_size , - 1 , self . n_heads , 3 * self . d_k ) # Split query, key, and values. Each of them will have shape `[batch_size, seq, n_heads, d_k]` q , k , v = torch . chunk ( qkv , 3 , dim =- 1 ) # Calculate scaled dot-product $\\frac{Q K^\\top}{\\sqrt{d_k}}$ attn = torch . einsum ( \"bihd,bjhd->bijh\" , q , k ) * self . scale # Softmax along the sequence dimension $\\underset{seq}{softmax}\\Bigg(\\frac{Q K^\\top}{\\sqrt{d_k}}\\Bigg)$ attn = attn . softmax ( dim = 1 ) # Multiply by values res = torch . einsum ( \"bijh,bjhd->bihd\" , attn , v ) # Reshape to `[batch_size, seq, n_heads * d_k]` res = res . view ( batch_size , - 1 , self . n_heads * self . d_k ) # Transform to `[batch_size, seq, n_channels]` res = self . output ( res ) # Add skip connection res += x # Change to shape `[batch_size, in_channels, height, width]` res = res . permute ( 0 , 2 , 1 ) . view ( batch_size , n_channels , height , width ) return res DownBlock \u00a4 Bases: nn . Module Down block This combines ResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required has_attn bool Whether to use attention block False activation nn . Module Activation function 'gelu' norm bool Whether to use normalization False Source code in pdearena/modules/twod_unet.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 class DownBlock ( nn . Module ): \"\"\"Down block This combines [`ResidualBlock`][pdearena.modules.twod_unet.ResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the first half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels has_attn (bool): Whether to use attention block activation (nn.Module): Activation function norm (bool): Whether to use normalization \"\"\" def __init__ ( self , in_channels : int , out_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () self . res = ResidualBlock ( in_channels , out_channels , activation = activation , norm = norm ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x Downsample \u00a4 Bases: nn . Module Scale down the feature map by \\(\\frac{1}{2} \\times\\) Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required Source code in pdearena/modules/twod_unet.py 374 375 376 377 378 379 380 381 382 383 384 385 386 class Downsample ( nn . Module ): r \"\"\"Scale down the feature map by $\\frac{1}{2} \\times$ Args: n_channels (int): Number of channels in the input and output. \"\"\" def __init__ ( self , n_channels ): super () . __init__ () self . conv = nn . Conv2d ( n_channels , n_channels , ( 3 , 3 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x ) FourierDownBlock \u00a4 Bases: nn . Module Down block This combines FourierResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Source code in pdearena/modules/twod_unet.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 class FourierDownBlock ( nn . Module ): \"\"\"Down block This combines [`FourierResidualBlock`][pdearena.modules.twod_unet.FourierResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the first half of U-Net at each resolution. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () self . res = FourierResidualBlock ( in_channels , out_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x FourierResidualBlock \u00a4 Bases: nn . Module Fourier Residual Block to be used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required modes1 int Number of modes in the first dimension. 16 modes2 int Number of modes in the second dimension. 16 activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 Source code in pdearena/modules/twod_unet.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class FourierResidualBlock ( nn . Module ): \"\"\"Fourier Residual Block to be used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. modes1 (int): Number of modes in the first dimension. modes2 (int): Number of modes in the second dimension. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int = 16 , modes2 : int = 16 , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , ): super () . __init__ () self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . modes1 = modes1 self . modes2 = modes2 self . fourier1 = SpectralConv2d ( in_channels , out_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) self . fourier2 = SpectralConv2d ( out_channels , out_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv2 = nn . Conv2d ( out_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () def forward ( self , x : torch . Tensor ): # using pre-norms h = self . activation ( self . norm1 ( x )) x1 = self . fourier1 ( h ) x2 = self . conv1 ( h ) out = x1 + x2 out = self . activation ( self . norm2 ( out )) x1 = self . fourier2 ( out ) x2 = self . conv2 ( out ) out = x1 + x2 + self . shortcut ( x ) return out FourierUnet \u00a4 Bases: nn . Module Unet with Fourier layers in early downsampling blocks. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of channels in the first layer. required activation str Activation function to use. required modes1 int Number of Fourier modes to use in the first spatial dimension. 12 modes2 int Number of Fourier modes to use in the second spatial dimension. 12 norm bool Whether to use normalization. False ch_mults list List of integers to multiply the number of channels by at each resolution. (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention at each resolution. (False, False, False, False) mid_attn bool Whether to use attention in the middle block. False n_blocks int Number of blocks to use at each resolution. 2 n_fourier_layers int Number of early downsampling layers to use Fourier layers in. 2 mode_scaling bool Whether to scale the number of modes with resolution. True use1x1 bool Whether to use 1x1 convolutions in the initial and final layer. False Source code in pdearena/modules/twod_unet.py 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 class FourierUnet ( nn . Module ): \"\"\"Unet with Fourier layers in early downsampling blocks. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of channels in the first layer. activation (str): Activation function to use. modes1 (int): Number of Fourier modes to use in the first spatial dimension. modes2 (int): Number of Fourier modes to use in the second spatial dimension. norm (bool): Whether to use normalization. ch_mults (list): List of integers to multiply the number of channels by at each resolution. is_attn (list): List of booleans indicating whether to use attention at each resolution. mid_attn (bool): Whether to use attention in the middle block. n_blocks (int): Number of blocks to use at each resolution. n_fourier_layers (int): Number of early downsampling layers to use Fourier layers in. mode_scaling (bool): Whether to scale the number of modes with resolution. use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layer. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , modes1 : int = 12 , modes2 : int = 12 , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , n_fourier_layers : int = 2 , mode_scaling : bool = True , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] if i < n_fourier_layers : for _ in range ( n_blocks ): down . append ( FourierDownBlock ( in_channels , out_channels , modes1 = max ( modes1 // 2 ** i , 4 ) if mode_scaling else modes1 , modes2 = max ( modes2 // 2 ** i , 4 ) if mode_scaling else modes2 , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels else : # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , has_attn = mid_attn , activation = activation , norm = norm ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm )) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) if use1x1 : self . final = nn . Conv2d ( n_channels , out_channels , kernel_size = 1 ) else : self . final = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) def forward ( self , x : torch . Tensor ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C x = self . image_proj ( x ) h = [ x ] for m in self . down : x = m ( x ) h . append ( x ) x = self . middle ( x ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x ) x = self . final ( self . activation ( self . norm ( x ))) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) FourierUpBlock \u00a4 Bases: nn . Module Up block that combines FourierResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Note We currently don't recommend using this block. Source code in pdearena/modules/twod_unet.py 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 class FourierUpBlock ( nn . Module ): \"\"\"Up block that combines [`FourierResidualBlock`][pdearena.modules.twod_unet.FourierResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the second half of U-Net at each resolution. Note: We currently don't recommend using this block. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = FourierResidualBlock ( in_channels + out_channels , out_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x MiddleBlock \u00a4 Bases: nn . Module Middle block It combines a ResidualBlock , AttentionBlock , followed by another ResidualBlock . This block is applied at the lowest resolution of the U-Net. Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required has_attn bool Whether to use attention block. Defaults to False. False activation str Activation function to use. Defaults to \"gelu\". 'gelu' norm bool Whether to use normalization. Defaults to False. False Source code in pdearena/modules/twod_unet.py 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 class MiddleBlock ( nn . Module ): \"\"\"Middle block It combines a `ResidualBlock`, `AttentionBlock`, followed by another `ResidualBlock`. This block is applied at the lowest resolution of the U-Net. Args: n_channels (int): Number of channels in the input and output. has_attn (bool, optional): Whether to use attention block. Defaults to False. activation (str): Activation function to use. Defaults to \"gelu\". norm (bool, optional): Whether to use normalization. Defaults to False. \"\"\" def __init__ ( self , n_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False ): super () . __init__ () self . res1 = ResidualBlock ( n_channels , n_channels , activation = activation , norm = norm ) self . attn = AttentionBlock ( n_channels ) if has_attn else nn . Identity () self . res2 = ResidualBlock ( n_channels , n_channels , activation = activation , norm = norm ) def forward ( self , x : torch . Tensor ): x = self . res1 ( x ) x = self . attn ( x ) x = self . res2 ( x ) return x ResidualBlock \u00a4 Bases: nn . Module Wide Residual Blocks used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 Source code in pdearena/modules/twod_unet.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class ResidualBlock ( nn . Module ): \"\"\"Wide Residual Blocks used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , ): super () . __init__ () self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) self . conv2 = nn . Conv2d ( out_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () def forward ( self , x : torch . Tensor ): # First convolution layer h = self . conv1 ( self . activation ( self . norm1 ( x ))) # Second convolution layer h = self . conv2 ( self . activation ( self . norm2 ( h ))) # Add the shortcut connection and return return h + self . shortcut ( x ) Unet \u00a4 Bases: nn . Module Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input required time_future int Number of time steps in the output required hidden_channels int Number of channels in the hidden layers required activation str Activation function to use required norm bool Whether to use normalization False ch_mults list List of channel multipliers for each resolution (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention blocks (False, False, False, False) mid_attn bool Whether to use attention block in the middle block False n_blocks int Number of residual blocks in each resolution 2 use1x1 bool Whether to use 1x1 convolutions in the initial and final layers False Source code in pdearena/modules/twod_unet.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 class Unet ( nn . Module ): \"\"\"Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input time_future (int): Number of time steps in the output hidden_channels (int): Number of channels in the hidden layers activation (str): Activation function to use norm (bool): Whether to use normalization ch_mults (list): List of channel multipliers for each resolution is_attn (list): List of booleans indicating whether to use attention blocks mid_attn (bool): Whether to use attention block in the middle block n_blocks (int): Number of residual blocks in each resolution use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layers \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , has_attn = mid_attn , activation = activation , norm = norm ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm )) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) # if use1x1 : self . final = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 ) else : self . final = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) def forward ( self , x : torch . Tensor ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C x = self . image_proj ( x ) h = [ x ] for m in self . down : x = m ( x ) h . append ( x ) x = self . middle ( x ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x ) x = self . final ( self . activation ( self . norm ( x ))) x = x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) return x UpBlock \u00a4 Bases: nn . Module Up block that combines ResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required has_attn bool Whether to use attention block False activation str Activation function 'gelu' norm bool Whether to use normalization False Source code in pdearena/modules/twod_unet.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 class UpBlock ( nn . Module ): \"\"\"Up block that combines [`ResidualBlock`][pdearena.modules.twod_unet.ResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the second half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels has_attn (bool): Whether to use attention block activation (str): Activation function norm (bool): Whether to use normalization \"\"\" def __init__ ( self , in_channels : int , out_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = ResidualBlock ( in_channels + out_channels , out_channels , activation = activation , norm = norm ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x Upsample \u00a4 Bases: nn . Module Scale up the feature map by \\(2 \\times\\) Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required Source code in pdearena/modules/twod_unet.py 359 360 361 362 363 364 365 366 367 368 369 370 371 class Upsample ( nn . Module ): r \"\"\"Scale up the feature map by $2 \\times$ Args: n_channels (int): Number of channels in the input and output. \"\"\" def __init__ ( self , n_channels : int ): super () . __init__ () self . conv = nn . ConvTranspose2d ( n_channels , n_channels , ( 4 , 4 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x )","title":"Architecture Modules"},{"location":"reference/modules/#available-pde-surrogate-modules","text":"","title":"Available PDE Surrogate Modules"},{"location":"reference/modules/#pdearena.modules.fourier.SpectralConv2d","text":"Bases: nn . Module 2D Fourier layer. Does FFT, linear transform, and Inverse FFT. Implemented in a way to allow multi-gpu training. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required modes1 int Number of Fourier modes to keep in the first spatial direction required modes2 int Number of Fourier modes to keep in the second spatial direction required paper Source code in pdearena/modules/fourier.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class SpectralConv2d ( nn . Module ): \"\"\"2D Fourier layer. Does FFT, linear transform, and Inverse FFT. Implemented in a way to allow multi-gpu training. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels modes1 (int): Number of Fourier modes to keep in the first spatial direction modes2 (int): Number of Fourier modes to keep in the second spatial direction [paper](https://arxiv.org/abs/2010.08895) \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int , modes2 : int ): super () . __init__ () self . in_channels = in_channels self . out_channels = out_channels self . modes1 = modes1 # Number of Fourier modes to multiply, at most floor(N/2) + 1 self . modes2 = modes2 self . scale = 1 / ( in_channels * out_channels ) self . weights1 = nn . Parameter ( self . scale * torch . rand ( in_channels , out_channels , self . modes1 , self . modes2 , 2 , dtype = torch . float32 ) ) self . weights2 = nn . Parameter ( self . scale * torch . rand ( in_channels , out_channels , self . modes1 , self . modes2 , 2 , dtype = torch . float32 ) ) def forward ( self , x , x_dim = None , y_dim = None ): batchsize = x . shape [ 0 ] # Compute Fourier coeffcients up to factor of e^(- something constant) x_ft = torch . fft . rfft2 ( x ) # Multiply relevant Fourier modes out_ft = torch . zeros ( batchsize , self . out_channels , x . size ( - 2 ), x . size ( - 1 ) // 2 + 1 , dtype = torch . cfloat , device = x . device , ) out_ft [:, :, : self . modes1 , : self . modes2 ] = batchmul2d ( x_ft [:, :, : self . modes1 , : self . modes2 ], torch . view_as_complex ( self . weights1 ) ) out_ft [:, :, - self . modes1 :, : self . modes2 ] = batchmul2d ( x_ft [:, :, - self . modes1 :, : self . modes2 ], torch . view_as_complex ( self . weights2 ) ) # Return to physical space x = torch . fft . irfft2 ( out_ft , s = ( x . size ( - 2 ), x . size ( - 1 ))) return x","title":"SpectralConv2d"},{"location":"reference/modules/#pdearena.modules.twod_resnet.DilatedBasicBlock","text":"Bases: nn . Module Basic block for Dilated ResNet Parameters: Name Type Description Default in_planes int number of input channels required planes int number of output channels required stride int stride of the convolution. Defaults to 1. 1 activation str activation function. Defaults to \"relu\". 'relu' norm bool whether to use group normalization. Defaults to True. True num_groups int number of groups for group normalization. Defaults to 1. 1 Source code in pdearena/modules/twod_resnet.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class DilatedBasicBlock ( nn . Module ): \"\"\"Basic block for Dilated ResNet Args: in_planes (int): number of input channels planes (int): number of output channels stride (int, optional): stride of the convolution. Defaults to 1. activation (str, optional): activation function. Defaults to \"relu\". norm (bool, optional): whether to use group normalization. Defaults to True. num_groups (int, optional): number of groups for group normalization. Defaults to 1. \"\"\" expansion = 1 def __init__ ( self , in_planes : int , planes : int , stride : int = 1 , activation : str = \"relu\" , norm : bool = True , num_groups : int = 1 , ): super () . __init__ () self . dilation = [ 1 , 2 , 4 , 8 , 4 , 2 , 1 ] dilation_layers = [] for dil in self . dilation : dilation_layers . append ( nn . Conv2d ( in_planes , planes , kernel_size = 3 , stride = stride , dilation = dil , padding = dil , bias = True , ) ) self . dilation_layers = nn . ModuleList ( dilation_layers ) self . norm_layers = nn . ModuleList ( nn . GroupNorm ( num_groups , num_channels = planes ) if norm else nn . Identity () for dil in self . dilation ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : out = x for layer , norm in zip ( self . dilation_layers , self . norm_layers ): out = self . activation ( layer ( norm ( out ))) return out + x","title":"DilatedBasicBlock"},{"location":"reference/modules/#pdearena.modules.twod_resnet.FourierBasicBlock","text":"Bases: nn . Module Basic block for Fourier Neural Operators Parameters: Name Type Description Default in_planes int number of input channels required planes int number of output channels required stride int stride of the convolution. Defaults to 1. 1 modes1 int number of modes for the first spatial dimension. Defaults to 16. 16 modes2 int number of modes for the second spatial dimension. Defaults to 16. 16 activation str activation function. Defaults to \"relu\". 'gelu' norm bool whether to use group normalization. Defaults to False. False Source code in pdearena/modules/twod_resnet.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 class FourierBasicBlock ( nn . Module ): \"\"\"Basic block for Fourier Neural Operators Args: in_planes (int): number of input channels planes (int): number of output channels stride (int, optional): stride of the convolution. Defaults to 1. modes1 (int, optional): number of modes for the first spatial dimension. Defaults to 16. modes2 (int, optional): number of modes for the second spatial dimension. Defaults to 16. activation (str, optional): activation function. Defaults to \"relu\". norm (bool, optional): whether to use group normalization. Defaults to False. \"\"\" expansion : int = 1 def __init__ ( self , in_planes : int , planes : int , stride : int = 1 , modes1 : int = 16 , modes2 : int = 16 , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () self . modes1 = modes1 self . modes2 = modes2 assert not norm self . fourier1 = SpectralConv2d ( in_planes , planes , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv1 = nn . Conv2d ( in_planes , planes , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" , bias = True ) self . fourier2 = SpectralConv2d ( planes , planes , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv2 = nn . Conv2d ( planes , planes , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" , bias = True ) # So far shortcut connections are not helping # self.shortcut = nn.Sequential() # if stride != 1 or in_planes != self.expansion * planes: # self.shortcut = nn.Sequential( # nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1) # ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) def forward ( self , x : torch . Tensor ) -> torch . Tensor : x1 = self . fourier1 ( x ) x2 = self . conv1 ( x ) out = self . activation ( x1 + x2 ) x1 = self . fourier2 ( out ) x2 = self . conv2 ( out ) out = x1 + x2 # out += self.shortcut(x) out = self . activation ( out ) return out","title":"FourierBasicBlock"},{"location":"reference/modules/#pdearena.modules.twod_resnet.ResNet","text":"Bases: nn . Module Class to support ResNet like feedforward architectures Parameters: Name Type Description Default n_input_scalar_components int Number of input scalar components in the model required n_input_vector_components int Number of input vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required block Callable BasicBlock or DilatedBasicBlock or FourierBasicBlock required num_blocks List [ int ] Number of blocks in each layer required time_history int Number of time steps to use in the input required time_future int Number of time steps to predict in the output required hidden_channels int Number of channels in the hidden layers 64 activation str Activation function to use 'gelu' norm bool Whether to use normalization True Source code in pdearena/modules/twod_resnet.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 class ResNet ( nn . Module ): \"\"\"Class to support ResNet like feedforward architectures Args: n_input_scalar_components (int): Number of input scalar components in the model n_input_vector_components (int): Number of input vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model block (Callable): BasicBlock or DilatedBasicBlock or FourierBasicBlock num_blocks (List[int]): Number of blocks in each layer time_history (int): Number of time steps to use in the input time_future (int): Number of time steps to predict in the output hidden_channels (int): Number of channels in the hidden layers activation (str): Activation function to use norm (bool): Whether to use normalization \"\"\" padding = 9 def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , block , num_blocks : list , time_history : int , time_future : int , hidden_channels : int = 64 , activation : str = \"gelu\" , norm : bool = True , diffmode : bool = False , usegrid : bool = False , ): super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . diffmode = diffmode self . usegrid = usegrid self . in_planes = hidden_channels insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) if self . usegrid : insize += 2 self . conv_in1 = nn . Conv2d ( insize , self . in_planes , kernel_size = 1 , bias = True , ) self . conv_in2 = nn . Conv2d ( self . in_planes , self . in_planes , kernel_size = 1 , bias = True , ) self . conv_out1 = nn . Conv2d ( self . in_planes , self . in_planes , kernel_size = 1 , bias = True , ) self . conv_out2 = nn . Conv2d ( self . in_planes , time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), kernel_size = 1 , bias = True , ) self . layers = nn . ModuleList ( [ self . _make_layer ( block , self . in_planes , num_blocks [ i ], stride = 1 , activation = activation , norm = norm , ) for i in range ( len ( num_blocks )) ] ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) def _make_layer ( self , block : Callable , planes : int , num_blocks : int , stride : int , activation : str , norm : bool = True , ) -> nn . Sequential : strides = [ stride ] + [ 1 ] * ( num_blocks - 1 ) layers = [] for stride in strides : layers . append ( block ( self . in_planes , planes , stride , activation = activation , norm = norm , ) ) self . in_planes = planes * block . expansion return nn . Sequential ( * layers ) def __repr__ ( self ): return \"ResNet\" def forward ( self , x : torch . Tensor ) -> torch . Tensor : assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C # prev = x.float() x = self . activation ( self . conv_in1 ( x . float ())) x = self . activation ( self . conv_in2 ( x . float ())) if self . padding > 0 : x = F . pad ( x , [ 0 , self . padding , 0 , self . padding ]) for layer in self . layers : x = layer ( x ) if self . padding > 0 : x = x [ ... , : - self . padding , : - self . padding ] x = self . activation ( self . conv_out1 ( x )) x = self . conv_out2 ( x ) if self . diffmode : raise NotImplementedError ( \"diffmode\" ) # x = x + prev[:, -1:, ...].detach() return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] )","title":"ResNet"},{"location":"reference/modules/#pdearena.modules.twod_uno.OperatorBlock_2D","text":"Bases: nn . Module Parameters: Name Type Description Default in_codim int Input co-domian dimension required out_codim int output co-domain dimension required dim1 int Default output grid size along x (or 1st dimension) required dim2 int Default output grid size along y ( or 2nd dimension) required modes1 int Number of fourier modes to consider along 1st dimension required modes2 int Number of fourier modes to consider along 2nd dimension required norm bool Whether to use normalization ( torch.nn.InstanceNorm2d ) True nonlin bool Whether to use non-linearity ( torch.nn.GELU ) True All variables are consistent with the SpectralConv2d_Uno . Source code in pdearena/modules/twod_uno.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 class OperatorBlock_2D ( nn . Module ): \"\"\" Args: in_codim (int): Input co-domian dimension out_codim (int): output co-domain dimension dim1 (int): Default output grid size along x (or 1st dimension) dim2 (int): Default output grid size along y ( or 2nd dimension) modes1 (int): Number of fourier modes to consider along 1st dimension modes2 (int): Number of fourier modes to consider along 2nd dimension norm (bool): Whether to use normalization ([torch.nn.InstanceNorm2d][]) nonlin (bool): Whether to use non-linearity ([torch.nn.GELU][]) All variables are consistent with the [`SpectralConv2d_Uno`][pdearena.modules.twod_uno.SpectralConv2d_Uno]. \"\"\" def __init__ ( self , in_codim , out_codim , dim1 , dim2 , modes1 , modes2 , norm = True , nonlin = True ): super () . __init__ () self . conv = SpectralConv2d_Uno ( in_codim , out_codim , dim1 , dim2 , modes1 , modes2 ) self . w = Pointwise_op_2D ( in_codim , out_codim , dim1 , dim2 ) self . norm = norm self . non_lin = nonlin if norm : self . normalize_layer = nn . InstanceNorm2d ( int ( out_codim ), affine = True ) def forward ( self , x , dim1 = None , dim2 = None ): # # input shape = (batch, in_codim, input_dim1,input_dim2) # output shape = (batch, out_codim, dim1,dim2) x1_out = self . conv ( x , dim1 , dim2 ) x2_out = self . w ( x , dim1 , dim2 ) x_out = x1_out + x2_out if self . norm : x_out = self . normalize_layer ( x_out ) if self . non_lin : x_out = F . gelu ( x_out ) return x_out","title":"OperatorBlock_2D"},{"location":"reference/modules/#pdearena.modules.twod_uno.Pointwise_op_2D","text":"Bases: nn . Module Parameters: Name Type Description Default in_codim int Input co-domian dimension required out_codim int output co-domain dimension required dim1 int Default output grid size along x (or 1st dimension) required dim2 int Default output grid size along y ( or 2nd dimension) required Source code in pdearena/modules/twod_uno.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 class Pointwise_op_2D ( nn . Module ): \"\"\" Args: in_codim (int): Input co-domian dimension out_codim (int): output co-domain dimension dim1 (int): Default output grid size along x (or 1st dimension) dim2 (int): Default output grid size along y ( or 2nd dimension) \"\"\" def __init__ ( self , in_codim : int , out_codim : int , dim1 : int , dim2 : int ): super () . __init__ () self . conv = nn . Conv2d ( int ( in_codim ), int ( out_codim ), 1 ) self . dim1 = int ( dim1 ) self . dim2 = int ( dim2 ) def forward ( self , x , dim1 = None , dim2 = None ): # # input shape = (batch, in_codim, input_dim1,input_dim2) # output shape = (batch, out_codim, dim1,dim2) if dim1 is None : dim1 = self . dim1 dim2 = self . dim2 x_out = self . conv ( x ) x_out = F . interpolate ( x_out , size = ( dim1 , dim2 ), mode = \"bicubic\" , align_corners = True , antialias = True ) return x_out","title":"Pointwise_op_2D"},{"location":"reference/modules/#pdearena.modules.twod_uno.SpectralConv2d_Uno","text":"Bases: nn . Module 2D Fourier layer. It does FFT, linear transform, and Inverse FFT. Modified to support multi-gpu training. Parameters: Name Type Description Default in_codim int Input co-domian dimension required out_codim int output co-domain dimension required dim1 int Default output grid size along x (or 1st dimension of output domain) required dim2 int Default output grid size along y ( or 2nd dimension of output domain) Ratio of grid size of the input and the output implecitely set the expansion or contraction farctor along each dimension. required modes1 int), modes2 (int Number of fourier modes to consider for the ontegral operator Number of modes must be compatibale with the input grid size and desired output grid size. i.e., modes1 <= min( dim1/2, input_dim1/2). Here \"input_dim1\" is the grid size along x axis (or first dimension) of the input domain. Other modes also the have same constrain. None Source code in pdearena/modules/twod_uno.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class SpectralConv2d_Uno ( nn . Module ): \"\"\"2D Fourier layer. It does FFT, linear transform, and Inverse FFT. Modified to support multi-gpu training. Args: in_codim (int): Input co-domian dimension out_codim (int): output co-domain dimension dim1 (int): Default output grid size along x (or 1st dimension of output domain) dim2 (int): Default output grid size along y ( or 2nd dimension of output domain) Ratio of grid size of the input and the output implecitely set the expansion or contraction farctor along each dimension. modes1 (int), modes2 (int): Number of fourier modes to consider for the ontegral operator Number of modes must be compatibale with the input grid size and desired output grid size. i.e., modes1 <= min( dim1/2, input_dim1/2). Here \"input_dim1\" is the grid size along x axis (or first dimension) of the input domain. Other modes also the have same constrain. \"\"\" def __init__ ( self , in_codim , out_codim , dim1 , dim2 , modes1 = None , modes2 = None ): super () . __init__ () in_codim = int ( in_codim ) out_codim = int ( out_codim ) self . in_channels = in_codim self . out_channels = out_codim self . dim1 = dim1 self . dim2 = dim2 if modes1 is not None : self . modes1 = modes1 self . modes2 = modes2 else : self . modes1 = dim1 // 2 - 1 self . modes2 = dim2 // 2 self . scale = ( 1 / ( 2 * in_codim )) ** ( 1.0 / 2.0 ) self . weights1 = nn . Parameter ( self . scale * ( torch . randn ( in_codim , out_codim , self . modes1 , self . modes2 , 2 , dtype = torch . float32 )) ) self . weights2 = nn . Parameter ( self . scale * ( torch . randn ( in_codim , out_codim , self . modes1 , self . modes2 , 2 , dtype = torch . float32 )) ) # Complex multiplication def compl_mul2d ( self , input , weights ): return torch . einsum ( \"bixy,ioxy->boxy\" , input , weights ) def forward ( self , x , dim1 = None , dim2 = None ): if dim1 is not None : self . dim1 = dim1 self . dim2 = dim2 batchsize = x . shape [ 0 ] # Compute Fourier coeffcients up to factor of e^(- something constant) x_ft = torch . fft . rfft2 ( x , norm = \"forward\" ) # Multiply relevant Fourier modes out_ft = torch . zeros ( batchsize , self . out_channels , self . dim1 , self . dim2 // 2 + 1 , dtype = torch . cfloat , device = x . device , ) out_ft [:, :, : self . modes1 , : self . modes2 ] = self . compl_mul2d ( x_ft [:, :, : self . modes1 , : self . modes2 ], torch . view_as_complex ( self . weights1 ) ) out_ft [:, :, - self . modes1 :, : self . modes2 ] = self . compl_mul2d ( x_ft [:, :, - self . modes1 :, : self . modes2 ], torch . view_as_complex ( self . weights2 ) ) # Return to physical space x = torch . fft . irfft2 ( out_ft , s = ( self . dim1 , self . dim2 ), norm = \"forward\" ) return x","title":"SpectralConv2d_Uno"},{"location":"reference/modules/#pdearena.modules.twod_uno.UNO","text":"Bases: nn . Module UNO model Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps to include in the model required time_future int Number of time steps to predict in the model required hidden_channels int Number of hidden channels in the model required pad int Padding to use in the model 0 factor int Scaling factor to use in the model 3 / 4 activation str Activation function to use in the model 'gelu' Source code in pdearena/modules/twod_uno.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 class UNO ( nn . Module ): \"\"\"UNO model Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps to include in the model time_future (int): Number of time steps to predict in the model hidden_channels (int): Number of hidden channels in the model pad (int): Padding to use in the model factor (int): Scaling factor to use in the model activation (str): Activation function to use in the model \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , pad = 0 , factor = 3 / 4 , activation = \"gelu\" , ): super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . width = hidden_channels self . factor = factor self . padding = pad self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) in_width = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) out_width = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) self . fc = nn . Linear ( in_width , self . width // 2 ) self . fc0 = nn . Linear ( self . width // 2 , self . width ) # input channel is 3: (a(x, y), x, y) self . L0 = OperatorBlock_2D ( self . width , 2 * factor * self . width , 48 , 48 , 18 , 18 ) self . L1 = OperatorBlock_2D ( 2 * factor * self . width , 4 * factor * self . width , 32 , 32 , 14 , 14 ) self . L2 = OperatorBlock_2D ( 4 * factor * self . width , 8 * factor * self . width , 16 , 16 , 6 , 6 ) self . L3 = OperatorBlock_2D ( 8 * factor * self . width , 8 * factor * self . width , 16 , 16 , 6 , 6 ) self . L4 = OperatorBlock_2D ( 8 * factor * self . width , 4 * factor * self . width , 32 , 32 , 6 , 6 ) self . L5 = OperatorBlock_2D ( 8 * factor * self . width , 2 * factor * self . width , 48 , 48 , 14 , 14 ) self . L6 = OperatorBlock_2D ( 4 * factor * self . width , self . width , 64 , 64 , 18 , 18 ) # will be reshaped self . fc1 = nn . Linear ( 2 * self . width , 4 * self . width ) self . fc2 = nn . Linear ( 4 * self . width , out_width ) def forward ( self , x ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C x = x . permute ( 0 , 2 , 3 , 1 ) x_fc = self . fc ( x ) x_fc = self . activation ( x_fc ) x_fc0 = self . fc0 ( x_fc ) x_fc0 = self . activation ( x_fc0 ) x_fc0 = x_fc0 . permute ( 0 , 3 , 1 , 2 ) x_fc0 = F . pad ( x_fc0 , [ self . padding , self . padding , self . padding , self . padding ]) D1 , D2 = x_fc0 . shape [ - 2 ], x_fc0 . shape [ - 1 ] x_c0 = self . L0 ( x_fc0 , int ( D1 * self . factor ), int ( D2 * self . factor )) x_c1 = self . L1 ( x_c0 , D1 // 2 , D2 // 2 ) x_c2 = self . L2 ( x_c1 , D1 // 4 , D2 // 4 ) x_c3 = self . L3 ( x_c2 , D1 // 4 , D2 // 4 ) x_c4 = self . L4 ( x_c3 , D1 // 2 , D2 // 2 ) x_c4 = torch . cat ([ x_c4 , x_c1 ], dim = 1 ) x_c5 = self . L5 ( x_c4 , int ( D1 * self . factor ), int ( D2 * self . factor )) x_c5 = torch . cat ([ x_c5 , x_c0 ], dim = 1 ) x_c6 = self . L6 ( x_c5 , D1 , D2 ) x_c6 = torch . cat ([ x_c6 , x_fc0 ], dim = 1 ) if self . padding != 0 : x_c6 = x_c6 [ ... , : - self . padding , : - self . padding ] x_c6 = x_c6 . permute ( 0 , 2 , 3 , 1 ) x_fc1 = self . fc1 ( x_c6 ) x_fc1 = self . activation ( x_fc1 ) x_out = self . fc2 ( x_fc1 ) x_out = x_out . permute ( 0 , 3 , 1 , 2 ) return x_out . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] )","title":"UNO"},{"location":"reference/modules/#pdearena.modules.twod_unet2015.Unet2015","text":"Bases: nn . Module Two-dimensional UNet based on original architecture. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of hidden channels. required activation str Activation function. required Source code in pdearena/modules/twod_unet2015.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 class Unet2015 ( nn . Module ): \"\"\"Two-dimensional UNet based on original architecture. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of hidden channels. activation (str): Activation function. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) in_channels = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) features = hidden_channels self . encoder1 = Unet2015 . _block ( in_channels , features , name = \"enc1\" , activation = self . activation ) self . pool1 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . encoder2 = Unet2015 . _block ( features , features * 2 , name = \"enc2\" , activation = self . activation ) self . pool2 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . encoder3 = Unet2015 . _block ( features * 2 , features * 4 , name = \"enc3\" , activation = self . activation ) self . pool3 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . encoder4 = Unet2015 . _block ( features * 4 , features * 8 , name = \"enc4\" , activation = self . activation ) self . pool4 = nn . MaxPool2d ( kernel_size = 2 , stride = 2 ) self . bottleneck = Unet2015 . _block ( features * 8 , features * 16 , name = \"bottleneck\" , activation = self . activation ) self . upconv4 = nn . ConvTranspose2d ( features * 16 , features * 8 , kernel_size = 2 , stride = 2 ) self . decoder4 = Unet2015 . _block (( features * 8 ) * 2 , features * 8 , name = \"dec4\" , activation = self . activation ) self . upconv3 = nn . ConvTranspose2d ( features * 8 , features * 4 , kernel_size = 2 , stride = 2 ) self . decoder3 = Unet2015 . _block (( features * 4 ) * 2 , features * 4 , name = \"dec3\" , activation = self . activation ) self . upconv2 = nn . ConvTranspose2d ( features * 4 , features * 2 , kernel_size = 2 , stride = 2 ) self . decoder2 = Unet2015 . _block (( features * 2 ) * 2 , features * 2 , name = \"dec2\" , activation = self . activation ) self . upconv1 = nn . ConvTranspose2d ( features * 2 , features , kernel_size = 2 , stride = 2 ) self . decoder1 = Unet2015 . _block ( features * 2 , features , name = \"dec1\" , activation = self . activation ) self . conv = nn . Conv2d ( in_channels = features , out_channels = out_channels , kernel_size = 1 ) def forward ( self , x ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) enc1 = self . encoder1 ( x ) enc2 = self . encoder2 ( self . pool1 ( enc1 )) enc3 = self . encoder3 ( self . pool2 ( enc2 )) enc4 = self . encoder4 ( self . pool3 ( enc3 )) bottleneck = self . bottleneck ( self . pool4 ( enc4 )) dec4 = self . upconv4 ( bottleneck ) dec4 = torch . cat (( dec4 , enc4 ), dim = 1 ) dec4 = self . decoder4 ( dec4 ) dec3 = self . upconv3 ( dec4 ) dec3 = torch . cat (( dec3 , enc3 ), dim = 1 ) dec3 = self . decoder3 ( dec3 ) dec2 = self . upconv2 ( dec3 ) dec2 = torch . cat (( dec2 , enc2 ), dim = 1 ) dec2 = self . decoder2 ( dec2 ) dec1 = self . upconv1 ( dec2 ) dec1 = torch . cat (( dec1 , enc1 ), dim = 1 ) dec1 = self . decoder1 ( dec1 ) out = self . conv ( dec1 ) return out . reshape ( orig_shape [ 0 ], - 1 , * orig_shape [ 2 :]) @staticmethod def _block ( in_channels , features , name , activation = nn . Tanh ()): return nn . Sequential ( OrderedDict ( [ ( name + \"conv1\" , nn . Conv2d ( in_channels = in_channels , out_channels = features , kernel_size = 3 , padding = 1 , bias = False , ), ), ( name + \"norm1\" , nn . BatchNorm2d ( num_features = features )), ( name + \"act1\" , activation ), ( name + \"conv2\" , nn . Conv2d ( in_channels = features , out_channels = features , kernel_size = 3 , padding = 1 , bias = False , ), ), ( name + \"norm2\" , nn . BatchNorm2d ( num_features = features )), ( name + \"act2\" , activation ), ] ) )","title":"Unet2015"},{"location":"reference/modules/#pdearena.modules.twod_unetbase.Unetbase","text":"Bases: nn . Module Our interpretation of the original U-Net architecture. Uses torch.nn.GroupNorm instead of torch.nn.BatchNorm2d . Also there is no BottleNeck block. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of channels in the hidden layers. required activation str Activation function to use. One of [\"gelu\", \"relu\", \"silu\"]. 'gelu' Source code in pdearena/modules/twod_unetbase.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 class Unetbase ( nn . Module ): \"\"\"Our interpretation of the original U-Net architecture. Uses [torch.nn.GroupNorm][] instead of [torch.nn.BatchNorm2d][]. Also there is no `BottleNeck` block. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of channels in the hidden layers. activation (str): Activation function to use. One of [\"gelu\", \"relu\", \"silu\"]. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation = \"gelu\" , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels self . image_proj = ConvBlock ( insize , n_channels , activation = activation ) self . down = nn . ModuleList ( [ Down ( n_channels , n_channels * 2 , activation = activation ), Down ( n_channels * 2 , n_channels * 4 , activation = activation ), Down ( n_channels * 4 , n_channels * 8 , activation = activation ), Down ( n_channels * 8 , n_channels * 16 , activation = activation ), ] ) self . up = nn . ModuleList ( [ Up ( n_channels * 16 , n_channels * 8 , activation = activation ), Up ( n_channels * 8 , n_channels * 4 , activation = activation ), Up ( n_channels * 4 , n_channels * 2 , activation = activation ), Up ( n_channels * 2 , n_channels , activation = activation ), ] ) out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) # should there be a final norm too? but we aren't doing \"prenorm\" in the original self . final = nn . Conv2d ( n_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) def forward ( self , x ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) h = self . image_proj ( x ) x1 = self . down [ 0 ]( h ) x2 = self . down [ 1 ]( x1 ) x3 = self . down [ 2 ]( x2 ) x4 = self . down [ 3 ]( x3 ) x = self . up [ 0 ]( x4 , x3 ) x = self . up [ 1 ]( x , x2 ) x = self . up [ 2 ]( x , x1 ) x = self . up [ 3 ]( x , h ) x = self . final ( x ) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] )","title":"Unetbase"},{"location":"reference/modules/#pdearena.modules.twod_unet.AttentionBlock","text":"Bases: nn . Module Attention block This is similar to [transformer multi-head attention] Parameters: Name Type Description Default n_channels int the number of channels in the input required n_heads int the number of heads in multi-head attention 1 d_k Optional [ int ] the number of dimensions in each head None n_groups int the number of groups for group normalization . 1 Source code in pdearena/modules/twod_unet.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class AttentionBlock ( nn . Module ): \"\"\"Attention block This is similar to [transformer multi-head attention] Args: n_channels (int): the number of channels in the input n_heads (int): the number of heads in multi-head attention d_k: the number of dimensions in each head n_groups (int): the number of groups for [group normalization][torch.nn.GroupNorm]. \"\"\" def __init__ ( self , n_channels : int , n_heads : int = 1 , d_k : Optional [ int ] = None , n_groups : int = 1 ): super () . __init__ () # Default `d_k` if d_k is None : d_k = n_channels # Normalization layer self . norm = nn . GroupNorm ( n_groups , n_channels ) # Projections for query, key and values self . projection = nn . Linear ( n_channels , n_heads * d_k * 3 ) # Linear layer for final transformation self . output = nn . Linear ( n_heads * d_k , n_channels ) # Scale for dot-product attention self . scale = d_k **- 0.5 # self . n_heads = n_heads self . d_k = d_k def forward ( self , x : torch . Tensor ): # Get shape batch_size , n_channels , height , width = x . shape # Change `x` to shape `[batch_size, seq, n_channels]` x = x . view ( batch_size , n_channels , - 1 ) . permute ( 0 , 2 , 1 ) # Get query, key, and values (concatenated) and shape it to `[batch_size, seq, n_heads, 3 * d_k]` qkv = self . projection ( x ) . view ( batch_size , - 1 , self . n_heads , 3 * self . d_k ) # Split query, key, and values. Each of them will have shape `[batch_size, seq, n_heads, d_k]` q , k , v = torch . chunk ( qkv , 3 , dim =- 1 ) # Calculate scaled dot-product $\\frac{Q K^\\top}{\\sqrt{d_k}}$ attn = torch . einsum ( \"bihd,bjhd->bijh\" , q , k ) * self . scale # Softmax along the sequence dimension $\\underset{seq}{softmax}\\Bigg(\\frac{Q K^\\top}{\\sqrt{d_k}}\\Bigg)$ attn = attn . softmax ( dim = 1 ) # Multiply by values res = torch . einsum ( \"bijh,bjhd->bihd\" , attn , v ) # Reshape to `[batch_size, seq, n_heads * d_k]` res = res . view ( batch_size , - 1 , self . n_heads * self . d_k ) # Transform to `[batch_size, seq, n_channels]` res = self . output ( res ) # Add skip connection res += x # Change to shape `[batch_size, in_channels, height, width]` res = res . permute ( 0 , 2 , 1 ) . view ( batch_size , n_channels , height , width ) return res","title":"AttentionBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.DownBlock","text":"Bases: nn . Module Down block This combines ResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required has_attn bool Whether to use attention block False activation nn . Module Activation function 'gelu' norm bool Whether to use normalization False Source code in pdearena/modules/twod_unet.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 class DownBlock ( nn . Module ): \"\"\"Down block This combines [`ResidualBlock`][pdearena.modules.twod_unet.ResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the first half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels has_attn (bool): Whether to use attention block activation (nn.Module): Activation function norm (bool): Whether to use normalization \"\"\" def __init__ ( self , in_channels : int , out_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () self . res = ResidualBlock ( in_channels , out_channels , activation = activation , norm = norm ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x","title":"DownBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.Downsample","text":"Bases: nn . Module Scale down the feature map by \\(\\frac{1}{2} \\times\\) Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required Source code in pdearena/modules/twod_unet.py 374 375 376 377 378 379 380 381 382 383 384 385 386 class Downsample ( nn . Module ): r \"\"\"Scale down the feature map by $\\frac{1}{2} \\times$ Args: n_channels (int): Number of channels in the input and output. \"\"\" def __init__ ( self , n_channels ): super () . __init__ () self . conv = nn . Conv2d ( n_channels , n_channels , ( 3 , 3 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x )","title":"Downsample"},{"location":"reference/modules/#pdearena.modules.twod_unet.FourierDownBlock","text":"Bases: nn . Module Down block This combines FourierResidualBlock and AttentionBlock . These are used in the first half of U-Net at each resolution. Source code in pdearena/modules/twod_unet.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 class FourierDownBlock ( nn . Module ): \"\"\"Down block This combines [`FourierResidualBlock`][pdearena.modules.twod_unet.FourierResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the first half of U-Net at each resolution. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () self . res = FourierResidualBlock ( in_channels , out_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x","title":"FourierDownBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.FourierResidualBlock","text":"Bases: nn . Module Fourier Residual Block to be used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required modes1 int Number of modes in the first dimension. 16 modes2 int Number of modes in the second dimension. 16 activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 Source code in pdearena/modules/twod_unet.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class FourierResidualBlock ( nn . Module ): \"\"\"Fourier Residual Block to be used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. modes1 (int): Number of modes in the first dimension. modes2 (int): Number of modes in the second dimension. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int = 16 , modes2 : int = 16 , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , ): super () . __init__ () self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . modes1 = modes1 self . modes2 = modes2 self . fourier1 = SpectralConv2d ( in_channels , out_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) self . fourier2 = SpectralConv2d ( out_channels , out_channels , modes1 = self . modes1 , modes2 = self . modes2 ) self . conv2 = nn . Conv2d ( out_channels , out_channels , kernel_size = 1 , padding = 0 , padding_mode = \"zeros\" ) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () def forward ( self , x : torch . Tensor ): # using pre-norms h = self . activation ( self . norm1 ( x )) x1 = self . fourier1 ( h ) x2 = self . conv1 ( h ) out = x1 + x2 out = self . activation ( self . norm2 ( out )) x1 = self . fourier2 ( out ) x2 = self . conv2 ( out ) out = x1 + x2 + self . shortcut ( x ) return out","title":"FourierResidualBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.FourierUnet","text":"Bases: nn . Module Unet with Fourier layers in early downsampling blocks. Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input. required time_future int Number of time steps in the output. required hidden_channels int Number of channels in the first layer. required activation str Activation function to use. required modes1 int Number of Fourier modes to use in the first spatial dimension. 12 modes2 int Number of Fourier modes to use in the second spatial dimension. 12 norm bool Whether to use normalization. False ch_mults list List of integers to multiply the number of channels by at each resolution. (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention at each resolution. (False, False, False, False) mid_attn bool Whether to use attention in the middle block. False n_blocks int Number of blocks to use at each resolution. 2 n_fourier_layers int Number of early downsampling layers to use Fourier layers in. 2 mode_scaling bool Whether to scale the number of modes with resolution. True use1x1 bool Whether to use 1x1 convolutions in the initial and final layer. False Source code in pdearena/modules/twod_unet.py 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 class FourierUnet ( nn . Module ): \"\"\"Unet with Fourier layers in early downsampling blocks. Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input. time_future (int): Number of time steps in the output. hidden_channels (int): Number of channels in the first layer. activation (str): Activation function to use. modes1 (int): Number of Fourier modes to use in the first spatial dimension. modes2 (int): Number of Fourier modes to use in the second spatial dimension. norm (bool): Whether to use normalization. ch_mults (list): List of integers to multiply the number of channels by at each resolution. is_attn (list): List of booleans indicating whether to use attention at each resolution. mid_attn (bool): Whether to use attention in the middle block. n_blocks (int): Number of blocks to use at each resolution. n_fourier_layers (int): Number of early downsampling layers to use Fourier layers in. mode_scaling (bool): Whether to scale the number of modes with resolution. use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layer. \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , modes1 : int = 12 , modes2 : int = 12 , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , n_fourier_layers : int = 2 , mode_scaling : bool = True , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] if i < n_fourier_layers : for _ in range ( n_blocks ): down . append ( FourierDownBlock ( in_channels , out_channels , modes1 = max ( modes1 // 2 ** i , 4 ) if mode_scaling else modes1 , modes2 = max ( modes2 // 2 ** i , 4 ) if mode_scaling else modes2 , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels else : # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , has_attn = mid_attn , activation = activation , norm = norm ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm )) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) if use1x1 : self . final = nn . Conv2d ( n_channels , out_channels , kernel_size = 1 ) else : self . final = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) def forward ( self , x : torch . Tensor ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C x = self . image_proj ( x ) h = [ x ] for m in self . down : x = m ( x ) h . append ( x ) x = self . middle ( x ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x ) x = self . final ( self . activation ( self . norm ( x ))) return x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] )","title":"FourierUnet"},{"location":"reference/modules/#pdearena.modules.twod_unet.FourierUpBlock","text":"Bases: nn . Module Up block that combines FourierResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Note We currently don't recommend using this block. Source code in pdearena/modules/twod_unet.py 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 class FourierUpBlock ( nn . Module ): \"\"\"Up block that combines [`FourierResidualBlock`][pdearena.modules.twod_unet.FourierResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the second half of U-Net at each resolution. Note: We currently don't recommend using this block. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , modes1 : int = 16 , modes2 : int = 16 , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = FourierResidualBlock ( in_channels + out_channels , out_channels , modes1 = modes1 , modes2 = modes2 , activation = activation , norm = norm , ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x","title":"FourierUpBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.MiddleBlock","text":"Bases: nn . Module Middle block It combines a ResidualBlock , AttentionBlock , followed by another ResidualBlock . This block is applied at the lowest resolution of the U-Net. Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required has_attn bool Whether to use attention block. Defaults to False. False activation str Activation function to use. Defaults to \"gelu\". 'gelu' norm bool Whether to use normalization. Defaults to False. False Source code in pdearena/modules/twod_unet.py 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 class MiddleBlock ( nn . Module ): \"\"\"Middle block It combines a `ResidualBlock`, `AttentionBlock`, followed by another `ResidualBlock`. This block is applied at the lowest resolution of the U-Net. Args: n_channels (int): Number of channels in the input and output. has_attn (bool, optional): Whether to use attention block. Defaults to False. activation (str): Activation function to use. Defaults to \"gelu\". norm (bool, optional): Whether to use normalization. Defaults to False. \"\"\" def __init__ ( self , n_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False ): super () . __init__ () self . res1 = ResidualBlock ( n_channels , n_channels , activation = activation , norm = norm ) self . attn = AttentionBlock ( n_channels ) if has_attn else nn . Identity () self . res2 = ResidualBlock ( n_channels , n_channels , activation = activation , norm = norm ) def forward ( self , x : torch . Tensor ): x = self . res1 ( x ) x = self . attn ( x ) x = self . res2 ( x ) return x","title":"MiddleBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.ResidualBlock","text":"Bases: nn . Module Wide Residual Blocks used in modern Unet architectures. Parameters: Name Type Description Default in_channels int Number of input channels. required out_channels int Number of output channels. required activation str Activation function to use. 'gelu' norm bool Whether to use normalization. False n_groups int Number of groups for group normalization. 1 Source code in pdearena/modules/twod_unet.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 class ResidualBlock ( nn . Module ): \"\"\"Wide Residual Blocks used in modern Unet architectures. Args: in_channels (int): Number of input channels. out_channels (int): Number of output channels. activation (str): Activation function to use. norm (bool): Whether to use normalization. n_groups (int): Number of groups for group normalization. \"\"\" def __init__ ( self , in_channels : int , out_channels : int , activation : str = \"gelu\" , norm : bool = False , n_groups : int = 1 , ): super () . __init__ () self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . conv1 = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) self . conv2 = nn . Conv2d ( out_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # If the number of input channels is not equal to the number of output channels we have to # project the shortcut connection if in_channels != out_channels : self . shortcut = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 1 , 1 )) else : self . shortcut = nn . Identity () if norm : self . norm1 = nn . GroupNorm ( n_groups , in_channels ) self . norm2 = nn . GroupNorm ( n_groups , out_channels ) else : self . norm1 = nn . Identity () self . norm2 = nn . Identity () def forward ( self , x : torch . Tensor ): # First convolution layer h = self . conv1 ( self . activation ( self . norm1 ( x ))) # Second convolution layer h = self . conv2 ( self . activation ( self . norm2 ( h ))) # Add the shortcut connection and return return h + self . shortcut ( x )","title":"ResidualBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.Unet","text":"Bases: nn . Module Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Parameters: Name Type Description Default n_input_scalar_components int Number of scalar components in the model required n_input_vector_components int Number of vector components in the model required n_output_scalar_components int Number of output scalar components in the model required n_output_vector_components int Number of output vector components in the model required time_history int Number of time steps in the input required time_future int Number of time steps in the output required hidden_channels int Number of channels in the hidden layers required activation str Activation function to use required norm bool Whether to use normalization False ch_mults list List of channel multipliers for each resolution (1, 2, 2, 4) is_attn list List of booleans indicating whether to use attention blocks (False, False, False, False) mid_attn bool Whether to use attention block in the middle block False n_blocks int Number of residual blocks in each resolution 2 use1x1 bool Whether to use 1x1 convolutions in the initial and final layers False Source code in pdearena/modules/twod_unet.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 class Unet ( nn . Module ): \"\"\"Modern U-Net architecture This is a modern U-Net architecture with wide-residual blocks and spatial attention blocks Args: n_input_scalar_components (int): Number of scalar components in the model n_input_vector_components (int): Number of vector components in the model n_output_scalar_components (int): Number of output scalar components in the model n_output_vector_components (int): Number of output vector components in the model time_history (int): Number of time steps in the input time_future (int): Number of time steps in the output hidden_channels (int): Number of channels in the hidden layers activation (str): Activation function to use norm (bool): Whether to use normalization ch_mults (list): List of channel multipliers for each resolution is_attn (list): List of booleans indicating whether to use attention blocks mid_attn (bool): Whether to use attention block in the middle block n_blocks (int): Number of residual blocks in each resolution use1x1 (bool): Whether to use 1x1 convolutions in the initial and final layers \"\"\" def __init__ ( self , n_input_scalar_components : int , n_input_vector_components : int , n_output_scalar_components : int , n_output_vector_components : int , time_history : int , time_future : int , hidden_channels : int , activation : str , norm : bool = False , ch_mults : Union [ Tuple [ int , ... ], List [ int ]] = ( 1 , 2 , 2 , 4 ), is_attn : Union [ Tuple [ bool , ... ], List [ bool ]] = ( False , False , False , False ), mid_attn : bool = False , n_blocks : int = 2 , use1x1 : bool = False , ) -> None : super () . __init__ () self . n_input_scalar_components = n_input_scalar_components self . n_input_vector_components = n_input_vector_components self . n_output_scalar_components = n_output_scalar_components self . n_output_vector_components = n_output_vector_components self . time_history = time_history self . time_future = time_future self . hidden_channels = hidden_channels self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) # Number of resolutions n_resolutions = len ( ch_mults ) insize = time_history * ( self . n_input_scalar_components + self . n_input_vector_components * 2 ) n_channels = hidden_channels # Project image into feature map if use1x1 : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = 1 ) else : self . image_proj = nn . Conv2d ( insize , n_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) # #### First half of U-Net - decreasing resolution down = [] # Number of channels out_channels = in_channels = n_channels # For each resolution for i in range ( n_resolutions ): # Number of output channels at this resolution out_channels = in_channels * ch_mults [ i ] # Add `n_blocks` for _ in range ( n_blocks ): down . append ( DownBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) in_channels = out_channels # Down sample at all resolutions except the last if i < n_resolutions - 1 : down . append ( Downsample ( in_channels )) # Combine the set of modules self . down = nn . ModuleList ( down ) # Middle block self . middle = MiddleBlock ( out_channels , has_attn = mid_attn , activation = activation , norm = norm ) # #### Second half of U-Net - increasing resolution up = [] # Number of channels in_channels = out_channels # For each resolution for i in reversed ( range ( n_resolutions )): # `n_blocks` at the same resolution out_channels = in_channels for _ in range ( n_blocks ): up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm , ) ) # Final block to reduce the number of channels out_channels = in_channels // ch_mults [ i ] up . append ( UpBlock ( in_channels , out_channels , has_attn = is_attn [ i ], activation = activation , norm = norm )) in_channels = out_channels # Up sample at all resolutions except last if i > 0 : up . append ( Upsample ( in_channels )) # Combine the set of modules self . up = nn . ModuleList ( up ) if norm : self . norm = nn . GroupNorm ( 8 , n_channels ) else : self . norm = nn . Identity () out_channels = time_future * ( self . n_output_scalar_components + self . n_output_vector_components * 2 ) # if use1x1 : self . final = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 ) else : self . final = nn . Conv2d ( in_channels , out_channels , kernel_size = ( 3 , 3 ), padding = ( 1 , 1 )) def forward ( self , x : torch . Tensor ): assert x . dim () == 5 orig_shape = x . shape x = x . reshape ( x . size ( 0 ), - 1 , * x . shape [ 3 :]) # collapse T,C x = self . image_proj ( x ) h = [ x ] for m in self . down : x = m ( x ) h . append ( x ) x = self . middle ( x ) for m in self . up : if isinstance ( m , Upsample ): x = m ( x ) else : # Get the skip connection from first half of U-Net and concatenate s = h . pop () x = torch . cat (( x , s ), dim = 1 ) # x = m ( x ) x = self . final ( self . activation ( self . norm ( x ))) x = x . reshape ( orig_shape [ 0 ], - 1 , ( self . n_output_scalar_components + self . n_output_vector_components * 2 ), * orig_shape [ 3 :] ) return x","title":"Unet"},{"location":"reference/modules/#pdearena.modules.twod_unet.UpBlock","text":"Bases: nn . Module Up block that combines ResidualBlock and AttentionBlock . These are used in the second half of U-Net at each resolution. Parameters: Name Type Description Default in_channels int Number of input channels required out_channels int Number of output channels required has_attn bool Whether to use attention block False activation str Activation function 'gelu' norm bool Whether to use normalization False Source code in pdearena/modules/twod_unet.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 class UpBlock ( nn . Module ): \"\"\"Up block that combines [`ResidualBlock`][pdearena.modules.twod_unet.ResidualBlock] and [`AttentionBlock`][pdearena.modules.twod_unet.AttentionBlock]. These are used in the second half of U-Net at each resolution. Args: in_channels (int): Number of input channels out_channels (int): Number of output channels has_attn (bool): Whether to use attention block activation (str): Activation function norm (bool): Whether to use normalization \"\"\" def __init__ ( self , in_channels : int , out_channels : int , has_attn : bool = False , activation : str = \"gelu\" , norm : bool = False , ): super () . __init__ () # The input has `in_channels + out_channels` because we concatenate the output of the same resolution # from the first half of the U-Net self . res = ResidualBlock ( in_channels + out_channels , out_channels , activation = activation , norm = norm ) if has_attn : self . attn = AttentionBlock ( out_channels ) else : self . attn = nn . Identity () def forward ( self , x : torch . Tensor ): x = self . res ( x ) x = self . attn ( x ) return x","title":"UpBlock"},{"location":"reference/modules/#pdearena.modules.twod_unet.Upsample","text":"Bases: nn . Module Scale up the feature map by \\(2 \\times\\) Parameters: Name Type Description Default n_channels int Number of channels in the input and output. required Source code in pdearena/modules/twod_unet.py 359 360 361 362 363 364 365 366 367 368 369 370 371 class Upsample ( nn . Module ): r \"\"\"Scale up the feature map by $2 \\times$ Args: n_channels (int): Number of channels in the input and output. \"\"\" def __init__ ( self , n_channels : int ): super () . __init__ () self . conv = nn . ConvTranspose2d ( n_channels , n_channels , ( 4 , 4 ), ( 2 , 2 ), ( 1 , 1 )) def forward ( self , x : torch . Tensor ): return self . conv ( x )","title":"Upsample"},{"location":"reference/visualization/","text":"Visualization \u00a4 plot_2dvec ( ax , vec ) \u00a4 Plot a 2D vector field. Cleanups up the axes and returns the quiver object. Parameters: Name Type Description Default ax mpl . axes . Axes Axes to plot on. required vec np . ndarray [2, ...] 2D Vector field to plot. required Returns: Type Description mpl . quiver . Quiver Quiver object. Source code in pdearena/visualization.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def plot_2dvec ( ax , vec : np . ndarray ) -> mpl . quiver . Quiver : \"\"\"Plot a 2D vector field. Cleanups up the axes and returns the quiver object. Args: ax (mpl.axes.Axes): Axes to plot on. vec (np.ndarray): [2, ...] 2D Vector field to plot. Returns: (mpl.quiver.Quiver): Quiver object. \"\"\" qv = ax . quiver ( vec [ 0 , ... ], vec [ 1 , ... ]) cleanup_axes ( ax ) return qv plot_scalar ( ax , scalar ) \u00a4 Plot a scalar field. Cleanups up the axes and returns the image object. Parameters: Name Type Description Default ax mpl . axes . Axes Axes to plot on. required scalar np . ndarray 2D Scalar field to plot. required Returns: Type Description mpl . image . AxesImage Image object. Source code in pdearena/visualization.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def plot_scalar ( ax , scalar : np . ndarray ) -> mpl . image . AxesImage : \"\"\"Plot a scalar field. Cleanups up the axes and returns the image object. Args: ax (mpl.axes.Axes): Axes to plot on. scalar (np.ndarray): 2D Scalar field to plot. Returns: (mpl.image.AxesImage): Image object. \"\"\" im = ax . imshow ( scalar ) cleanup_axes ( ax ) return im plot_scalar_sequence_comparison ( init_field , ground_truth , prediction , fontsize = 37 , text_loc = ( - 10 , 64 )) \u00a4 Plot a scalar field sequence comparison. Parameters: Name Type Description Default init_field np . ndarray Initial scalar field. We only plot the last time step of the initial field. required ground_truth np . ndarray Ground truth scalar field. required prediction np . ndarray Predicted scalar field. required fontsize int Fontsize for the text annotations. Defaults to 37. 37 text_loc tuple Location of the text annotations. Defaults to (-10, 64). (-10, 64) Returns: Type Description mpl . figure . Figure Figure object. Source code in pdearena/visualization.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def plot_scalar_sequence_comparison ( init_field , ground_truth , prediction , fontsize = 37 , text_loc = ( - 10 , 64 )): \"\"\"Plot a scalar field sequence comparison. Args: init_field (np.ndarray): Initial scalar field. We only plot the last time step of the initial field. ground_truth (np.ndarray): Ground truth scalar field. prediction (np.ndarray): Predicted scalar field. fontsize (int, optional): Fontsize for the text annotations. Defaults to 37. text_loc (tuple, optional): Location of the text annotations. Defaults to (-10, 64). Returns: (mpl.figure.Figure): Figure object. \"\"\" assert ground_truth . shape == prediction . shape err = np . abs ( ground_truth - prediction ) n_timesteps = ground_truth . shape [ 0 ] scaling = max ( ground_truth . shape [ - 2 ] / ground_truth . shape [ - 1 ], 1 ) fig = plt . figure ( figsize = ( n_timesteps * 6 * scaling , 15 )) # Plot the last timestep of init_field ## create space for init_field gs = GridSpec ( 1 , n_timesteps + 1 , figure = fig ) ax1 = fig . add_subplot ( gs [ 0 , 0 ]) im1 = plot_scalar ( ax1 , np . transpose ( init_field [ - 1 , ... ], ( 1 , 2 , 0 ))) ax1 . text ( * text_loc , s = \"Ground truth\" , fontdict = { \"ha\" : \"center\" , \"va\" : \"center\" }, rotation = 90 , fontsize = fontsize ) # Plot the ground truth sequence for i in range ( n_timesteps ): ax = fig . add_subplot ( gs [ 0 , i + 1 ]) im1 = plot_scalar ( ax , np . transpose ( ground_truth [ i , ... ], ( 1 , 2 , 0 ))) # Plot the prediction sequence for i in range ( n_timesteps ): ax = fig . add_subplot ( gs [ 1 , i + 1 ]) im2 = plot_scalar ( ax , np . transpose ( prediction [ i , ... ], ( 1 , 2 , 0 ))) if i == 0 : ax . text ( * text_loc , s = \"Prediction\" , fontdict = { \"ha\" : \"center\" , \"va\" : \"center\" }, rotation = 90 , fontsize = fontsize ) # Plot the error sequence for i in range ( n_timesteps ): ax = fig . add_subplot ( gs [ 2 , i + 1 ]) im3 = plot_scalar ( ax , np . transpose ( err [ i , ... ], ( 1 , 2 , 0 ))) if i == 0 : ax . text ( * text_loc , s = \"Error\" , fontdict = { \"ha\" : \"center\" , \"va\" : \"center\" }, rotation = 90 , fontsize = fontsize ) # Plot the colorbars ## Create space for colorbars fig . subplots_adjust ( wspace = 0 , hspace = 0 , right = 0.9 ) ## Add colorbars cax1 = fig . add_axes ([ 0.9 , 0.15 , 0.02 , 0.2 ]) fig . colorbar ( im3 , cax = cax1 ) cax1 . tick_params ( labelsize = fontsize * 0.6 ) cax2 = fig . add_axes ([ 0.9 , 0.4 , 0.02 , 0.2 ]) fig . colorbar ( im2 , cax = cax2 ) cax2 . tick_params ( labelsize = fontsize * 0.6 ) return fig","title":"Visualization"},{"location":"reference/visualization/#visualization","text":"","title":"Visualization"},{"location":"reference/visualization/#pdearena.visualization.plot_2dvec","text":"Plot a 2D vector field. Cleanups up the axes and returns the quiver object. Parameters: Name Type Description Default ax mpl . axes . Axes Axes to plot on. required vec np . ndarray [2, ...] 2D Vector field to plot. required Returns: Type Description mpl . quiver . Quiver Quiver object. Source code in pdearena/visualization.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def plot_2dvec ( ax , vec : np . ndarray ) -> mpl . quiver . Quiver : \"\"\"Plot a 2D vector field. Cleanups up the axes and returns the quiver object. Args: ax (mpl.axes.Axes): Axes to plot on. vec (np.ndarray): [2, ...] 2D Vector field to plot. Returns: (mpl.quiver.Quiver): Quiver object. \"\"\" qv = ax . quiver ( vec [ 0 , ... ], vec [ 1 , ... ]) cleanup_axes ( ax ) return qv","title":"plot_2dvec()"},{"location":"reference/visualization/#pdearena.visualization.plot_scalar","text":"Plot a scalar field. Cleanups up the axes and returns the image object. Parameters: Name Type Description Default ax mpl . axes . Axes Axes to plot on. required scalar np . ndarray 2D Scalar field to plot. required Returns: Type Description mpl . image . AxesImage Image object. Source code in pdearena/visualization.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def plot_scalar ( ax , scalar : np . ndarray ) -> mpl . image . AxesImage : \"\"\"Plot a scalar field. Cleanups up the axes and returns the image object. Args: ax (mpl.axes.Axes): Axes to plot on. scalar (np.ndarray): 2D Scalar field to plot. Returns: (mpl.image.AxesImage): Image object. \"\"\" im = ax . imshow ( scalar ) cleanup_axes ( ax ) return im","title":"plot_scalar()"},{"location":"reference/visualization/#pdearena.visualization.plot_scalar_sequence_comparison","text":"Plot a scalar field sequence comparison. Parameters: Name Type Description Default init_field np . ndarray Initial scalar field. We only plot the last time step of the initial field. required ground_truth np . ndarray Ground truth scalar field. required prediction np . ndarray Predicted scalar field. required fontsize int Fontsize for the text annotations. Defaults to 37. 37 text_loc tuple Location of the text annotations. Defaults to (-10, 64). (-10, 64) Returns: Type Description mpl . figure . Figure Figure object. Source code in pdearena/visualization.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def plot_scalar_sequence_comparison ( init_field , ground_truth , prediction , fontsize = 37 , text_loc = ( - 10 , 64 )): \"\"\"Plot a scalar field sequence comparison. Args: init_field (np.ndarray): Initial scalar field. We only plot the last time step of the initial field. ground_truth (np.ndarray): Ground truth scalar field. prediction (np.ndarray): Predicted scalar field. fontsize (int, optional): Fontsize for the text annotations. Defaults to 37. text_loc (tuple, optional): Location of the text annotations. Defaults to (-10, 64). Returns: (mpl.figure.Figure): Figure object. \"\"\" assert ground_truth . shape == prediction . shape err = np . abs ( ground_truth - prediction ) n_timesteps = ground_truth . shape [ 0 ] scaling = max ( ground_truth . shape [ - 2 ] / ground_truth . shape [ - 1 ], 1 ) fig = plt . figure ( figsize = ( n_timesteps * 6 * scaling , 15 )) # Plot the last timestep of init_field ## create space for init_field gs = GridSpec ( 1 , n_timesteps + 1 , figure = fig ) ax1 = fig . add_subplot ( gs [ 0 , 0 ]) im1 = plot_scalar ( ax1 , np . transpose ( init_field [ - 1 , ... ], ( 1 , 2 , 0 ))) ax1 . text ( * text_loc , s = \"Ground truth\" , fontdict = { \"ha\" : \"center\" , \"va\" : \"center\" }, rotation = 90 , fontsize = fontsize ) # Plot the ground truth sequence for i in range ( n_timesteps ): ax = fig . add_subplot ( gs [ 0 , i + 1 ]) im1 = plot_scalar ( ax , np . transpose ( ground_truth [ i , ... ], ( 1 , 2 , 0 ))) # Plot the prediction sequence for i in range ( n_timesteps ): ax = fig . add_subplot ( gs [ 1 , i + 1 ]) im2 = plot_scalar ( ax , np . transpose ( prediction [ i , ... ], ( 1 , 2 , 0 ))) if i == 0 : ax . text ( * text_loc , s = \"Prediction\" , fontdict = { \"ha\" : \"center\" , \"va\" : \"center\" }, rotation = 90 , fontsize = fontsize ) # Plot the error sequence for i in range ( n_timesteps ): ax = fig . add_subplot ( gs [ 2 , i + 1 ]) im3 = plot_scalar ( ax , np . transpose ( err [ i , ... ], ( 1 , 2 , 0 ))) if i == 0 : ax . text ( * text_loc , s = \"Error\" , fontdict = { \"ha\" : \"center\" , \"va\" : \"center\" }, rotation = 90 , fontsize = fontsize ) # Plot the colorbars ## Create space for colorbars fig . subplots_adjust ( wspace = 0 , hspace = 0 , right = 0.9 ) ## Add colorbars cax1 = fig . add_axes ([ 0.9 , 0.15 , 0.02 , 0.2 ]) fig . colorbar ( im3 , cax = cax1 ) cax1 . tick_params ( labelsize = fontsize * 0.6 ) cax2 = fig . add_axes ([ 0.9 , 0.4 , 0.02 , 0.2 ]) fig . colorbar ( im2 , cax = cax2 ) cax2 . tick_params ( labelsize = fontsize * 0.6 ) return fig","title":"plot_scalar_sequence_comparison()"},{"location":"scenarios/applied/","text":"Scenario: You have a new class of PDE and want to see if PDE surrogates can be useful for you \u00a4 There are hundreds of possible PDE surrogate models. As with most deep learning, choice of hyperparameters can matter a lot too. You might also have your own runtime requirements, and data or time limitations. PDEArena provides a simple interface for you to try out many possible model designs and understand the best model for your task and constraints. All you need to do is, define your PDE configuration details in pde.py , write a IterDataPipe for your dataset, add it to the DATAPIPE_REGISTRY , and you should be good to go. Simple Example \u00a4 Let's say you want a new task modeling Shallow water making predictions at 18 hours interval. You can subclass the ShallowWaterDatasetOpener as: class ShallowWaterDatasetOpener18Hr ( ShallowWaterDatasetOpener ): def __init__ ( self , dp , mode : str , limit_trajectories : Optional [ int ] = None , usegrid : bool = False , ) -> None : # sample_rate=1 implies 6hr super () . __init__ ( dp , mode , limit_trajectories , usevort = False , usegrid = usegrid , sample_rate = 3 ) Now you can set up the various datapipes for training, validation and testing: # Train train_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathertrain_filter , sharder = _sharder , mode = \"train\" , ) # Valid onestep_valid_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathervalid_filter , sharder = _sharder , mode = \"valid\" , onestep = True , ) trajectory_valid_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathervalid_filter , sharder = _sharder , mode = \"valid\" , onestep = False , ) # Test onestep_test_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathertest_filter , sharder = _sharder , mode = \"test\" , onestep = True , ) trajectory_test_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathertest_filter , sharder = _sharder , mode = \"test\" , onestep = False , ) Then you can add these datapipes to the data registry : DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ] = {} DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ][ \"train\" ] = train_datapipe_18Hr_vel DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ][ \"valid\" ] = [ onestep_valid_datapipe_18Hr_vel , trajectory_valid_datapipe_18Hr_vel , ] DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ][ \"test\" ] = [ onestep_test_datapipe_18Hr_vel , trajectory_test_datapipe_18Hr_vel , ] Finally you can train different models from the model zoo by setting the data.task=ShallowWater2DVel-18Hr : data : task : ShallowWater2DVel-18Hr See config for an example of training with 2-day prediction.","title":"Application"},{"location":"scenarios/applied/#scenario-you-have-a-new-class-of-pde-and-want-to-see-if-pde-surrogates-can-be-useful-for-you","text":"There are hundreds of possible PDE surrogate models. As with most deep learning, choice of hyperparameters can matter a lot too. You might also have your own runtime requirements, and data or time limitations. PDEArena provides a simple interface for you to try out many possible model designs and understand the best model for your task and constraints. All you need to do is, define your PDE configuration details in pde.py , write a IterDataPipe for your dataset, add it to the DATAPIPE_REGISTRY , and you should be good to go.","title":"Scenario: You have a new class of PDE and want to see if PDE surrogates can be useful for you"},{"location":"scenarios/applied/#simple-example","text":"Let's say you want a new task modeling Shallow water making predictions at 18 hours interval. You can subclass the ShallowWaterDatasetOpener as: class ShallowWaterDatasetOpener18Hr ( ShallowWaterDatasetOpener ): def __init__ ( self , dp , mode : str , limit_trajectories : Optional [ int ] = None , usegrid : bool = False , ) -> None : # sample_rate=1 implies 6hr super () . __init__ ( dp , mode , limit_trajectories , usevort = False , usegrid = usegrid , sample_rate = 3 ) Now you can set up the various datapipes for training, validation and testing: # Train train_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathertrain_filter , sharder = _sharder , mode = \"train\" , ) # Valid onestep_valid_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathervalid_filter , sharder = _sharder , mode = \"valid\" , onestep = True , ) trajectory_valid_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathervalid_filter , sharder = _sharder , mode = \"valid\" , onestep = False , ) # Test onestep_test_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathertest_filter , sharder = _sharder , mode = \"test\" , onestep = True , ) trajectory_test_datapipe_18Hr_vel = functools . partial ( build_datapipes , dataset_opener = ShallowWaterDatasetOpener18Hr , lister = ZarrLister , filter_fn = _weathertest_filter , sharder = _sharder , mode = \"test\" , onestep = False , ) Then you can add these datapipes to the data registry : DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ] = {} DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ][ \"train\" ] = train_datapipe_18Hr_vel DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ][ \"valid\" ] = [ onestep_valid_datapipe_18Hr_vel , trajectory_valid_datapipe_18Hr_vel , ] DATAPIPE_REGISTRY [ \"ShallowWater2DVel-18Hr\" ][ \"test\" ] = [ onestep_test_datapipe_18Hr_vel , trajectory_test_datapipe_18Hr_vel , ] Finally you can train different models from the model zoo by setting the data.task=ShallowWater2DVel-18Hr : data : task : ShallowWater2DVel-18Hr See config for an example of training with 2-day prediction.","title":"Simple Example"},{"location":"scenarios/beginner/","text":"Scenario: You are a beginner to PDE surrogate modeling \u00a4 PDE surrogate modeling has seen quite some interest being at the intersection of AI and Science. You probably have read an exciting PDE surrogate modeling paper (more frequently termed operator learning paper), and maybe you want to understand how the pipeline works. PDEArena can be a perfect place for you to start learning about standardized PDE surrogate implementations and evaluations, following modern deep learning best practices.","title":"Beginner"},{"location":"scenarios/beginner/#scenario-you-are-a-beginner-to-pde-surrogate-modeling","text":"PDE surrogate modeling has seen quite some interest being at the intersection of AI and Science. You probably have read an exciting PDE surrogate modeling paper (more frequently termed operator learning paper), and maybe you want to understand how the pipeline works. PDEArena can be a perfect place for you to start learning about standardized PDE surrogate implementations and evaluations, following modern deep learning best practices.","title":"Scenario: You are a beginner to PDE surrogate modeling"},{"location":"scenarios/researcher/","text":"Scenario: You are a PDE + ML researcher \u00a4 Simple Example \u00a4 Say you want to evaluate a conditioned version of DilatedResNet . You can add a version of DilatedBasicBlock that works with an embedding vector as follows: class CondDilatedBasicBlock ( nn . Module ): \"\"\"Basic block for Dilated ResNet Args: in_planes (int): number of input channels planes (int): number of output channels stride (int, optional): stride of the convolution. Defaults to 1. activation (str, optional): activation function. Defaults to \"relu\". norm (bool, optional): whether to use group normalization. Defaults to True. num_groups (int, optional): number of groups for group normalization. Defaults to 1. \"\"\" expansion = 1 def __init__ ( self , in_planes : int , planes : int , cond_channels : int , stride : int = 1 , activation : str = \"relu\" , norm : bool = True , num_groups : int = 1 , ): super () . __init__ () self . dilation = [ 1 , 2 , 4 , 8 , 4 , 2 , 1 ] dilation_layers = [] for dil in self . dilation : dilation_layers . append ( nn . Conv2d ( in_planes , planes , kernel_size = 3 , stride = stride , dilation = dil , padding = dil , bias = True , ) ) self . dilation_layers = nn . ModuleList ( dilation_layers ) self . norm_layers = nn . ModuleList ( nn . GroupNorm ( num_groups , num_channels = planes ) if norm else nn . Identity () for dil in self . dilation ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . cond_emb = nn . Linear ( cond_channels , planes ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ) -> torch . Tensor : out = x emb_out = self . cond_emb ( emb ) while len ( emb_out . shape ) < len ( x . shape ): emb_out = emb_out [ ... , None ] for layer , norm in zip ( self . dilation_layers , self . norm_layers ): out = self . activation ( layer ( norm ( out ))) return out + x + emb_out Now we can add an appropriate instantiation of the model in the COND_MODEL_REGISTRY : COND_MODEL_REGISTRY [ \"DilResNet-128\" ] = { \"class_path\" : \"pdearena.modules.conditioned.twod_resnet.ResNet\" , \"init_args\" : { \"hidden_channels\" : 128 , \"norm\" : True , \"num_blocks\" : [ 1 , 1 , 1 , 1 ], \"block\" : CondDilatedBasicBlock } } Finally you can train this model by appropriately setting up model.name=DilResNet-128 in the training config: model : name : DilResNet-128 max_num_steps : 5 activation : \"gelu\" criterion : mse lr : 1e-3 param_conditioning : \"scalar\"","title":"PDE Surrogate Research"},{"location":"scenarios/researcher/#scenario-you-are-a-pde-ml-researcher","text":"","title":"Scenario: You are a PDE + ML researcher"},{"location":"scenarios/researcher/#simple-example","text":"Say you want to evaluate a conditioned version of DilatedResNet . You can add a version of DilatedBasicBlock that works with an embedding vector as follows: class CondDilatedBasicBlock ( nn . Module ): \"\"\"Basic block for Dilated ResNet Args: in_planes (int): number of input channels planes (int): number of output channels stride (int, optional): stride of the convolution. Defaults to 1. activation (str, optional): activation function. Defaults to \"relu\". norm (bool, optional): whether to use group normalization. Defaults to True. num_groups (int, optional): number of groups for group normalization. Defaults to 1. \"\"\" expansion = 1 def __init__ ( self , in_planes : int , planes : int , cond_channels : int , stride : int = 1 , activation : str = \"relu\" , norm : bool = True , num_groups : int = 1 , ): super () . __init__ () self . dilation = [ 1 , 2 , 4 , 8 , 4 , 2 , 1 ] dilation_layers = [] for dil in self . dilation : dilation_layers . append ( nn . Conv2d ( in_planes , planes , kernel_size = 3 , stride = stride , dilation = dil , padding = dil , bias = True , ) ) self . dilation_layers = nn . ModuleList ( dilation_layers ) self . norm_layers = nn . ModuleList ( nn . GroupNorm ( num_groups , num_channels = planes ) if norm else nn . Identity () for dil in self . dilation ) self . activation : nn . Module = ACTIVATION_REGISTRY . get ( activation , None ) if self . activation is None : raise NotImplementedError ( f \"Activation { activation } not implemented\" ) self . cond_emb = nn . Linear ( cond_channels , planes ) def forward ( self , x : torch . Tensor , emb : torch . Tensor ) -> torch . Tensor : out = x emb_out = self . cond_emb ( emb ) while len ( emb_out . shape ) < len ( x . shape ): emb_out = emb_out [ ... , None ] for layer , norm in zip ( self . dilation_layers , self . norm_layers ): out = self . activation ( layer ( norm ( out ))) return out + x + emb_out Now we can add an appropriate instantiation of the model in the COND_MODEL_REGISTRY : COND_MODEL_REGISTRY [ \"DilResNet-128\" ] = { \"class_path\" : \"pdearena.modules.conditioned.twod_resnet.ResNet\" , \"init_args\" : { \"hidden_channels\" : 128 , \"norm\" : True , \"num_blocks\" : [ 1 , 1 , 1 , 1 ], \"block\" : CondDilatedBasicBlock } } Finally you can train this model by appropriately setting up model.name=DilResNet-128 in the training config: model : name : DilResNet-128 max_num_steps : 5 activation : \"gelu\" criterion : mse lr : 1e-3 param_conditioning : \"scalar\"","title":"Simple Example"}]}